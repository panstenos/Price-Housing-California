{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for ZipCode 91342\n",
      "Fitting for window_size of 50 and hidden size of 100\n",
      "Epoch:  1 Test Loss: 0.93648630 Val RMSE: 145848.70541209934\n",
      "Epoch:  2 Test Loss: 0.71711433 Val RMSE: 124605.04052143593\n",
      "Epoch:  3 Test Loss: 0.16873655 Val RMSE: 68582.11572668009\n",
      "Epoch:  4 Test Loss: 0.09283120 Val RMSE: 55677.11870716107\n",
      "Epoch:  5 Test Loss: 0.10093425 Val RMSE: 58704.58399920813\n",
      "Epoch:  6 Test Loss: 0.09235884 Val RMSE: 57610.72533828434\n",
      "Epoch:  7 Test Loss: 0.08046671 Val RMSE: 55442.74324564358\n",
      "Epoch:  8 Test Loss: 0.07162179 Val RMSE: 53750.075327539336\n",
      "Epoch:  9 Test Loss: 0.06448394 Val RMSE: 52316.788032330165\n",
      "Epoch: 10 Test Loss: 0.05827413 Val RMSE: 50992.72633898256\n",
      "Epoch: 11 Test Loss: 0.05258998 Val RMSE: 49689.40890725855\n",
      "Epoch: 12 Test Loss: 0.04721517 Val RMSE: 48348.85654217488\n",
      "Epoch: 13 Test Loss: 0.04202900 Val RMSE: 46926.78967463009\n",
      "Epoch: 14 Test Loss: 0.03696821 Val RMSE: 45385.478331923114\n",
      "Epoch: 15 Test Loss: 0.03201133 Val RMSE: 43691.58614665234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import math\n",
    "import copy\n",
    "\n",
    "datapath = \"All_zip.csv\"\n",
    "WINDOW_SIZE = 50\n",
    "LEARNING_RATE = 0.000025\n",
    "N_EPOCHS = 100\n",
    "HIDDEN_SIZE = 100\n",
    "EPOCHS_EARLY = 20\n",
    "\n",
    "class PriceData():\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.df = self.generateDF(filename)\n",
    "\n",
    "    def generateDF(self, filename):\n",
    "        \n",
    "        def lat(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][0]\n",
    "\n",
    "        def long(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][1]\n",
    "\n",
    "        \n",
    "        orig_df = pd.read_csv(filename)\n",
    "        filtered_df = orig_df.loc[(orig_df['State'] == \"CA\")]\n",
    "        \n",
    "        \n",
    "\n",
    "        columns = filtered_df.columns\n",
    "        \n",
    "\n",
    "        cal_df = filtered_df \\\n",
    "            .dropna() \\\n",
    "            .drop(columns=columns[3:9]) \\\n",
    "            .drop(columns=columns[0:2]) \\\n",
    "            .rename(columns={'RegionName': 'ZipCode'}) \\\n",
    "            .reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        cal_df.set_index(\"ZipCode\", inplace = True)\n",
    "\n",
    "#         for zip_code in cal_df.index:\n",
    "#             print(zip_code)\n",
    "#             cal_df[\"windows\"] = cal_df.apply(lambda row: createBatches(row[\"prices\"]), axis = 1)\n",
    "        \n",
    "\n",
    "        return cal_df\n",
    "    \n",
    "    \n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size = 1, window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE, out_size = 1, learning_rate = LEARNING_RATE, epochs = N_EPOCHS):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        #Model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,out_size)\n",
    "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
    "        self.window_size = None\n",
    "        self.prices = None\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        #Data processing\n",
    "        self.scaler = None\n",
    "        \n",
    "        #Training parameters\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        \n",
    "        #Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def _preprocessor(self, ySeries):\n",
    "        y = ySeries.values\n",
    "\n",
    "        \n",
    "        \n",
    "        window_size = self.window_size\n",
    "\n",
    "        out = []\n",
    "        self.prices = y[:window_size].reshape(window_size)\n",
    "        for i in range(len(y) - window_size):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            y_scaled = scaler.fit_transform(y[i:i+window_size+1].reshape(-1, 1))\n",
    "            self.scaler = scaler\n",
    "            window = torch.tensor(y_scaled[:window_size]).to(torch.float32)\n",
    "            label = torch.tensor(y_scaled[window_size:window_size+1]).to(torch.float32)\n",
    "            self.prices = np.append(self.prices, y[i+window_size:i+window_size+1][0])\n",
    "            out.append((window, label))\n",
    "        return out\n",
    "    \n",
    "    def fit(self, y, y_val):\n",
    "        y_train = self._preprocessor(y)\n",
    "        \n",
    "        epochs_wo_imp = 0\n",
    "        lowest_rmse = math.inf\n",
    "        val_rmse = math.inf\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for seq, y_hat in y_train:\n",
    "                self.optimiser.zero_grad()\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size), torch.zeros(1,1,self.hidden_size))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "                loss = self.criterion(y_hat[0], y_pred)\n",
    "                loss.backward() \n",
    "                self.optimiser.step()\n",
    "            \n",
    "            val_rmse = self.score(y_val)[0]\n",
    "            \n",
    "            if (epoch > 2):\n",
    "                if (val_rmse < lowest_rmse):\n",
    "                    best_model = copy.deepcopy(self)\n",
    "                    best_model.prices = np.append(best_model.prices, y_val)\n",
    "                    lowest_rmse = val_rmse\n",
    "                    epochs_wo_imp = 0\n",
    "                else:\n",
    "                    epochs_wo_imp += 1\n",
    "\n",
    "                if (epochs_wo_imp == EPOCHS_EARLY):\n",
    "                    return best_model, lowest_rmse\n",
    "            \n",
    "            print(f'Epoch: {epoch+1:2} Test Loss: {loss.item():10.8f} Val RMSE: {val_rmse}')\n",
    "            \n",
    "        return (best_model, lowest_rmse)\n",
    "                \n",
    "            \n",
    "    def predict(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            seq = torch.FloatTensor(scaler.fit_transform(self.prices[-self.window_size:].reshape(-1, 1)))\n",
    "            self.scaler = scaler\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self.scaler.inverse_transform(np.array(self(seq).item()).reshape(-1, 1)))\n",
    "        \n",
    "        predictions = self.prices[-future_instances:]\n",
    "        self.prices = self.prices[:-future_instances]\n",
    "        return predictions\n",
    "    \n",
    "    def predict_inplace(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            seq = torch.FloatTensor(scaler.fit_transform(self.prices[-self.window_size:].reshape(-1, 1)))\n",
    "            self.scaler = scaler\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self.scaler.inverse_transform(np.array(self(seq).item()).reshape(-1, 1)))\n",
    "        \n",
    "        predictions = self.prices[-future_instances:]\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, y):\n",
    "        y_pred = self.predict(len(y))\n",
    "        rmse = np.sqrt(np.mean(((np.array(y_pred)-np.array(y)))**2))\n",
    "        return rmse, y_pred\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
    "        pred = self.linear(lstm_out.view(len(seq),-1))\n",
    "        return pred[-1]\n",
    "    \n",
    "    \n",
    "def split_dataset(y, valid_proportion, test_proportion):\n",
    "\n",
    "    n_test = round(len(y) * test_proportion)\n",
    "    n_valid = round(len(y) * valid_proportion)\n",
    "    n_train = (len(y) - n_test) - n_valid\n",
    "    \n",
    "    y_train = y[:n_train]\n",
    "    y_valid = y[n_train:n_train + n_valid]\n",
    "    y_test = y[n_train + n_valid:]\n",
    "    \n",
    "    return (y_train, y_valid, y_test)\n",
    "\n",
    "\n",
    "def save_regressor(trained_model, zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to save the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with load_regressor\n",
    "    with open(str(zipcode) + '_model.pickle', 'wb') as target:\n",
    "        pickle.dump(trained_model, target)\n",
    "    print(f\"\\nSaved model in {zipcode}_model.pickle\\n\")\n",
    "\n",
    "\n",
    "def load_regressor(zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to load the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with save_regressor\n",
    "    with open(str(zipcode) + '_model.pickle', 'rb') as target:\n",
    "        trained_model = pickle.load(target)\n",
    "    print(f\"\\nLoaded model in {zipcode}_model.pickle\\n\")\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def hyperparameterSearch( window_sizes = [10, 20, 40, 80, 100], hidden_sizes = [10, 20, 40, 60, 80, 100, 150], zipcode = 91331, df = cal_df):\n",
    "    lowest_rmse = math.inf\n",
    "    val_rmse = math.inf\n",
    "    \n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        WINDOW_SIZE = window_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            HIDDEN_SIZE = hidden_size\n",
    "            \n",
    "            print(f\"Fitting for window_size of {WINDOW_SIZE} and hidden size of {HIDDEN_SIZE}\")\n",
    "            y = df.loc[zipcode]\n",
    "\n",
    "            y_train, y_valid, y_test = split_dataset(y, 0.1, 0.1)\n",
    "\n",
    "            model = LSTM(window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE)\n",
    "            model, val_rmse = model.fit(y_train, y_valid)\n",
    "            print(f\"Model trained for window_size of {model.window_size} and hidden size of {model.hidden_size}\")\n",
    "\n",
    "\n",
    "            if (val_rmse < lowest_rmse):\n",
    "                best_model = copy.deepcopy(model)\n",
    "                lowest_rmse = val_rmse\n",
    "                \n",
    "    save_regressor(best_model,zipcode)\n",
    "    return best_model\n",
    "\n",
    "def evaluate(zipcode, cal_df):\n",
    "    model = load_regressor(zipcode)\n",
    "    print(\"Window size:\", model.window_size, \"Hidden size:\", model.hidden_size)\n",
    "    y = cal_df.loc[zipcode]\n",
    "    y_train, y_valid, y_test = split_dataset(y, 0.1, 0.1)\n",
    "    test_rmse, y_preds = model.score(y_test)\n",
    "    print(\"RMSE:\", test_rmse)\n",
    "\n",
    "\n",
    "    plt.plot(np.append(model.prices, y_preds))\n",
    "    plt.plot(np.append(y_train, np.append(y_valid, y_test)))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    cal_df = PriceData(datapath).df\n",
    "    zip_codes = cal_df.index[10:11]\n",
    "    for zip_code in zip_codes:\n",
    "        print(f\"Training Model for ZipCode {zip_code}\")\n",
    "        hyperparameterSearch( window_sizes = [50], hidden_sizes = [100], zipcode = zip_code, df = cal_df)\n",
    "\n",
    "        print(f\"Evaluating Model for ZipCode {zip_code}\")\n",
    "        evaluate(zip_code, cal_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluating Model for ZipCode {zip_code}\")\n",
    "evaluate(zip_code, cal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
