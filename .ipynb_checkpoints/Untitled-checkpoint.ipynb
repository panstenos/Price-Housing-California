{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for ZipCode 91342\n",
      "Fitting for window_size of 50 and hidden size of 100\n",
      "Epoch:  1 Test Loss: 0.86702091 Val RMSE: 140434.1706591415\n",
      "Epoch:  2 Test Loss: 0.66352886 Val RMSE: 121680.2845623071\n",
      "Epoch:  3 Test Loss: 0.17351483 Val RMSE: 71655.43824690834\n",
      "Epoch:  4 Test Loss: 0.07394452 Val RMSE: 51903.43128008025\n",
      "Epoch:  5 Test Loss: 0.08180917 Val RMSE: 55448.83347209108\n",
      "Epoch:  6 Test Loss: 0.07658131 Val RMSE: 54944.31970241349\n",
      "Epoch:  7 Test Loss: 0.06662495 Val RMSE: 52774.2273889214\n",
      "Epoch:  8 Test Loss: 0.05877249 Val RMSE: 50895.38824950112\n",
      "Epoch:  9 Test Loss: 0.05257741 Val RMSE: 49301.377387449305\n",
      "Epoch: 10 Test Loss: 0.04736563 Val RMSE: 47847.21052570802\n",
      "Epoch: 11 Test Loss: 0.04277659 Val RMSE: 46444.56388333647\n",
      "Epoch: 12 Test Loss: 0.03861612 Val RMSE: 45039.52952866726\n",
      "Epoch: 13 Test Loss: 0.03476992 Val RMSE: 43594.16430539737\n",
      "Epoch: 14 Test Loss: 0.03117084 Val RMSE: 42081.19502315935\n",
      "Epoch: 15 Test Loss: 0.02778400 Val RMSE: 40483.799563966815\n",
      "Epoch: 16 Test Loss: 0.02459922 Val RMSE: 38798.29109239933\n",
      "Epoch: 17 Test Loss: 0.02162362 Val RMSE: 37036.603854066176\n",
      "Epoch: 18 Test Loss: 0.01887079 Val RMSE: 35224.25543758191\n",
      "Epoch: 19 Test Loss: 0.01634910 Val RMSE: 33392.26672312876\n",
      "Epoch: 20 Test Loss: 0.01405564 Val RMSE: 31570.51572388382\n",
      "Epoch: 21 Test Loss: 0.01197773 Val RMSE: 29788.81823139381\n",
      "Epoch: 22 Test Loss: 0.01009936 Val RMSE: 26089.91248244441\n",
      "Epoch: 23 Test Loss: 0.00840736 Val RMSE: 21560.470371514777\n",
      "Epoch: 24 Test Loss: 0.00689426 Val RMSE: 16747.32951746864\n",
      "Epoch: 25 Test Loss: 0.00555844 Val RMSE: 12282.13323214648\n",
      "Epoch: 26 Test Loss: 0.00440378 Val RMSE: 10186.942864279878\n",
      "Epoch: 27 Test Loss: 0.00343844 Val RMSE: 13815.00331239267\n",
      "Epoch: 28 Test Loss: 0.00267140 Val RMSE: 22609.494361618694\n",
      "Epoch: 29 Test Loss: 0.00210529 Val RMSE: 34624.320551243276\n",
      "Epoch: 30 Test Loss: 0.00172791 Val RMSE: 48174.60049642587\n",
      "Epoch: 31 Test Loss: 0.00150893 Val RMSE: 60936.163357806196\n",
      "Epoch: 32 Test Loss: 0.00140625 Val RMSE: 71081.86706967985\n",
      "Epoch: 33 Test Loss: 0.00137718 Val RMSE: 78165.60194690623\n",
      "Epoch: 34 Test Loss: 0.00138670 Val RMSE: 82731.27528723686\n",
      "Epoch: 35 Test Loss: 0.00141026 Val RMSE: 85617.07873479923\n",
      "Epoch: 36 Test Loss: 0.00143277 Val RMSE: 87503.76693359906\n",
      "Epoch: 37 Test Loss: 0.00144614 Val RMSE: 88862.72440134705\n",
      "Epoch: 38 Test Loss: 0.00144717 Val RMSE: 89965.33778423058\n",
      "Epoch: 39 Test Loss: 0.00143571 Val RMSE: 90935.04571382448\n",
      "Epoch: 40 Test Loss: 0.00141340 Val RMSE: 91805.35887029629\n",
      "Epoch: 41 Test Loss: 0.00138276 Val RMSE: 92558.08852748794\n",
      "Epoch: 42 Test Loss: 0.00134650 Val RMSE: 93159.23188933847\n",
      "Epoch: 43 Test Loss: 0.00130720 Val RMSE: 93570.84391342769\n",
      "Epoch: 44 Test Loss: 0.00126710 Val RMSE: 93766.20262546767\n",
      "Epoch: 45 Test Loss: 0.00122808 Val RMSE: 93727.07172475761\n",
      "Epoch: 46 Test Loss: 0.00119169 Val RMSE: 93446.39371749507\n",
      "Epoch: 47 Test Loss: 0.00115914 Val RMSE: 92923.81678212056\n",
      "Epoch: 48 Test Loss: 0.00113143 Val RMSE: 92165.97317011672\n",
      "Epoch: 49 Test Loss: 0.00110936 Val RMSE: 91180.99682859541\n",
      "Epoch: 50 Test Loss: 0.00109355 Val RMSE: 89982.17756376837\n",
      "Epoch: 51 Test Loss: 0.00108448 Val RMSE: 88582.67969042019\n",
      "Epoch: 52 Test Loss: 0.00108247 Val RMSE: 87000.29496071872\n",
      "Epoch: 53 Test Loss: 0.00108775 Val RMSE: 85254.06338478335\n",
      "Epoch: 54 Test Loss: 0.00110028 Val RMSE: 83367.73731535453\n",
      "Epoch: 55 Test Loss: 0.00111985 Val RMSE: 81369.57459683529\n",
      "Epoch: 56 Test Loss: 0.00114604 Val RMSE: 79290.12121224734\n",
      "Epoch: 57 Test Loss: 0.00117805 Val RMSE: 77165.59446910286\n",
      "Epoch: 58 Test Loss: 0.00121477 Val RMSE: 75034.18786995512\n",
      "Epoch: 59 Test Loss: 0.00125476 Val RMSE: 72936.53189209627\n",
      "Epoch: 60 Test Loss: 0.00129623 Val RMSE: 70913.41199321636\n",
      "Epoch: 61 Test Loss: 0.00133715 Val RMSE: 69003.09271114867\n",
      "Epoch: 62 Test Loss: 0.00137535 Val RMSE: 67241.05025385332\n",
      "Epoch: 63 Test Loss: 0.00140868 Val RMSE: 65654.63169661914\n",
      "Epoch: 64 Test Loss: 0.00143522 Val RMSE: 64265.753350904415\n",
      "Epoch: 65 Test Loss: 0.00145343 Val RMSE: 63086.493019984424\n",
      "Epoch: 66 Test Loss: 0.00146229 Val RMSE: 62121.83319566003\n",
      "Epoch: 67 Test Loss: 0.00146134 Val RMSE: 61369.139528693595\n",
      "Epoch: 68 Test Loss: 0.00145064 Val RMSE: 60819.85749392798\n",
      "Epoch: 69 Test Loss: 0.00143077 Val RMSE: 60460.98723872818\n",
      "Epoch: 70 Test Loss: 0.00140260 Val RMSE: 60277.83944032229\n",
      "Epoch: 71 Test Loss: 0.00136725 Val RMSE: 60254.503626795165\n",
      "Epoch: 72 Test Loss: 0.00132586 Val RMSE: 60374.87398451309\n",
      "Epoch: 73 Test Loss: 0.00127962 Val RMSE: 60624.12070541129\n",
      "Epoch: 74 Test Loss: 0.00122962 Val RMSE: 60988.38684605782\n",
      "Epoch: 75 Test Loss: 0.00117682 Val RMSE: 61456.054125755756\n",
      "Epoch: 76 Test Loss: 0.00112210 Val RMSE: 62015.7823828814\n",
      "Epoch: 77 Test Loss: 0.00106617 Val RMSE: 62659.26871181349\n",
      "Epoch: 78 Test Loss: 0.00100966 Val RMSE: 63378.74802952705\n",
      "Epoch: 79 Test Loss: 0.00095307 Val RMSE: 64167.7452750586\n",
      "Epoch: 80 Test Loss: 0.00089685 Val RMSE: 65021.10816709078\n",
      "Epoch: 81 Test Loss: 0.00084131 Val RMSE: 65936.47460204847\n",
      "Epoch: 82 Test Loss: 0.00078675 Val RMSE: 66910.35607644521\n",
      "Epoch: 83 Test Loss: 0.00073338 Val RMSE: 67942.42586673683\n",
      "Epoch: 84 Test Loss: 0.00068139 Val RMSE: 69033.15565293383\n",
      "Epoch: 85 Test Loss: 0.00063093 Val RMSE: 70184.21195084312\n",
      "Epoch: 86 Test Loss: 0.00058211 Val RMSE: 71399.51747250279\n",
      "Epoch: 87 Test Loss: 0.00053502 Val RMSE: 72684.46504530497\n",
      "Epoch: 88 Test Loss: 0.00048975 Val RMSE: 74046.4204878286\n",
      "Epoch: 89 Test Loss: 0.00044637 Val RMSE: 75496.05406484794\n",
      "Epoch: 90 Test Loss: 0.00040496 Val RMSE: 77047.68342169942\n",
      "Epoch: 91 Test Loss: 0.00036563 Val RMSE: 78719.50304643039\n",
      "Epoch: 92 Test Loss: 0.00032847 Val RMSE: 80538.61080896712\n",
      "Epoch: 93 Test Loss: 0.00029363 Val RMSE: 82543.14406942521\n",
      "Epoch: 94 Test Loss: 0.00026130 Val RMSE: 84790.618661555\n",
      "Epoch: 95 Test Loss: 0.00023177 Val RMSE: 87375.86772213328\n",
      "Epoch: 96 Test Loss: 0.00020544 Val RMSE: 90460.90001305845\n",
      "Epoch: 97 Test Loss: 0.00018299 Val RMSE: 94351.52133182925\n",
      "Epoch: 98 Test Loss: 0.00016561 Val RMSE: 99666.40566015914\n",
      "Epoch: 99 Test Loss: 0.00015573 Val RMSE: 107746.01012561934\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import math\n",
    "import copy\n",
    "\n",
    "datapath = \"All_zip.csv\"\n",
    "WINDOW_SIZE = 50\n",
    "LEARNING_RATE = 0.000025\n",
    "N_EPOCHS = 100\n",
    "HIDDEN_SIZE = 100\n",
    "EPOCHS_EARLY = 20\n",
    "\n",
    "class PriceData():\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.df = self.generateDF(filename)\n",
    "\n",
    "    def generateDF(self, filename):\n",
    "        \n",
    "        def lat(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][0]\n",
    "\n",
    "        def long(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][1]\n",
    "\n",
    "        \n",
    "        orig_df = pd.read_csv(filename)\n",
    "        filtered_df = orig_df.loc[(orig_df['State'] == \"CA\")]\n",
    "        \n",
    "        \n",
    "\n",
    "        columns = filtered_df.columns\n",
    "        \n",
    "\n",
    "        cal_df = filtered_df \\\n",
    "            .dropna() \\\n",
    "            .drop(columns=columns[3:9]) \\\n",
    "            .drop(columns=columns[0:2]) \\\n",
    "            .rename(columns={'RegionName': 'ZipCode'}) \\\n",
    "            .reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        cal_df.set_index(\"ZipCode\", inplace = True)\n",
    "\n",
    "#         for zip_code in cal_df.index:\n",
    "#             print(zip_code)\n",
    "#             cal_df[\"windows\"] = cal_df.apply(lambda row: createBatches(row[\"prices\"]), axis = 1)\n",
    "        \n",
    "\n",
    "        return cal_df\n",
    "    \n",
    "    \n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size = 1, window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE, out_size = 1, learning_rate = LEARNING_RATE, epochs = N_EPOCHS):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        #Model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,out_size)\n",
    "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
    "        self.window_size = None\n",
    "        self.prices = None\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        #Data processing\n",
    "        self.scaler = None\n",
    "        \n",
    "        #Training parameters\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        \n",
    "        #Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def _preprocessor(self, ySeries):\n",
    "        y = ySeries.values\n",
    "\n",
    "        \n",
    "        \n",
    "        window_size = self.window_size\n",
    "\n",
    "        out = []\n",
    "        self.prices = y[:window_size].reshape(window_size)\n",
    "        for i in range(len(y) - window_size):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            y_scaled = scaler.fit_transform(y[i:i+window_size+1].reshape(-1, 1))\n",
    "            self.scaler = scaler\n",
    "            window = torch.tensor(y_scaled[:window_size]).to(torch.float32)\n",
    "            label = torch.tensor(y_scaled[window_size:window_size+1]).to(torch.float32)\n",
    "            self.prices = np.append(self.prices, y[i+window_size:i+window_size+1][0])\n",
    "            out.append((window, label))\n",
    "        return out\n",
    "    \n",
    "    def fit(self, y, y_val):\n",
    "        y_train = self._preprocessor(y)\n",
    "        \n",
    "        epochs_wo_imp = 0\n",
    "        lowest_rmse = math.inf\n",
    "        val_rmse = math.inf\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for seq, y_hat in y_train:\n",
    "                self.optimiser.zero_grad()\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size), torch.zeros(1,1,self.hidden_size))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "                loss = self.criterion(y_hat[0], y_pred)\n",
    "                loss.backward() \n",
    "                self.optimiser.step()\n",
    "            \n",
    "            val_rmse = self.score(y_val)[0]\n",
    "            \n",
    "            if (epoch > 2):\n",
    "                if (val_rmse < lowest_rmse):\n",
    "                    best_model = copy.deepcopy(self)\n",
    "                    best_model.prices = np.append(best_model.prices, y_val)\n",
    "                    lowest_rmse = val_rmse\n",
    "                    epochs_wo_imp = 0\n",
    "                else:\n",
    "                    epochs_wo_imp += 1\n",
    "\n",
    "                if (epochs_wo_imp == EPOCHS_EARLY):\n",
    "                    return best_model, lowest_rmse\n",
    "            \n",
    "            print(f'Epoch: {epoch+1:2} Test Loss: {loss.item():10.8f} Val RMSE: {val_rmse}')\n",
    "            \n",
    "        return (best_model, lowest_rmse)\n",
    "                \n",
    "            \n",
    "    def predict(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            seq = torch.FloatTensor(scaler.fit_transform(self.prices[-self.window_size:].reshape(-1, 1)))\n",
    "            self.scaler = scaler\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self.scaler.inverse_transform(np.array(self(seq).item()).reshape(-1, 1)))\n",
    "        \n",
    "        predictions = self.prices[-future_instances:]\n",
    "        self.prices = self.prices[:-future_instances]\n",
    "        return predictions\n",
    "    \n",
    "    def predict_inplace(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            seq = torch.FloatTensor(scaler.fit_transform(self.prices[-self.window_size:].reshape(-1, 1)))\n",
    "            self.scaler = scaler\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self.scaler.inverse_transform(np.array(self(seq).item()).reshape(-1, 1)))\n",
    "        \n",
    "        predictions = self.prices[-future_instances:]\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, y):\n",
    "        y_pred = self.predict(len(y))\n",
    "        rmse = np.sqrt(np.mean(((np.array(y_pred)-np.array(y)))**2))\n",
    "        return rmse, y_pred\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
    "        pred = self.linear(lstm_out.view(len(seq),-1))\n",
    "        return pred[-1]\n",
    "    \n",
    "    \n",
    "def split_dataset(y, valid_proportion, test_proportion):\n",
    "\n",
    "    n_test = round(len(y) * test_proportion)\n",
    "    n_valid = round(len(y) * valid_proportion)\n",
    "    n_train = (len(y) - n_test) - n_valid\n",
    "    \n",
    "    y_train = y[:n_train]\n",
    "    y_valid = y[n_train:n_train + n_valid]\n",
    "    y_test = y[n_train + n_valid:]\n",
    "    \n",
    "    return (y_train, y_valid, y_test)\n",
    "\n",
    "\n",
    "def save_regressor(trained_model, zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to save the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with load_regressor\n",
    "    with open(str(zipcode) + '_model.pickle', 'wb') as target:\n",
    "        pickle.dump(trained_model, target)\n",
    "    print(f\"\\nSaved model in {zipcode}_model.pickle\\n\")\n",
    "\n",
    "\n",
    "def load_regressor(zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to load the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with save_regressor\n",
    "    with open(str(zipcode) + '_model.pickle', 'rb') as target:\n",
    "        trained_model = pickle.load(target)\n",
    "    print(f\"\\nLoaded model in {zipcode}_model.pickle\\n\")\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def hyperparameterSearch( window_sizes = [10, 20, 40, 80, 100], hidden_sizes = [10, 20, 40, 60, 80, 100, 150], zipcode = 91331, df = cal_df):\n",
    "    lowest_rmse = math.inf\n",
    "    val_rmse = math.inf\n",
    "    \n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        WINDOW_SIZE = window_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            HIDDEN_SIZE = hidden_size\n",
    "            \n",
    "            print(f\"Fitting for window_size of {WINDOW_SIZE} and hidden size of {HIDDEN_SIZE}\")\n",
    "            y = df.loc[zipcode]\n",
    "\n",
    "            y_train, y_valid, y_test = split_dataset(y, 0.1, 0.1)\n",
    "\n",
    "            model = LSTM(window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE)\n",
    "            model, val_rmse = model.fit(y_train, y_valid)\n",
    "            print(f\"Model trained for window_size of {model.window_size} and hidden size of {model.hidden_size}\")\n",
    "\n",
    "\n",
    "            if (val_rmse < lowest_rmse):\n",
    "                best_model = copy.deepcopy(model)\n",
    "                lowest_rmse = val_rmse\n",
    "                \n",
    "    save_regressor(best_model,zipcode)\n",
    "    return best_model\n",
    "\n",
    "def evaluate(zipcode, cal_df):\n",
    "    model = load_regressor(zipcode)\n",
    "    print(\"Window size:\", model.window_size, \"Hidden size:\", model.hidden_size)\n",
    "    y = cal_df.loc[zipcode]\n",
    "    y_train, y_valid, y_test = split_dataset(y, 0.1, 0.1)\n",
    "    test_rmse, y_preds = model.score(y_test)\n",
    "    print(\"RMSE:\", test_rmse)\n",
    "\n",
    "\n",
    "    plt.plot(np.append(model.prices, y_preds))\n",
    "    plt.plot(np.append(y_train, np.append(y_valid, y_test)))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    cal_df = PriceData(datapath).df\n",
    "    zip_codes = cal_df.index[10:11]\n",
    "    for zip_code in zip_codes:\n",
    "        print(f\"Training Model for ZipCode {zip_code}\")\n",
    "        hyperparameterSearch( window_sizes = [50], hidden_sizes = [100], zipcode = zip_code, df = cal_df)\n",
    "\n",
    "        print(f\"Evaluating Model for ZipCode {zip_code}\")\n",
    "        evaluate(zip_code, cal_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluating Model for ZipCode {zip_code}\")\n",
    "evaluate(zip_code, cal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
