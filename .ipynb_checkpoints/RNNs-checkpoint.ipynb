{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import math\n",
    "import copy\n",
    "\n",
    "#Path to datafile\n",
    "datapath = \"All_zip.csv\"\n",
    "WINDOW_SIZE = 50\n",
    "LEARNING_RATE = 0.000025\n",
    "N_EPOCHS = 200\n",
    "HIDDEN_SIZE = 100\n",
    "EPOCHS_EARLY = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "class PriceData():\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.df = self.generateDF(filename)\n",
    "\n",
    "    def generateDF(self, filename):\n",
    "        \n",
    "        def lat(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][0]\n",
    "\n",
    "        def long(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][1]\n",
    "\n",
    "        \n",
    "        orig_df = pd.read_csv(filename)\n",
    "        filtered_df = orig_df.loc[(orig_df['State'] == \"CA\")]\n",
    "        \n",
    "        \n",
    "\n",
    "        columns = filtered_df.columns\n",
    "        \n",
    "\n",
    "        cal_df = filtered_df \\\n",
    "            .dropna() \\\n",
    "            .drop(columns=columns[3:9]) \\\n",
    "            .drop(columns=columns[0:2]) \\\n",
    "            .rename(columns={'RegionName': 'ZipCode'}) \\\n",
    "            .reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        cal_df.set_index(\"ZipCode\", inplace = True)\n",
    "\n",
    "#         for zip_code in cal_df.index:\n",
    "#             print(zip_code)\n",
    "#             cal_df[\"windows\"] = cal_df.apply(lambda row: createBatches(row[\"prices\"]), axis = 1)\n",
    "        \n",
    "\n",
    "        return cal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size = 1, window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE, out_size = 1, learning_rate = LEARNING_RATE, epochs = N_EPOCHS):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        #Model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,out_size)\n",
    "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
    "        self.window_size = None\n",
    "        self.prices = None\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        #Data processing\n",
    "        self.scaler = None\n",
    "        \n",
    "        #Training parameters\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        \n",
    "        #Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def _preprocessor(self, ySeries):\n",
    "        y = ySeries.values\n",
    "\n",
    "        \n",
    "        \n",
    "        window_size = self.window_size\n",
    "\n",
    "        out = []\n",
    "        self.prices = y[:window_size].reshape(window_size)\n",
    "        for i in range(len(y) - window_size):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            y_scaled = scaler.fit_transform(y[i:i+window_size+1].reshape(-1, 1))\n",
    "            self.scaler = scaler\n",
    "            window = torch.tensor(y_scaled[:window_size]).to(torch.float32)\n",
    "            label = torch.tensor(y_scaled[window_size:window_size+1]).to(torch.float32)\n",
    "            self.prices = np.append(self.prices, y[i+window_size:i+window_size+1][0])\n",
    "            out.append((window, label))\n",
    "        return out\n",
    "    \n",
    "    def fit(self, y, y_val):\n",
    "        y_train = self._preprocessor(y)\n",
    "        \n",
    "        epochs_wo_imp = 0\n",
    "        lowest_rmse = math.inf\n",
    "        val_rmse = math.inf\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for seq, y_hat in y_train:\n",
    "                self.optimiser.zero_grad()\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size), torch.zeros(1,1,self.hidden_size))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "                loss = self.criterion(y_hat[0], y_pred)\n",
    "                loss.backward() \n",
    "                self.optimiser.step()\n",
    "            \n",
    "            val_rmse = self.score(y_val)[0]\n",
    "            \n",
    "            if (val_rmse < lowest_rmse):\n",
    "                best_model = copy.deepcopy(self)\n",
    "                best_model.prices = np.append(best_model.prices, y_val)\n",
    "                lowest_rmse = val_rmse\n",
    "                epochs_wo_imp = 0\n",
    "            else:\n",
    "                epochs_wo_imp += 1\n",
    "                \n",
    "            if (epochs_wo_imp == EPOCHS_EARLY):\n",
    "                return best_model, lowest_rmse\n",
    "            \n",
    "            print(f'Epoch: {epoch+1:2} Test Loss: {loss.item():10.8f} Val RMSE: {val_rmse}')\n",
    "            \n",
    "        return (best_model, lowest_rmse)\n",
    "                \n",
    "            \n",
    "    def predict(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            seq = torch.FloatTensor(scaler.fit_transform(self.prices[-self.window_size:].reshape(-1, 1)))\n",
    "            self.scaler = scaler\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self.scaler.inverse_transform(np.array(self(seq).item()).reshape(-1, 1)))\n",
    "        \n",
    "        predictions = self.prices[-future_instances:]\n",
    "        self.prices = self.prices[:-future_instances]\n",
    "        return predictions\n",
    "    \n",
    "    def predict_inplace(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            seq = torch.FloatTensor(scaler.fit_transform(self.prices[-self.window_size:].reshape(-1, 1)))\n",
    "            self.scaler = scaler\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self.scaler.inverse_transform(np.array(self(seq).item()).reshape(-1, 1)))\n",
    "        \n",
    "        predictions = self.prices[-future_instances:]\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, y):\n",
    "        y_pred = self.predict(len(y))\n",
    "        rmse = np.sqrt(np.mean(((np.array(y_pred)-np.array(y)))**2))\n",
    "        return rmse, y_pred\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
    "        pred = self.linear(lstm_out.view(len(seq),-1))\n",
    "        return pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(y, valid_proportion, test_proportion):\n",
    "\n",
    "   \n",
    "    \n",
    "    n_test = round(len(y) * test_proportion)\n",
    "    n_valid = round(len(y) * valid_proportion)\n",
    "    n_train = (len(y) - n_test) - n_valid\n",
    "    \n",
    "    y_train = y[:n_train]\n",
    "    y_valid = y[n_train:n_train + n_valid]\n",
    "    y_test = y[n_train + n_valid:]\n",
    "    \n",
    "    return (y_train, y_valid, y_test)\n",
    "\n",
    "\n",
    "def save_regressor(trained_model, zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to save the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with load_regressor\n",
    "    with open(str(zipcode) + '_model.pickle', 'wb') as target:\n",
    "        pickle.dump(trained_model, target)\n",
    "    print(f\"\\nSaved model in {zipcode}_model.pickle\\n\")\n",
    "\n",
    "\n",
    "def load_regressor(zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to load the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with save_regressor\n",
    "    with open(str(zipcode) + '_model.pickle', 'rb') as target:\n",
    "        trained_model = pickle.load(target)\n",
    "    print(f\"\\nLoaded model in {zipcode}_model.pickle\\n\")\n",
    "    return trained_model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for ZipCode 91331\n",
      "Fitting for window_size of 10 and hidden size of 10\n",
      "Epoch:  1 Test Loss: 0.54288834 Val RMSE: 53803.49783892542\n",
      "Epoch:  2 Test Loss: 0.50027466 Val RMSE: 52416.04993946533\n",
      "Epoch:  3 Test Loss: 0.45984966 Val RMSE: 51060.538186458514\n",
      "Epoch:  4 Test Loss: 0.42151058 Val RMSE: 49739.28999504545\n",
      "Epoch:  5 Test Loss: 0.38514471 Val RMSE: 48458.85692610428\n",
      "Epoch:  6 Test Loss: 0.35064951 Val RMSE: 47218.17037789746\n",
      "Epoch:  7 Test Loss: 0.31793797 Val RMSE: 46010.99460238595\n",
      "Epoch:  8 Test Loss: 0.28696826 Val RMSE: 44852.39534790395\n",
      "Epoch:  9 Test Loss: 0.25776991 Val RMSE: 43740.71303747185\n",
      "Epoch: 10 Test Loss: 0.23044603 Val RMSE: 42677.693999607654\n",
      "Epoch: 11 Test Loss: 0.20513573 Val RMSE: 41670.63316118327\n",
      "Epoch: 12 Test Loss: 0.18196914 Val RMSE: 40749.11147209886\n",
      "Epoch: 13 Test Loss: 0.16103907 Val RMSE: 39903.35058080892\n",
      "Epoch: 14 Test Loss: 0.14238365 Val RMSE: 39136.58976230024\n",
      "Epoch: 15 Test Loss: 0.12597829 Val RMSE: 38457.73527090033\n",
      "Epoch: 16 Test Loss: 0.11173408 Val RMSE: 37860.60518835761\n",
      "Epoch: 17 Test Loss: 0.09950799 Val RMSE: 37341.43220629809\n",
      "Epoch: 18 Test Loss: 0.08911688 Val RMSE: 36897.07904134598\n",
      "Epoch: 19 Test Loss: 0.08035526 Val RMSE: 36526.10642357036\n",
      "Epoch: 20 Test Loss: 0.07301040 Val RMSE: 36212.68604501343\n",
      "Epoch: 21 Test Loss: 0.06687643 Val RMSE: 35948.64111931476\n",
      "Epoch: 22 Test Loss: 0.06176320 Val RMSE: 35726.821635124266\n",
      "Epoch: 23 Test Loss: 0.05750131 Val RMSE: 35540.638112135304\n",
      "Epoch: 24 Test Loss: 0.05394401 Val RMSE: 35384.48446389143\n",
      "Epoch: 25 Test Loss: 0.05096628 Val RMSE: 35253.076658992235\n",
      "Epoch: 26 Test Loss: 0.04846353 Val RMSE: 35142.021961973805\n",
      "Epoch: 27 Test Loss: 0.04634874 Val RMSE: 35047.71759483835\n",
      "Epoch: 28 Test Loss: 0.04455037 Val RMSE: 34967.18057274029\n",
      "Epoch: 29 Test Loss: 0.04300975 Val RMSE: 34897.93014124895\n",
      "Epoch: 30 Test Loss: 0.04167852 Val RMSE: 34837.965937125824\n",
      "Epoch: 31 Test Loss: 0.04051738 Val RMSE: 34785.826513847256\n",
      "Epoch: 32 Test Loss: 0.03949385 Val RMSE: 34739.82033323462\n",
      "Epoch: 33 Test Loss: 0.03858134 Val RMSE: 34698.81646998434\n",
      "Epoch: 34 Test Loss: 0.03775803 Val RMSE: 34661.88641662119\n",
      "Epoch: 35 Test Loss: 0.03700583 Val RMSE: 34628.26055858283\n",
      "Epoch: 36 Test Loss: 0.03630979 Val RMSE: 34597.308155483086\n",
      "Epoch: 37 Test Loss: 0.03565736 Val RMSE: 34568.50440640758\n",
      "Epoch: 38 Test Loss: 0.03503807 Val RMSE: 34541.41988254962\n",
      "Epoch: 39 Test Loss: 0.03444282 Val RMSE: 34515.6913320481\n",
      "Epoch: 40 Test Loss: 0.03386421 Val RMSE: 34491.0867847947\n",
      "Epoch: 41 Test Loss: 0.03329533 Val RMSE: 34467.30638905442\n",
      "Epoch: 42 Test Loss: 0.03273019 Val RMSE: 34444.150114620854\n",
      "Epoch: 43 Test Loss: 0.03216365 Val RMSE: 34421.47118787195\n",
      "Epoch: 44 Test Loss: 0.03159095 Val RMSE: 34399.15865556632\n",
      "Epoch: 45 Test Loss: 0.03100763 Val RMSE: 34377.137273840104\n",
      "Epoch: 46 Test Loss: 0.03040955 Val RMSE: 34355.36913884951\n",
      "Epoch: 47 Test Loss: 0.02979293 Val RMSE: 34333.855106400515\n",
      "Epoch: 48 Test Loss: 0.02915449 Val RMSE: 34312.65830751722\n",
      "Epoch: 49 Test Loss: 0.02849066 Val RMSE: 34291.86061488913\n",
      "Epoch: 50 Test Loss: 0.02779847 Val RMSE: 34272.50926084437\n",
      "Epoch: 51 Test Loss: 0.02707543 Val RMSE: 34254.34788331645\n",
      "Epoch: 52 Test Loss: 0.02631935 Val RMSE: 34237.31338128269\n",
      "Epoch: 53 Test Loss: 0.02552880 Val RMSE: 34221.68661255463\n",
      "Epoch: 54 Test Loss: 0.02470271 Val RMSE: 34207.94007111968\n",
      "Epoch: 55 Test Loss: 0.02384046 Val RMSE: 34197.41851871991\n",
      "Epoch: 56 Test Loss: 0.02294195 Val RMSE: 34190.36181051607\n",
      "Epoch: 57 Test Loss: 0.02200719 Val RMSE: 34186.996569662726\n",
      "Epoch: 58 Test Loss: 0.02103647 Val RMSE: 34187.82648358516\n",
      "Epoch: 59 Test Loss: 0.02003092 Val RMSE: 34195.38560575602\n",
      "Epoch: 60 Test Loss: 0.01899174 Val RMSE: 34212.924751952094\n",
      "Epoch: 61 Test Loss: 0.01792113 Val RMSE: 34239.99605063872\n",
      "Epoch: 62 Test Loss: 0.01682208 Val RMSE: 34277.33759073762\n",
      "Epoch: 63 Test Loss: 0.01569861 Val RMSE: 34324.598107308404\n",
      "Epoch: 64 Test Loss: 0.01455549 Val RMSE: 34381.84878551493\n",
      "Epoch: 65 Test Loss: 0.01339858 Val RMSE: 34449.980388418735\n",
      "Epoch: 66 Test Loss: 0.01223475 Val RMSE: 34529.24488760659\n",
      "Epoch: 67 Test Loss: 0.01107239 Val RMSE: 34621.1036840026\n",
      "Epoch: 68 Test Loss: 0.00992117 Val RMSE: 34725.19738299269\n",
      "Epoch: 69 Test Loss: 0.00879233 Val RMSE: 34847.64224780684\n",
      "Epoch: 70 Test Loss: 0.00769803 Val RMSE: 34981.79532248789\n",
      "Epoch: 71 Test Loss: 0.00665059 Val RMSE: 35025.35904241215\n",
      "Epoch: 72 Test Loss: 0.00566164 Val RMSE: 35048.29868542911\n",
      "Epoch: 73 Test Loss: 0.00474175 Val RMSE: 35088.81072888912\n",
      "Epoch: 74 Test Loss: 0.00389954 Val RMSE: 35143.68944853859\n",
      "Epoch: 75 Test Loss: 0.00314157 Val RMSE: 35188.42869352419\n",
      "Epoch: 76 Test Loss: 0.00247192 Val RMSE: 35161.98788902969\n",
      "Model trained for window_size of 10 and hidden size of 10\n",
      "Fitting for window_size of 10 and hidden size of 20\n",
      "Epoch:  1 Test Loss: 1.37500811 Val RMSE: 497193.3368769926\n",
      "Epoch:  2 Test Loss: 1.29879940 Val RMSE: 273387.5048431982\n",
      "Epoch:  3 Test Loss: 1.21442866 Val RMSE: 156998.62644662292\n",
      "Epoch:  4 Test Loss: 1.11650681 Val RMSE: 98033.71579215796\n",
      "Epoch:  5 Test Loss: 0.99623537 Val RMSE: 68303.17564016947\n",
      "Epoch:  6 Test Loss: 0.84011096 Val RMSE: 62585.51932940676\n",
      "Epoch:  7 Test Loss: 0.63397038 Val RMSE: 56829.399638050054\n",
      "Epoch:  8 Test Loss: 0.39468992 Val RMSE: 48785.738706621596\n",
      "Epoch:  9 Test Loss: 0.20655721 Val RMSE: 41504.241236666574\n",
      "Epoch: 10 Test Loss: 0.11472673 Val RMSE: 37740.93073853541\n",
      "Epoch: 11 Test Loss: 0.07927496 Val RMSE: 36257.28601692886\n",
      "Epoch: 12 Test Loss: 0.06535164 Val RMSE: 35678.34536518628\n",
      "Epoch: 13 Test Loss: 0.05931480 Val RMSE: 35430.40901138609\n",
      "Epoch: 14 Test Loss: 0.05638876 Val RMSE: 35313.80499756076\n",
      "Epoch: 15 Test Loss: 0.05478723 Val RMSE: 35253.229917873316\n",
      "Epoch: 16 Test Loss: 0.05378423 Val RMSE: 35217.90864889203\n",
      "Epoch: 17 Test Loss: 0.05306552 Val RMSE: 35194.49857970969\n",
      "Epoch: 18 Test Loss: 0.05248713 Val RMSE: 35176.90027480847\n",
      "Epoch: 19 Test Loss: 0.05198092 Val RMSE: 35162.246157884154\n",
      "Epoch: 20 Test Loss: 0.05151244 Val RMSE: 35149.10829525556\n",
      "Epoch: 21 Test Loss: 0.05106413 Val RMSE: 35136.77658682626\n",
      "Epoch: 22 Test Loss: 0.05062614 Val RMSE: 35124.86722556688\n",
      "Epoch: 23 Test Loss: 0.05019228 Val RMSE: 35113.15273784803\n",
      "Epoch: 24 Test Loss: 0.04975853 Val RMSE: 35101.49583760896\n",
      "Epoch: 25 Test Loss: 0.04932206 Val RMSE: 35089.83913684988\n",
      "Epoch: 26 Test Loss: 0.04888022 Val RMSE: 35078.128752978555\n",
      "Epoch: 27 Test Loss: 0.04843068 Val RMSE: 35066.25876013048\n",
      "Epoch: 28 Test Loss: 0.04797117 Val RMSE: 35054.166483773624\n",
      "Epoch: 29 Test Loss: 0.04749970 Val RMSE: 35041.80989853413\n",
      "Epoch: 30 Test Loss: 0.04701407 Val RMSE: 35029.14251170807\n",
      "Epoch: 31 Test Loss: 0.04651200 Val RMSE: 35016.10557727056\n",
      "Epoch: 32 Test Loss: 0.04599100 Val RMSE: 35002.6393961831\n",
      "Epoch: 33 Test Loss: 0.04544866 Val RMSE: 34988.68243072968\n",
      "Epoch: 34 Test Loss: 0.04488254 Val RMSE: 34974.175551360226\n",
      "Epoch: 35 Test Loss: 0.04428968 Val RMSE: 34959.04050842482\n",
      "Epoch: 36 Test Loss: 0.04366694 Val RMSE: 34943.1936013372\n",
      "Epoch: 37 Test Loss: 0.04301096 Val RMSE: 34926.57481126147\n",
      "Epoch: 38 Test Loss: 0.04231785 Val RMSE: 34909.37427957163\n",
      "Epoch: 39 Test Loss: 0.04158356 Val RMSE: 34891.18910338294\n",
      "Epoch: 40 Test Loss: 0.04080375 Val RMSE: 34871.903702060576\n",
      "Epoch: 41 Test Loss: 0.03997380 Val RMSE: 34851.3755854531\n",
      "Epoch: 42 Test Loss: 0.03908851 Val RMSE: 34829.467968085715\n",
      "Epoch: 43 Test Loss: 0.03814274 Val RMSE: 34806.24661506151\n",
      "Epoch: 44 Test Loss: 0.03713142 Val RMSE: 34781.66378009625\n",
      "Epoch: 45 Test Loss: 0.03604874 Val RMSE: 34755.39957085945\n",
      "Epoch: 46 Test Loss: 0.03488956 Val RMSE: 34728.60406310676\n",
      "Epoch: 47 Test Loss: 0.03364821 Val RMSE: 34701.12320496141\n",
      "Epoch: 48 Test Loss: 0.03231984 Val RMSE: 34673.59001162299\n",
      "Epoch: 49 Test Loss: 0.03089905 Val RMSE: 34648.51054345112\n",
      "Epoch: 50 Test Loss: 0.02938140 Val RMSE: 34623.789465108675\n",
      "Epoch: 51 Test Loss: 0.02776279 Val RMSE: 34598.945573775774\n",
      "Epoch: 52 Test Loss: 0.02604177 Val RMSE: 34589.314702268945\n",
      "Epoch: 53 Test Loss: 0.02421953 Val RMSE: 34596.780212985715\n",
      "Epoch: 54 Test Loss: 0.02230077 Val RMSE: 34617.35594380723\n",
      "Epoch: 55 Test Loss: 0.02029459 Val RMSE: 34652.70327311524\n",
      "Epoch: 56 Test Loss: 0.01821478 Val RMSE: 34713.806583829246\n",
      "Epoch: 57 Test Loss: 0.01608101 Val RMSE: 34808.43623719811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 Test Loss: 0.01391969 Val RMSE: 34927.62240286275\n",
      "Epoch: 59 Test Loss: 0.01176443 Val RMSE: 35077.699457266455\n",
      "Epoch: 60 Test Loss: 0.00965686 Val RMSE: 35263.466137007876\n",
      "Epoch: 61 Test Loss: 0.00764596 Val RMSE: 35482.81765438434\n",
      "Epoch: 62 Test Loss: 0.00578538 Val RMSE: 35756.132850887356\n",
      "Epoch: 63 Test Loss: 0.00412864 Val RMSE: 36102.41715321133\n",
      "Epoch: 64 Test Loss: 0.00272293 Val RMSE: 36241.997887894206\n",
      "Epoch: 65 Test Loss: 0.00160311 Val RMSE: 36330.987082462525\n",
      "Epoch: 66 Test Loss: 0.00078660 Val RMSE: 36442.39938310546\n",
      "Epoch: 67 Test Loss: 0.00027021 Val RMSE: 36560.26908682617\n",
      "Epoch: 68 Test Loss: 0.00002960 Val RMSE: 36403.983009496784\n",
      "Epoch: 69 Test Loss: 0.00002252 Val RMSE: 36062.65164563662\n",
      "Epoch: 70 Test Loss: 0.00019499 Val RMSE: 35732.63836739863\n",
      "Epoch: 71 Test Loss: 0.00048901 Val RMSE: 35464.002212238134\n",
      "Model trained for window_size of 10 and hidden size of 20\n",
      "Fitting for window_size of 10 and hidden size of 40\n",
      "Epoch:  1 Test Loss: 0.49781933 Val RMSE: 52623.61777942974\n",
      "Epoch:  2 Test Loss: 0.41310307 Val RMSE: 49689.45972304977\n",
      "Epoch:  3 Test Loss: 0.31819344 Val RMSE: 46168.576097770245\n",
      "Epoch:  4 Test Loss: 0.21654321 Val RMSE: 42133.74556656008\n",
      "Epoch:  5 Test Loss: 0.13186377 Val RMSE: 38568.46852729965\n",
      "Epoch:  6 Test Loss: 0.08638290 Val RMSE: 36557.70276591435\n",
      "Epoch:  7 Test Loss: 0.06808729 Val RMSE: 35739.7903352828\n",
      "Epoch:  8 Test Loss: 0.06049650 Val RMSE: 35402.524200808075\n",
      "Epoch:  9 Test Loss: 0.05671911 Val RMSE: 35240.78560703705\n",
      "Epoch: 10 Test Loss: 0.05439932 Val RMSE: 35146.823477482445\n",
      "Epoch: 11 Test Loss: 0.05268253 Val RMSE: 35081.05199475626\n",
      "Epoch: 12 Test Loss: 0.05122534 Val RMSE: 35027.72893313555\n",
      "Epoch: 13 Test Loss: 0.04987723 Val RMSE: 34980.14915801297\n",
      "Epoch: 14 Test Loss: 0.04856745 Val RMSE: 34935.26627408942\n",
      "Epoch: 15 Test Loss: 0.04725603 Val RMSE: 34891.398329890806\n",
      "Epoch: 16 Test Loss: 0.04591620 Val RMSE: 34847.9012719203\n",
      "Epoch: 17 Test Loss: 0.04453017 Val RMSE: 34803.90475891081\n",
      "Epoch: 18 Test Loss: 0.04308600 Val RMSE: 34759.09373733239\n",
      "Epoch: 19 Test Loss: 0.04157437 Val RMSE: 34713.28404118439\n",
      "Epoch: 20 Test Loss: 0.03998543 Val RMSE: 34666.34652414254\n",
      "Epoch: 21 Test Loss: 0.03830891 Val RMSE: 34618.14374504234\n",
      "Epoch: 22 Test Loss: 0.03653311 Val RMSE: 34568.53532648177\n",
      "Epoch: 23 Test Loss: 0.03464586 Val RMSE: 34517.57495577643\n",
      "Epoch: 24 Test Loss: 0.03263498 Val RMSE: 34465.54437682859\n",
      "Epoch: 25 Test Loss: 0.03048851 Val RMSE: 34413.319330855964\n",
      "Epoch: 26 Test Loss: 0.02819592 Val RMSE: 34366.367825216876\n",
      "Epoch: 27 Test Loss: 0.02574913 Val RMSE: 34323.37092254501\n",
      "Epoch: 28 Test Loss: 0.02314452 Val RMSE: 34289.88889675524\n",
      "Epoch: 29 Test Loss: 0.02038650 Val RMSE: 34273.262732407304\n",
      "Epoch: 30 Test Loss: 0.01749260 Val RMSE: 34309.455551742256\n",
      "Epoch: 31 Test Loss: 0.01450116 Val RMSE: 34391.06339722887\n",
      "Epoch: 32 Test Loss: 0.01148114 Val RMSE: 34533.67257504419\n",
      "Epoch: 33 Test Loss: 0.00854077 Val RMSE: 34772.42145953789\n",
      "Epoch: 34 Test Loss: 0.00582704 Val RMSE: 34841.33392153857\n",
      "Epoch: 35 Test Loss: 0.00350655 Val RMSE: 34850.06680319238\n",
      "Epoch: 36 Test Loss: 0.00172683 Val RMSE: 34684.551751336854\n",
      "Epoch: 37 Test Loss: 0.00057473 Val RMSE: 34055.63807865894\n",
      "Epoch: 38 Test Loss: 0.00005112 Val RMSE: 33465.462584152665\n",
      "Epoch: 39 Test Loss: 0.00006794 Val RMSE: 32798.96533287202\n",
      "Epoch: 40 Test Loss: 0.00046762 Val RMSE: 32119.6822305477\n",
      "Epoch: 41 Test Loss: 0.00106466 Val RMSE: 31710.817852460717\n",
      "Epoch: 42 Test Loss: 0.00169619 Val RMSE: 31428.23347350799\n",
      "Epoch: 43 Test Loss: 0.00225482 Val RMSE: 31281.488194223217\n",
      "Epoch: 44 Test Loss: 0.00269118 Val RMSE: 31043.915739173153\n",
      "Epoch: 45 Test Loss: 0.00299708 Val RMSE: 30841.157462385876\n",
      "Epoch: 46 Test Loss: 0.00318621 Val RMSE: 30673.84834325682\n",
      "Epoch: 47 Test Loss: 0.00328010 Val RMSE: 30491.413019563075\n",
      "Epoch: 48 Test Loss: 0.00330069 Val RMSE: 30288.383139991343\n",
      "Epoch: 49 Test Loss: 0.00326698 Val RMSE: 30031.67452692823\n",
      "Epoch: 50 Test Loss: 0.00319439 Val RMSE: 29774.62716650972\n",
      "Epoch: 51 Test Loss: 0.00309472 Val RMSE: 29373.807072574415\n",
      "Epoch: 52 Test Loss: 0.00297702 Val RMSE: 28894.557280425735\n",
      "Epoch: 53 Test Loss: 0.00284812 Val RMSE: 28704.12699677592\n",
      "Epoch: 54 Test Loss: 0.00271310 Val RMSE: 28496.67813056775\n",
      "Epoch: 55 Test Loss: 0.00257578 Val RMSE: 28298.394263054604\n",
      "Epoch: 56 Test Loss: 0.00243905 Val RMSE: 28184.289038975272\n",
      "Epoch: 57 Test Loss: 0.00230496 Val RMSE: 28089.431589196916\n",
      "Epoch: 58 Test Loss: 0.00217509 Val RMSE: 28007.72839547082\n",
      "Epoch: 59 Test Loss: 0.00205052 Val RMSE: 27937.515360160894\n",
      "Epoch: 60 Test Loss: 0.00193199 Val RMSE: 27859.367100277173\n",
      "Epoch: 61 Test Loss: 0.00181997 Val RMSE: 27784.143789923117\n",
      "Epoch: 62 Test Loss: 0.00171468 Val RMSE: 27725.08122621129\n",
      "Epoch: 63 Test Loss: 0.00161616 Val RMSE: 27677.733831301208\n",
      "Epoch: 64 Test Loss: 0.00152443 Val RMSE: 27638.16980103826\n",
      "Epoch: 65 Test Loss: 0.00143923 Val RMSE: 27605.33237196897\n",
      "Epoch: 66 Test Loss: 0.00136037 Val RMSE: 27565.22655427754\n",
      "Epoch: 67 Test Loss: 0.00128759 Val RMSE: 27529.754805450346\n",
      "Epoch: 68 Test Loss: 0.00122051 Val RMSE: 27500.672309446145\n",
      "Epoch: 69 Test Loss: 0.00115883 Val RMSE: 27477.203052918074\n",
      "Epoch: 70 Test Loss: 0.00110221 Val RMSE: 27458.577663583295\n",
      "Epoch: 71 Test Loss: 0.00105026 Val RMSE: 27444.268346208264\n",
      "Epoch: 72 Test Loss: 0.00100268 Val RMSE: 27432.15476154034\n",
      "Epoch: 73 Test Loss: 0.00095912 Val RMSE: 27415.846922717334\n",
      "Epoch: 74 Test Loss: 0.00091928 Val RMSE: 27379.505282058977\n",
      "Epoch: 75 Test Loss: 0.00088283 Val RMSE: 27342.381524457247\n",
      "Epoch: 76 Test Loss: 0.00084953 Val RMSE: 27313.383784636877\n",
      "Epoch: 77 Test Loss: 0.00081908 Val RMSE: 27291.770126479503\n",
      "Epoch: 78 Test Loss: 0.00079127 Val RMSE: 27276.616237670474\n",
      "Epoch: 79 Test Loss: 0.00076585 Val RMSE: 27267.314321804093\n",
      "Epoch: 80 Test Loss: 0.00074260 Val RMSE: 27263.24206643989\n",
      "Epoch: 81 Test Loss: 0.00072136 Val RMSE: 27263.82715721946\n",
      "Epoch: 82 Test Loss: 0.00070193 Val RMSE: 27268.71292318262\n",
      "Epoch: 83 Test Loss: 0.00068418 Val RMSE: 27277.214111082583\n",
      "Epoch: 84 Test Loss: 0.00066791 Val RMSE: 27289.218777936247\n",
      "Epoch: 85 Test Loss: 0.00065303 Val RMSE: 27304.182271598656\n",
      "Epoch: 86 Test Loss: 0.00063940 Val RMSE: 27321.886278067217\n",
      "Epoch: 87 Test Loss: 0.00062691 Val RMSE: 27341.987555397027\n",
      "Epoch: 88 Test Loss: 0.00061546 Val RMSE: 27364.356871686305\n",
      "Epoch: 89 Test Loss: 0.00060496 Val RMSE: 27388.579021035894\n",
      "Epoch: 90 Test Loss: 0.00059533 Val RMSE: 27414.579375173176\n",
      "Epoch: 91 Test Loss: 0.00058647 Val RMSE: 27442.23745339391\n",
      "Epoch: 92 Test Loss: 0.00057835 Val RMSE: 27473.21999392733\n",
      "Epoch: 93 Test Loss: 0.00057086 Val RMSE: 27507.076203085977\n",
      "Epoch: 94 Test Loss: 0.00056398 Val RMSE: 27542.13012277999\n",
      "Epoch: 95 Test Loss: 0.00055765 Val RMSE: 27578.173311903814\n",
      "Epoch: 96 Test Loss: 0.00055179 Val RMSE: 27615.28004975066\n",
      "Epoch: 97 Test Loss: 0.00054641 Val RMSE: 27653.096081210366\n",
      "Epoch: 98 Test Loss: 0.00054144 Val RMSE: 27691.661362482195\n",
      "Epoch: 99 Test Loss: 0.00053684 Val RMSE: 27721.572347563182\n",
      "Model trained for window_size of 10 and hidden size of 40\n",
      "Fitting for window_size of 10 and hidden size of 60\n",
      "Epoch:  1 Test Loss: 0.67047715 Val RMSE: 57943.02503470545\n",
      "Epoch:  2 Test Loss: 0.51537174 Val RMSE: 53078.740982806594\n",
      "Epoch:  3 Test Loss: 0.30599511 Val RMSE: 45444.06533448219\n",
      "Epoch:  4 Test Loss: 0.12903796 Val RMSE: 38229.228178855235\n",
      "Epoch:  5 Test Loss: 0.07896051 Val RMSE: 36101.065142760635\n",
      "Epoch:  6 Test Loss: 0.06829885 Val RMSE: 35675.24644157817\n",
      "Epoch:  7 Test Loss: 0.06389178 Val RMSE: 35519.072988754946\n",
      "Epoch:  8 Test Loss: 0.06092025 Val RMSE: 35424.35785188006\n",
      "Epoch:  9 Test Loss: 0.05837723 Val RMSE: 35348.1050803915\n",
      "Epoch: 10 Test Loss: 0.05595657 Val RMSE: 35277.71398272422\n",
      "Epoch: 11 Test Loss: 0.05352713 Val RMSE: 35208.3156858452\n",
      "Epoch: 12 Test Loss: 0.05101139 Val RMSE: 35137.09986223485\n",
      "Epoch: 13 Test Loss: 0.04834799 Val RMSE: 35061.981917073026\n",
      "Epoch: 14 Test Loss: 0.04547779 Val RMSE: 34981.38948212295\n",
      "Epoch: 15 Test Loss: 0.04233637 Val RMSE: 34894.460006586596\n",
      "Epoch: 16 Test Loss: 0.03885007 Val RMSE: 34798.857880472264\n",
      "Epoch: 17 Test Loss: 0.03493630 Val RMSE: 34693.68099550426\n",
      "Epoch: 18 Test Loss: 0.03051495 Val RMSE: 34585.85598683927\n",
      "Epoch: 19 Test Loss: 0.02554208 Val RMSE: 34485.90948190916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Test Loss: 0.02007427 Val RMSE: 34453.30700682975\n",
      "Epoch: 21 Test Loss: 0.01435105 Val RMSE: 34568.794153366005\n",
      "Epoch: 22 Test Loss: 0.00885230 Val RMSE: 34822.524071585\n",
      "Epoch: 23 Test Loss: 0.00425539 Val RMSE: 35263.408117173225\n",
      "Epoch: 24 Test Loss: 0.00121712 Val RMSE: 35430.22771144594\n",
      "Epoch: 25 Test Loss: 0.00003029 Val RMSE: 35192.37378772701\n",
      "Epoch: 26 Test Loss: 0.00041311 Val RMSE: 34231.96993375574\n",
      "Epoch: 27 Test Loss: 0.00166319 Val RMSE: 33501.01193134094\n",
      "Epoch: 28 Test Loss: 0.00307242 Val RMSE: 33053.203788445506\n",
      "Epoch: 29 Test Loss: 0.00422566 Val RMSE: 32801.01548782108\n",
      "Epoch: 30 Test Loss: 0.00499607 Val RMSE: 32687.13303601007\n",
      "Epoch: 31 Test Loss: 0.00540687 Val RMSE: 32630.793068602692\n",
      "Epoch: 32 Test Loss: 0.00552991 Val RMSE: 32428.264976648632\n",
      "Epoch: 33 Test Loss: 0.00544021 Val RMSE: 32232.11438659309\n",
      "Epoch: 34 Test Loss: 0.00520062 Val RMSE: 32094.805962855124\n",
      "Epoch: 35 Test Loss: 0.00485962 Val RMSE: 32028.847453719543\n",
      "Epoch: 36 Test Loss: 0.00445387 Val RMSE: 31986.617402463828\n",
      "Epoch: 37 Test Loss: 0.00401210 Val RMSE: 31947.142083837312\n",
      "Epoch: 38 Test Loss: 0.00355758 Val RMSE: 31882.89770039825\n",
      "Epoch: 39 Test Loss: 0.00310947 Val RMSE: 31795.236388577327\n",
      "Epoch: 40 Test Loss: 0.00268320 Val RMSE: 31725.272967988494\n",
      "Epoch: 41 Test Loss: 0.00229038 Val RMSE: 31620.13552783576\n",
      "Epoch: 42 Test Loss: 0.00193846 Val RMSE: 31464.73274781428\n",
      "Epoch: 43 Test Loss: 0.00163112 Val RMSE: 31309.113692556995\n",
      "Epoch: 44 Test Loss: 0.00136853 Val RMSE: 31207.61114433053\n",
      "Epoch: 45 Test Loss: 0.00114833 Val RMSE: 31120.449699929002\n",
      "Epoch: 46 Test Loss: 0.00096647 Val RMSE: 31037.511061343434\n",
      "Epoch: 47 Test Loss: 0.00081807 Val RMSE: 30970.321452944783\n",
      "Epoch: 48 Test Loss: 0.00069809 Val RMSE: 30916.71131613373\n",
      "Epoch: 49 Test Loss: 0.00060171 Val RMSE: 30874.91184005685\n",
      "Epoch: 50 Test Loss: 0.00052466 Val RMSE: 30845.102201800357\n",
      "Epoch: 51 Test Loss: 0.00046322 Val RMSE: 30824.666462788824\n",
      "Epoch: 52 Test Loss: 0.00041434 Val RMSE: 30812.035096803123\n",
      "Epoch: 53 Test Loss: 0.00037550 Val RMSE: 30806.37576788862\n",
      "Epoch: 54 Test Loss: 0.00034468 Val RMSE: 30806.960707389273\n",
      "Epoch: 55 Test Loss: 0.00032026 Val RMSE: 30813.092586575083\n",
      "Epoch: 56 Test Loss: 0.00030097 Val RMSE: 30824.763886536195\n",
      "Epoch: 57 Test Loss: 0.00028579 Val RMSE: 30842.020536046035\n",
      "Epoch: 58 Test Loss: 0.00027391 Val RMSE: 30863.11586419226\n",
      "Epoch: 59 Test Loss: 0.00026470 Val RMSE: 30887.225077854728\n",
      "Epoch: 60 Test Loss: 0.00025766 Val RMSE: 30913.865050728153\n",
      "Epoch: 61 Test Loss: 0.00025238 Val RMSE: 30942.645198012226\n",
      "Epoch: 62 Test Loss: 0.00024853 Val RMSE: 30973.21689520554\n",
      "Epoch: 63 Test Loss: 0.00024585 Val RMSE: 31005.246119398886\n",
      "Epoch: 64 Test Loss: 0.00024413 Val RMSE: 31036.269077604775\n",
      "Epoch: 65 Test Loss: 0.00024320 Val RMSE: 31070.348978134083\n",
      "Epoch: 66 Test Loss: 0.00024291 Val RMSE: 31104.94939285459\n",
      "Epoch: 67 Test Loss: 0.00024315 Val RMSE: 31140.004407742294\n",
      "Epoch: 68 Test Loss: 0.00024382 Val RMSE: 31175.410364633157\n",
      "Epoch: 69 Test Loss: 0.00024485 Val RMSE: 31211.120849687773\n",
      "Epoch: 70 Test Loss: 0.00024616 Val RMSE: 31247.040500299427\n",
      "Epoch: 71 Test Loss: 0.00024770 Val RMSE: 31283.115502773377\n",
      "Epoch: 72 Test Loss: 0.00024943 Val RMSE: 31319.35134176343\n",
      "Model trained for window_size of 10 and hidden size of 60\n",
      "Fitting for window_size of 10 and hidden size of 80\n",
      "Epoch:  1 Test Loss: 0.72634870 Val RMSE: 59444.01652177181\n",
      "Epoch:  2 Test Loss: 0.53522623 Val RMSE: 53581.03435415003\n",
      "Epoch:  3 Test Loss: 0.27614179 Val RMSE: 44017.11507517884\n",
      "Epoch:  4 Test Loss: 0.11321756 Val RMSE: 37272.330355183694\n",
      "Epoch:  5 Test Loss: 0.08588459 Val RMSE: 36179.59054397352\n",
      "Epoch:  6 Test Loss: 0.07655179 Val RMSE: 35867.678693672286\n",
      "Epoch:  7 Test Loss: 0.07020124 Val RMSE: 35682.44900804256\n",
      "Epoch:  8 Test Loss: 0.06462821 Val RMSE: 35529.79631376746\n",
      "Epoch:  9 Test Loss: 0.05920215 Val RMSE: 35384.41993620397\n",
      "Epoch: 10 Test Loss: 0.05364430 Val RMSE: 35236.22766419552\n",
      "Epoch: 11 Test Loss: 0.04778689 Val RMSE: 35079.216052523494\n",
      "Epoch: 12 Test Loss: 0.04151543 Val RMSE: 34912.03673587328\n",
      "Epoch: 13 Test Loss: 0.03476758 Val RMSE: 34736.60413943663\n",
      "Epoch: 14 Test Loss: 0.02756851 Val RMSE: 34574.14200692918\n",
      "Epoch: 15 Test Loss: 0.02010512 Val RMSE: 34494.51501065869\n",
      "Epoch: 16 Test Loss: 0.01282828 Val RMSE: 34657.69409747013\n",
      "Epoch: 17 Test Loss: 0.00650302 Val RMSE: 35008.01434735588\n",
      "Epoch: 18 Test Loss: 0.00205223 Val RMSE: 35389.31132362586\n",
      "Epoch: 19 Test Loss: 0.00010090 Val RMSE: 35204.35325019876\n",
      "Epoch: 20 Test Loss: 0.00045861 Val RMSE: 33876.32051730357\n",
      "Epoch: 21 Test Loss: 0.00211453 Val RMSE: 32920.335293640586\n",
      "Epoch: 22 Test Loss: 0.00394338 Val RMSE: 32386.72493200364\n",
      "Epoch: 23 Test Loss: 0.00534587 Val RMSE: 32205.318104512477\n",
      "Epoch: 24 Test Loss: 0.00620615 Val RMSE: 32046.100727543693\n",
      "Epoch: 25 Test Loss: 0.00660008 Val RMSE: 31978.570334626558\n",
      "Epoch: 26 Test Loss: 0.00664821 Val RMSE: 32030.315861836603\n",
      "Epoch: 27 Test Loss: 0.00646696 Val RMSE: 32084.783521201127\n",
      "Epoch: 28 Test Loss: 0.00614795 Val RMSE: 32135.473413052096\n",
      "Epoch: 29 Test Loss: 0.00575378 Val RMSE: 32163.775406132732\n",
      "Epoch: 30 Test Loss: 0.00532383 Val RMSE: 32174.53677570376\n",
      "Epoch: 31 Test Loss: 0.00488190 Val RMSE: 32170.325391961873\n",
      "Epoch: 32 Test Loss: 0.00444266 Val RMSE: 32128.97053645592\n",
      "Epoch: 33 Test Loss: 0.00401556 Val RMSE: 32049.73355469625\n",
      "Epoch: 34 Test Loss: 0.00360732 Val RMSE: 31960.91096921958\n",
      "Epoch: 35 Test Loss: 0.00322295 Val RMSE: 31887.696297039965\n",
      "Epoch: 36 Test Loss: 0.00286621 Val RMSE: 31821.75072700549\n",
      "Epoch: 37 Test Loss: 0.00253987 Val RMSE: 31763.33841558523\n",
      "Epoch: 38 Test Loss: 0.00224556 Val RMSE: 31712.628531953604\n",
      "Epoch: 39 Test Loss: 0.00198383 Val RMSE: 31669.28013323599\n",
      "Epoch: 40 Test Loss: 0.00175419 Val RMSE: 31634.953511301454\n",
      "Epoch: 41 Test Loss: 0.00155518 Val RMSE: 31555.97039762177\n",
      "Epoch: 42 Test Loss: 0.00138465 Val RMSE: 31486.79962830024\n",
      "Epoch: 43 Test Loss: 0.00123995 Val RMSE: 31426.585045358544\n",
      "Epoch: 44 Test Loss: 0.00111817 Val RMSE: 31374.589114500046\n",
      "Epoch: 45 Test Loss: 0.00101636 Val RMSE: 31330.17800569254\n",
      "Epoch: 46 Test Loss: 0.00093167 Val RMSE: 31292.709165741155\n",
      "Epoch: 47 Test Loss: 0.00086151 Val RMSE: 31249.727884032407\n",
      "Epoch: 48 Test Loss: 0.00080353 Val RMSE: 31211.50201519199\n",
      "Epoch: 49 Test Loss: 0.00075570 Val RMSE: 31180.716530679194\n",
      "Epoch: 50 Test Loss: 0.00071629 Val RMSE: 31156.74756399616\n",
      "Epoch: 51 Test Loss: 0.00068383 Val RMSE: 31139.004201181535\n",
      "Epoch: 52 Test Loss: 0.00065709 Val RMSE: 31126.800951673777\n",
      "Epoch: 53 Test Loss: 0.00063506 Val RMSE: 31119.540917679835\n",
      "Epoch: 54 Test Loss: 0.00061689 Val RMSE: 31116.631082535514\n",
      "Epoch: 55 Test Loss: 0.00060190 Val RMSE: 31117.48846057746\n",
      "Epoch: 56 Test Loss: 0.00058952 Val RMSE: 31121.627698584314\n",
      "Epoch: 57 Test Loss: 0.00057927 Val RMSE: 31128.57026318005\n",
      "Epoch: 58 Test Loss: 0.00057077 Val RMSE: 31138.002437960386\n",
      "Epoch: 59 Test Loss: 0.00056371 Val RMSE: 31149.470349266223\n",
      "Epoch: 60 Test Loss: 0.00055784 Val RMSE: 31162.587308403625\n",
      "Epoch: 61 Test Loss: 0.00055293 Val RMSE: 31177.083646685944\n",
      "Epoch: 62 Test Loss: 0.00054882 Val RMSE: 31192.730127036273\n",
      "Epoch: 63 Test Loss: 0.00054536 Val RMSE: 31209.305575873288\n",
      "Epoch: 64 Test Loss: 0.00054241 Val RMSE: 31226.67884782028\n",
      "Epoch: 65 Test Loss: 0.00053991 Val RMSE: 31244.67116737511\n",
      "Epoch: 66 Test Loss: 0.00053777 Val RMSE: 31263.17749786132\n",
      "Epoch: 67 Test Loss: 0.00053590 Val RMSE: 31282.719056515194\n",
      "Epoch: 68 Test Loss: 0.00053428 Val RMSE: 31303.139207080447\n",
      "Epoch: 69 Test Loss: 0.00053283 Val RMSE: 31323.88839521921\n",
      "Epoch: 70 Test Loss: 0.00053155 Val RMSE: 31344.80531805268\n",
      "Epoch: 71 Test Loss: 0.00053039 Val RMSE: 31365.825804766322\n",
      "Epoch: 72 Test Loss: 0.00052932 Val RMSE: 31386.96083984375\n",
      "Epoch: 73 Test Loss: 0.00052834 Val RMSE: 31408.12804103732\n",
      "Model trained for window_size of 10 and hidden size of 80\n",
      "Fitting for window_size of 10 and hidden size of 100\n",
      "Epoch:  1 Test Loss: 0.66325635 Val RMSE: 57641.265589700335\n",
      "Epoch:  2 Test Loss: 0.40916765 Val RMSE: 49189.90840662475\n",
      "Epoch:  3 Test Loss: 0.12797043 Val RMSE: 38040.831657273586\n",
      "Epoch:  4 Test Loss: 0.08430812 Val RMSE: 36250.804175889076\n",
      "Epoch:  5 Test Loss: 0.07549129 Val RMSE: 35932.980598126764\n",
      "Epoch:  6 Test Loss: 0.07056538 Val RMSE: 35775.07709798839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7 Test Loss: 0.06665197 Val RMSE: 35657.70329412074\n",
      "Epoch:  8 Test Loss: 0.06303789 Val RMSE: 35552.83397130359\n",
      "Epoch:  9 Test Loss: 0.05941722 Val RMSE: 35449.20967170489\n",
      "Epoch: 10 Test Loss: 0.05559086 Val RMSE: 35340.00309865827\n",
      "Epoch: 11 Test Loss: 0.05138844 Val RMSE: 35219.555696474716\n",
      "Epoch: 12 Test Loss: 0.04664468 Val RMSE: 35081.41605380744\n",
      "Epoch: 13 Test Loss: 0.04119417 Val RMSE: 34921.7879819793\n",
      "Epoch: 14 Test Loss: 0.03488135 Val RMSE: 34735.89820949756\n",
      "Epoch: 15 Test Loss: 0.02760890 Val RMSE: 34553.99770454303\n",
      "Epoch: 16 Test Loss: 0.01947960 Val RMSE: 34439.03647988288\n",
      "Epoch: 17 Test Loss: 0.01110714 Val RMSE: 34565.43968915745\n",
      "Epoch: 18 Test Loss: 0.00399465 Val RMSE: 34934.60407243185\n",
      "Epoch: 19 Test Loss: 0.00026309 Val RMSE: 35033.3616807676\n",
      "Epoch: 20 Test Loss: 0.00073101 Val RMSE: 33115.08299773251\n",
      "Epoch: 21 Test Loss: 0.00328781 Val RMSE: 31712.089871383305\n",
      "Epoch: 22 Test Loss: 0.00542578 Val RMSE: 31491.87102814283\n",
      "Epoch: 23 Test Loss: 0.00668190 Val RMSE: 31707.71494405684\n",
      "Epoch: 24 Test Loss: 0.00734178 Val RMSE: 31869.3008771903\n",
      "Epoch: 25 Test Loss: 0.00751033 Val RMSE: 31891.20260911687\n",
      "Epoch: 26 Test Loss: 0.00726846 Val RMSE: 31927.422660898083\n",
      "Epoch: 27 Test Loss: 0.00675434 Val RMSE: 31930.084288621554\n",
      "Epoch: 28 Test Loss: 0.00610357 Val RMSE: 31955.613539916816\n",
      "Epoch: 29 Test Loss: 0.00541144 Val RMSE: 32028.83045074704\n",
      "Epoch: 30 Test Loss: 0.00473416 Val RMSE: 32093.355000992397\n",
      "Epoch: 31 Test Loss: 0.00410166 Val RMSE: 32099.95314901956\n",
      "Epoch: 32 Test Loss: 0.00352858 Val RMSE: 32107.67722682287\n",
      "Epoch: 33 Test Loss: 0.00302092 Val RMSE: 32099.695478589118\n",
      "Epoch: 34 Test Loss: 0.00257957 Val RMSE: 32092.929735025147\n",
      "Epoch: 35 Test Loss: 0.00220230 Val RMSE: 32086.96334180433\n",
      "Epoch: 36 Test Loss: 0.00188467 Val RMSE: 32083.837760579303\n",
      "Epoch: 37 Test Loss: 0.00162103 Val RMSE: 32098.88137406671\n",
      "Epoch: 38 Test Loss: 0.00140496 Val RMSE: 32071.66505882802\n",
      "Epoch: 39 Test Loss: 0.00122987 Val RMSE: 32035.726372141\n",
      "Epoch: 40 Test Loss: 0.00108939 Val RMSE: 31993.762904441235\n",
      "Epoch: 41 Test Loss: 0.00097764 Val RMSE: 31947.308120470385\n",
      "Model trained for window_size of 10 and hidden size of 100\n",
      "Fitting for window_size of 10 and hidden size of 150\n",
      "Epoch:  1 Test Loss: 0.77296317 Val RMSE: 60747.551028278205\n",
      "Epoch:  2 Test Loss: 0.11471531 Val RMSE: 37169.32411782325\n",
      "Epoch:  3 Test Loss: 0.08696077 Val RMSE: 36207.103441714324\n",
      "Epoch:  4 Test Loss: 0.07826813 Val RMSE: 35971.05336134891\n",
      "Epoch:  5 Test Loss: 0.07052606 Val RMSE: 35748.98705500714\n",
      "Epoch:  6 Test Loss: 0.06394246 Val RMSE: 35564.68941700232\n",
      "Epoch:  7 Test Loss: 0.05755572 Val RMSE: 35383.28504100756\n",
      "Epoch:  8 Test Loss: 0.05088732 Val RMSE: 35188.50711731634\n",
      "Epoch:  9 Test Loss: 0.04358456 Val RMSE: 34966.755239063576\n",
      "Epoch: 10 Test Loss: 0.03536149 Val RMSE: 34709.936960999155\n",
      "Epoch: 11 Test Loss: 0.02608230 Val RMSE: 34437.91976888824\n",
      "Epoch: 12 Test Loss: 0.01605419 Val RMSE: 34247.639714076395\n",
      "Epoch: 13 Test Loss: 0.00664451 Val RMSE: 34367.87729290316\n",
      "Epoch: 14 Test Loss: 0.00073674 Val RMSE: 34578.699189811516\n",
      "Epoch: 15 Test Loss: 0.00068757 Val RMSE: 32458.78279587269\n",
      "Epoch: 16 Test Loss: 0.00377058 Val RMSE: 30686.63434511372\n",
      "Epoch: 17 Test Loss: 0.00553635 Val RMSE: 31185.885662552257\n",
      "Epoch: 18 Test Loss: 0.00617259 Val RMSE: 32378.207643182563\n",
      "Epoch: 19 Test Loss: 0.00673582 Val RMSE: 33010.11587842615\n",
      "Epoch: 20 Test Loss: 0.00711295 Val RMSE: 33219.42064271825\n",
      "Epoch: 21 Test Loss: 0.00709197 Val RMSE: 33215.66289851714\n",
      "Epoch: 22 Test Loss: 0.00671066 Val RMSE: 33008.09979320718\n",
      "Epoch: 23 Test Loss: 0.00610886 Val RMSE: 32835.23968827388\n",
      "Epoch: 24 Test Loss: 0.00541160 Val RMSE: 32791.9773963203\n",
      "Epoch: 25 Test Loss: 0.00469974 Val RMSE: 32796.74968142048\n",
      "Epoch: 26 Test Loss: 0.00401903 Val RMSE: 32812.83204776557\n",
      "Epoch: 27 Test Loss: 0.00339371 Val RMSE: 32835.29790987226\n",
      "Epoch: 28 Test Loss: 0.00283595 Val RMSE: 32815.56962600147\n",
      "Epoch: 29 Test Loss: 0.00235089 Val RMSE: 32801.184192777066\n",
      "Epoch: 30 Test Loss: 0.00193892 Val RMSE: 32790.019676886615\n",
      "Epoch: 31 Test Loss: 0.00159690 Val RMSE: 32786.681465628426\n",
      "Epoch: 32 Test Loss: 0.00131898 Val RMSE: 32787.112028971496\n",
      "Epoch: 33 Test Loss: 0.00109751 Val RMSE: 32789.183331751374\n",
      "Epoch: 34 Test Loss: 0.00092407 Val RMSE: 32793.5014433655\n",
      "Epoch: 35 Test Loss: 0.00079021 Val RMSE: 32800.98324275212\n",
      "Model trained for window_size of 10 and hidden size of 150\n",
      "Fitting for window_size of 20 and hidden size of 10\n",
      "Epoch:  1 Test Loss: 0.27537301 Val RMSE: 51829.035998502615\n",
      "Epoch:  2 Test Loss: 0.24516776 Val RMSE: 50316.328328917494\n",
      "Epoch:  3 Test Loss: 0.21634357 Val RMSE: 48826.3196680261\n",
      "Epoch:  4 Test Loss: 0.18934548 Val RMSE: 47365.871583104374\n",
      "Epoch:  5 Test Loss: 0.16458163 Val RMSE: 45956.80675544449\n",
      "Epoch:  6 Test Loss: 0.14238679 Val RMSE: 44634.50217459161\n",
      "Epoch:  7 Test Loss: 0.12296919 Val RMSE: 43413.32367305095\n",
      "Epoch:  8 Test Loss: 0.10637814 Val RMSE: 42324.38955167908\n",
      "Epoch:  9 Test Loss: 0.09250576 Val RMSE: 41366.01742060396\n",
      "Epoch: 10 Test Loss: 0.08111800 Val RMSE: 40540.607457311606\n",
      "Epoch: 11 Test Loss: 0.07190348 Val RMSE: 39847.61451890812\n",
      "Epoch: 12 Test Loss: 0.06452221 Val RMSE: 39271.17778768454\n",
      "Epoch: 13 Test Loss: 0.05864529 Val RMSE: 38794.762121141226\n",
      "Epoch: 14 Test Loss: 0.05397718 Val RMSE: 38403.29879175217\n",
      "Epoch: 15 Test Loss: 0.05026631 Val RMSE: 38082.32477463178\n",
      "Epoch: 16 Test Loss: 0.04730650 Val RMSE: 37818.88246106112\n",
      "Epoch: 17 Test Loss: 0.04493253 Val RMSE: 37601.820060271035\n",
      "Epoch: 18 Test Loss: 0.04301408 Val RMSE: 37421.82369179873\n",
      "Epoch: 19 Test Loss: 0.04144944 Val RMSE: 37271.26510943911\n",
      "Epoch: 20 Test Loss: 0.04015992 Val RMSE: 37144.00602614507\n",
      "Epoch: 21 Test Loss: 0.03908448 Val RMSE: 37035.12322241573\n",
      "Epoch: 22 Test Loss: 0.03817557 Val RMSE: 36940.6676462796\n",
      "Epoch: 23 Test Loss: 0.03739700 Val RMSE: 36858.19551535542\n",
      "Epoch: 24 Test Loss: 0.03672009 Val RMSE: 36784.845368604176\n",
      "Epoch: 25 Test Loss: 0.03612318 Val RMSE: 36718.33151198023\n",
      "Epoch: 26 Test Loss: 0.03558869 Val RMSE: 36657.07960512691\n",
      "Epoch: 27 Test Loss: 0.03510379 Val RMSE: 36599.92032143096\n",
      "Epoch: 28 Test Loss: 0.03465771 Val RMSE: 36545.8453069464\n",
      "Epoch: 29 Test Loss: 0.03424227 Val RMSE: 36494.08061319448\n",
      "Epoch: 30 Test Loss: 0.03385122 Val RMSE: 36444.01036463867\n",
      "Epoch: 31 Test Loss: 0.03347941 Val RMSE: 36395.1273049286\n",
      "Epoch: 32 Test Loss: 0.03312284 Val RMSE: 36347.019721823\n",
      "Epoch: 33 Test Loss: 0.03277830 Val RMSE: 36299.3514585838\n",
      "Epoch: 34 Test Loss: 0.03244336 Val RMSE: 36251.84709992288\n",
      "Epoch: 35 Test Loss: 0.03211580 Val RMSE: 36204.259232189936\n",
      "Epoch: 36 Test Loss: 0.03179417 Val RMSE: 36156.40934407464\n",
      "Epoch: 37 Test Loss: 0.03147706 Val RMSE: 36108.112259634756\n",
      "Epoch: 38 Test Loss: 0.03116309 Val RMSE: 36059.184849067984\n",
      "Epoch: 39 Test Loss: 0.03085150 Val RMSE: 36009.513518014486\n",
      "Epoch: 40 Test Loss: 0.03054157 Val RMSE: 35958.979662360485\n",
      "Epoch: 41 Test Loss: 0.03023269 Val RMSE: 35907.47046661301\n",
      "Epoch: 42 Test Loss: 0.02992417 Val RMSE: 35854.86373414138\n",
      "Epoch: 43 Test Loss: 0.02961540 Val RMSE: 35801.04581438458\n",
      "Epoch: 44 Test Loss: 0.02930598 Val RMSE: 35745.92773550401\n",
      "Epoch: 45 Test Loss: 0.02899552 Val RMSE: 35689.40572024015\n",
      "Epoch: 46 Test Loss: 0.02868359 Val RMSE: 35631.381966585475\n",
      "Epoch: 47 Test Loss: 0.02836972 Val RMSE: 35571.74900483256\n",
      "Epoch: 48 Test Loss: 0.02805340 Val RMSE: 35510.40339113252\n",
      "Epoch: 49 Test Loss: 0.02773423 Val RMSE: 35447.22830623196\n",
      "Epoch: 50 Test Loss: 0.02741197 Val RMSE: 35382.1640403418\n",
      "Epoch: 51 Test Loss: 0.02708598 Val RMSE: 35315.08107441409\n",
      "Epoch: 52 Test Loss: 0.02675578 Val RMSE: 35245.88068247073\n",
      "Epoch: 53 Test Loss: 0.02642102 Val RMSE: 35174.49328275927\n",
      "Epoch: 54 Test Loss: 0.02608109 Val RMSE: 35100.82558721469\n",
      "Epoch: 55 Test Loss: 0.02573555 Val RMSE: 35024.82330553192\n",
      "Epoch: 56 Test Loss: 0.02538366 Val RMSE: 34946.40837595866\n",
      "Epoch: 57 Test Loss: 0.02502502 Val RMSE: 34865.582566553254\n",
      "Epoch: 58 Test Loss: 0.02465890 Val RMSE: 34782.34022529763\n",
      "Epoch: 59 Test Loss: 0.02428459 Val RMSE: 34696.70732184637\n",
      "Epoch: 60 Test Loss: 0.02390154 Val RMSE: 34608.81458005236\n",
      "Epoch: 61 Test Loss: 0.02350884 Val RMSE: 34518.79190887573\n",
      "Epoch: 62 Test Loss: 0.02310585 Val RMSE: 34426.9065643706\n",
      "Epoch: 63 Test Loss: 0.02269162 Val RMSE: 34333.47712576928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 Test Loss: 0.02226522 Val RMSE: 34238.95223341143\n",
      "Epoch: 65 Test Loss: 0.02182591 Val RMSE: 34143.953859058594\n",
      "Epoch: 66 Test Loss: 0.02137258 Val RMSE: 34049.197755259214\n",
      "Epoch: 67 Test Loss: 0.02090414 Val RMSE: 33955.60479497938\n",
      "Epoch: 68 Test Loss: 0.02041966 Val RMSE: 33864.31252494941\n",
      "Epoch: 69 Test Loss: 0.01991789 Val RMSE: 33776.57589361207\n",
      "Epoch: 70 Test Loss: 0.01939755 Val RMSE: 33693.83094147392\n",
      "Epoch: 71 Test Loss: 0.01885743 Val RMSE: 33617.66855947126\n",
      "Epoch: 72 Test Loss: 0.01829649 Val RMSE: 33549.8427178219\n",
      "Epoch: 73 Test Loss: 0.01771337 Val RMSE: 33431.673779292825\n",
      "Epoch: 74 Test Loss: 0.01710677 Val RMSE: 33309.86047009787\n",
      "Epoch: 75 Test Loss: 0.01647523 Val RMSE: 33015.00142418969\n",
      "Epoch: 76 Test Loss: 0.01581776 Val RMSE: 32657.619240609085\n",
      "Epoch: 77 Test Loss: 0.01513339 Val RMSE: 32251.557082402043\n",
      "Epoch: 78 Test Loss: 0.01442130 Val RMSE: 31822.491838511363\n",
      "Epoch: 79 Test Loss: 0.01368095 Val RMSE: 31340.56369309485\n",
      "Epoch: 80 Test Loss: 0.01291240 Val RMSE: 30843.22196811333\n",
      "Epoch: 81 Test Loss: 0.01211643 Val RMSE: 30279.1110539236\n",
      "Epoch: 82 Test Loss: 0.01129460 Val RMSE: 29670.744763911927\n",
      "Epoch: 83 Test Loss: 0.01044945 Val RMSE: 29028.299256522274\n",
      "Epoch: 84 Test Loss: 0.00958505 Val RMSE: 28344.22284231627\n",
      "Epoch: 85 Test Loss: 0.00870700 Val RMSE: 27542.16494018392\n",
      "Epoch: 86 Test Loss: 0.00782276 Val RMSE: 26663.807260202408\n",
      "Epoch: 87 Test Loss: 0.00694187 Val RMSE: 25702.26909781672\n",
      "Epoch: 88 Test Loss: 0.00607577 Val RMSE: 24672.71009794222\n",
      "Epoch: 89 Test Loss: 0.00523761 Val RMSE: 23542.271123416354\n",
      "Epoch: 90 Test Loss: 0.00444143 Val RMSE: 22303.21601318894\n",
      "Epoch: 91 Test Loss: 0.00370100 Val RMSE: 20981.15557397251\n",
      "Epoch: 92 Test Loss: 0.00302874 Val RMSE: 19822.555462354998\n",
      "Epoch: 93 Test Loss: 0.00243416 Val RMSE: 19034.16832161682\n",
      "Epoch: 94 Test Loss: 0.00192269 Val RMSE: 19131.727142089094\n",
      "Epoch: 95 Test Loss: 0.00149518 Val RMSE: 20709.197979592926\n",
      "Epoch: 96 Test Loss: 0.00114798 Val RMSE: 24460.100662909448\n",
      "Epoch: 97 Test Loss: 0.00087354 Val RMSE: 31042.201682441453\n",
      "Epoch: 98 Test Loss: 0.00066205 Val RMSE: 40243.34294581096\n",
      "Epoch: 99 Test Loss: 0.00050258 Val RMSE: 51554.88280305302\n",
      "Epoch: 100 Test Loss: 0.00038454 Val RMSE: 63429.894041597785\n",
      "Epoch: 101 Test Loss: 0.00029841 Val RMSE: 74420.25921171451\n",
      "Epoch: 102 Test Loss: 0.00023624 Val RMSE: 84044.7951972246\n",
      "Epoch: 103 Test Loss: 0.00019173 Val RMSE: 92212.1349515107\n",
      "Epoch: 104 Test Loss: 0.00016006 Val RMSE: 98982.31801999011\n",
      "Epoch: 105 Test Loss: 0.00013769 Val RMSE: 104483.15973487696\n",
      "Epoch: 106 Test Loss: 0.00012201 Val RMSE: 108874.38915992345\n",
      "Epoch: 107 Test Loss: 0.00011119 Val RMSE: 112312.98000243546\n",
      "Epoch: 108 Test Loss: 0.00010391 Val RMSE: 114952.65534580748\n",
      "Epoch: 109 Test Loss: 0.00009921 Val RMSE: 116935.60229959762\n",
      "Epoch: 110 Test Loss: 0.00009642 Val RMSE: 118375.6325939957\n",
      "Epoch: 111 Test Loss: 0.00009502 Val RMSE: 119382.93353363103\n",
      "Epoch: 112 Test Loss: 0.00009464 Val RMSE: 120041.28621556718\n",
      "Model trained for window_size of 20 and hidden size of 10\n",
      "Fitting for window_size of 20 and hidden size of 20\n",
      "Epoch:  1 Test Loss: 1.18063498 Val RMSE: 448713.5067495036\n",
      "Epoch:  2 Test Loss: 1.08768415 Val RMSE: 232573.41890563132\n",
      "Epoch:  3 Test Loss: 0.98886806 Val RMSE: 128774.38457406177\n",
      "Epoch:  4 Test Loss: 0.88130486 Val RMSE: 84932.4893497239\n",
      "Epoch:  5 Test Loss: 0.76209801 Val RMSE: 78405.14143651318\n",
      "Epoch:  6 Test Loss: 0.63020116 Val RMSE: 72028.24373812698\n",
      "Epoch:  7 Test Loss: 0.49012884 Val RMSE: 65071.325796427715\n",
      "Epoch:  8 Test Loss: 0.35544461 Val RMSE: 58102.17033438411\n",
      "Epoch:  9 Test Loss: 0.24431011 Val RMSE: 51828.591693184804\n",
      "Epoch: 10 Test Loss: 0.16614421 Val RMSE: 46862.43549937425\n",
      "Epoch: 11 Test Loss: 0.11744844 Val RMSE: 43430.23631852982\n",
      "Epoch: 12 Test Loss: 0.08905927 Val RMSE: 41264.38360292793\n",
      "Epoch: 13 Test Loss: 0.07280407 Val RMSE: 39953.04267778967\n",
      "Epoch: 14 Test Loss: 0.06337221 Val RMSE: 39161.43405493236\n",
      "Epoch: 15 Test Loss: 0.05773346 Val RMSE: 38673.25681445476\n",
      "Epoch: 16 Test Loss: 0.05422712 Val RMSE: 38362.61205023111\n",
      "Epoch: 17 Test Loss: 0.05194003 Val RMSE: 38156.202911330605\n",
      "Epoch: 18 Test Loss: 0.05036052 Val RMSE: 38011.34979238434\n",
      "Epoch: 19 Test Loss: 0.04919565 Val RMSE: 37902.93243549234\n",
      "Epoch: 20 Test Loss: 0.04827476 Val RMSE: 37816.00352275812\n",
      "Epoch: 21 Test Loss: 0.04749651 Val RMSE: 37741.53672369569\n",
      "Epoch: 22 Test Loss: 0.04680024 Val RMSE: 37674.02952833577\n",
      "Epoch: 23 Test Loss: 0.04614913 Val RMSE: 37610.0660633905\n",
      "Epoch: 24 Test Loss: 0.04552033 Val RMSE: 37547.47179210788\n",
      "Epoch: 25 Test Loss: 0.04489901 Val RMSE: 37484.76993100146\n",
      "Epoch: 26 Test Loss: 0.04427591 Val RMSE: 37420.98475521819\n",
      "Epoch: 27 Test Loss: 0.04364431 Val RMSE: 37355.335397463474\n",
      "Epoch: 28 Test Loss: 0.04299887 Val RMSE: 37287.15519235223\n",
      "Epoch: 29 Test Loss: 0.04233485 Val RMSE: 37215.78070202519\n",
      "Epoch: 30 Test Loss: 0.04164764 Val RMSE: 37140.49988802225\n",
      "Epoch: 31 Test Loss: 0.04093241 Val RMSE: 37061.1867251456\n",
      "Epoch: 32 Test Loss: 0.04018386 Val RMSE: 36976.35654219113\n",
      "Epoch: 33 Test Loss: 0.03939668 Val RMSE: 36884.78892970725\n",
      "Epoch: 34 Test Loss: 0.03856549 Val RMSE: 36785.28718329168\n",
      "Epoch: 35 Test Loss: 0.03768532 Val RMSE: 36676.681004971586\n",
      "Epoch: 36 Test Loss: 0.03675137 Val RMSE: 36557.922229183285\n",
      "Epoch: 37 Test Loss: 0.03575920 Val RMSE: 36428.40181684091\n",
      "Epoch: 38 Test Loss: 0.03470324 Val RMSE: 36288.20366357718\n",
      "Epoch: 39 Test Loss: 0.03357506 Val RMSE: 36138.39040758897\n",
      "Epoch: 40 Test Loss: 0.03236038 Val RMSE: 35981.33604326998\n",
      "Epoch: 41 Test Loss: 0.03103534 Val RMSE: 35821.05047497472\n",
      "Epoch: 42 Test Loss: 0.02956678 Val RMSE: 35663.697120900106\n",
      "Epoch: 43 Test Loss: 0.02791405 Val RMSE: 35516.98408967893\n",
      "Epoch: 44 Test Loss: 0.02603675 Val RMSE: 35389.157635442636\n",
      "Epoch: 45 Test Loss: 0.02390449 Val RMSE: 35290.43644470881\n",
      "Epoch: 46 Test Loss: 0.02151292 Val RMSE: 35244.12790196539\n",
      "Epoch: 47 Test Loss: 0.01889677 Val RMSE: 35276.98018318715\n",
      "Epoch: 48 Test Loss: 0.01613370 Val RMSE: 35162.9225665126\n",
      "Epoch: 49 Test Loss: 0.01333757 Val RMSE: 35001.48601867199\n",
      "Epoch: 50 Test Loss: 0.01064355 Val RMSE: 34442.51516948205\n",
      "Epoch: 51 Test Loss: 0.00818674 Val RMSE: 32791.222488479994\n",
      "Epoch: 52 Test Loss: 0.00607591 Val RMSE: 30781.502069251525\n",
      "Epoch: 53 Test Loss: 0.00437053 Val RMSE: 28529.588607239795\n",
      "Epoch: 54 Test Loss: 0.00307343 Val RMSE: 26169.151152225637\n",
      "Epoch: 55 Test Loss: 0.00214137 Val RMSE: 23793.499331096373\n",
      "Epoch: 56 Test Loss: 0.00150608 Val RMSE: 21537.757223988494\n",
      "Epoch: 57 Test Loss: 0.00109436 Val RMSE: 19955.174581609106\n",
      "Epoch: 58 Test Loss: 0.00084158 Val RMSE: 19315.71527150325\n",
      "Epoch: 59 Test Loss: 0.00069724 Val RMSE: 19259.82455317459\n",
      "Epoch: 60 Test Loss: 0.00062464 Val RMSE: 19100.602385886075\n",
      "Epoch: 61 Test Loss: 0.00059785 Val RMSE: 18794.512046345397\n",
      "Epoch: 62 Test Loss: 0.00059790 Val RMSE: 18790.541383057604\n",
      "Epoch: 63 Test Loss: 0.00061071 Val RMSE: 18646.995574302644\n",
      "Epoch: 64 Test Loss: 0.00062646 Val RMSE: 18374.368166204138\n",
      "Epoch: 65 Test Loss: 0.00063936 Val RMSE: 18065.34816122265\n",
      "Epoch: 66 Test Loss: 0.00064710 Val RMSE: 17767.062990236554\n",
      "Epoch: 67 Test Loss: 0.00064945 Val RMSE: 17502.342119091245\n",
      "Epoch: 68 Test Loss: 0.00064725 Val RMSE: 17272.782096972926\n",
      "Epoch: 69 Test Loss: 0.00064159 Val RMSE: 17076.262787368356\n",
      "Epoch: 70 Test Loss: 0.00063340 Val RMSE: 16911.84354013875\n",
      "Epoch: 71 Test Loss: 0.00062344 Val RMSE: 16779.511491534508\n",
      "Epoch: 72 Test Loss: 0.00061226 Val RMSE: 16670.619889076883\n",
      "Epoch: 73 Test Loss: 0.00060026 Val RMSE: 16584.363169902375\n",
      "Epoch: 74 Test Loss: 0.00058773 Val RMSE: 16525.85233156101\n",
      "Epoch: 75 Test Loss: 0.00057490 Val RMSE: 16494.042714394312\n",
      "Epoch: 76 Test Loss: 0.00056195 Val RMSE: 16475.794147073982\n",
      "Epoch: 77 Test Loss: 0.00054899 Val RMSE: 16466.024190534834\n",
      "Epoch: 78 Test Loss: 0.00053613 Val RMSE: 16473.541698296565\n",
      "Epoch: 79 Test Loss: 0.00052346 Val RMSE: 16496.15836013354\n",
      "Epoch: 80 Test Loss: 0.00051100 Val RMSE: 16531.629134405564\n",
      "Epoch: 81 Test Loss: 0.00049883 Val RMSE: 16577.761563291024\n",
      "Epoch: 82 Test Loss: 0.00048696 Val RMSE: 16632.51250211354\n",
      "Epoch: 83 Test Loss: 0.00047540 Val RMSE: 16693.95511716256\n",
      "Epoch: 84 Test Loss: 0.00046418 Val RMSE: 16738.796416169167\n",
      "Epoch: 85 Test Loss: 0.00045330 Val RMSE: 16787.45836975824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 Test Loss: 0.00044274 Val RMSE: 16839.02164626893\n",
      "Epoch: 87 Test Loss: 0.00043251 Val RMSE: 16892.59922388818\n",
      "Epoch: 88 Test Loss: 0.00042259 Val RMSE: 16947.501188772407\n",
      "Epoch: 89 Test Loss: 0.00041299 Val RMSE: 17003.17518114193\n",
      "Epoch: 90 Test Loss: 0.00040369 Val RMSE: 17059.116655959147\n",
      "Epoch: 91 Test Loss: 0.00039467 Val RMSE: 17115.007921624958\n",
      "Epoch: 92 Test Loss: 0.00038592 Val RMSE: 17170.541232603584\n",
      "Epoch: 93 Test Loss: 0.00037744 Val RMSE: 17225.510652989367\n",
      "Epoch: 94 Test Loss: 0.00036920 Val RMSE: 17279.73297426878\n",
      "Epoch: 95 Test Loss: 0.00036121 Val RMSE: 17333.13986852128\n",
      "Epoch: 96 Test Loss: 0.00035343 Val RMSE: 17385.552743858276\n",
      "Model trained for window_size of 20 and hidden size of 20\n",
      "Fitting for window_size of 20 and hidden size of 40\n",
      "Epoch:  1 Test Loss: 1.42535675 Val RMSE: 2253224.015187576\n",
      "Epoch:  2 Test Loss: 1.27563107 Val RMSE: 687562.2731673368\n",
      "Epoch:  3 Test Loss: 1.11465311 Val RMSE: 210644.4106661223\n",
      "Epoch:  4 Test Loss: 0.91295010 Val RMSE: 84796.93731531086\n",
      "Epoch:  5 Test Loss: 0.61959791 Val RMSE: 70592.28865933746\n",
      "Epoch:  6 Test Loss: 0.23313124 Val RMSE: 49816.12026071024\n",
      "Epoch:  7 Test Loss: 0.09324784 Val RMSE: 40483.37301245539\n",
      "Epoch:  8 Test Loss: 0.07663681 Val RMSE: 39239.39145605305\n",
      "Epoch:  9 Test Loss: 0.07247780 Val RMSE: 38946.332075087375\n",
      "Epoch: 10 Test Loss: 0.07034639 Val RMSE: 38808.07079138389\n",
      "Epoch: 11 Test Loss: 0.06875443 Val RMSE: 38709.43634439461\n",
      "Epoch: 12 Test Loss: 0.06736102 Val RMSE: 38624.556565087565\n",
      "Epoch: 13 Test Loss: 0.06605217 Val RMSE: 38545.10379710378\n",
      "Epoch: 14 Test Loss: 0.06477554 Val RMSE: 38467.41418347523\n",
      "Epoch: 15 Test Loss: 0.06349933 Val RMSE: 38389.290450597335\n",
      "Epoch: 16 Test Loss: 0.06220028 Val RMSE: 38309.104305720306\n",
      "Epoch: 17 Test Loss: 0.06085886 Val RMSE: 38225.456124250966\n",
      "Epoch: 18 Test Loss: 0.05945750 Val RMSE: 38137.06753291991\n",
      "Epoch: 19 Test Loss: 0.05797966 Val RMSE: 38042.72790521016\n",
      "Epoch: 20 Test Loss: 0.05640948 Val RMSE: 37941.26556562059\n",
      "Epoch: 21 Test Loss: 0.05473189 Val RMSE: 37831.59906305813\n",
      "Epoch: 22 Test Loss: 0.05293132 Val RMSE: 37712.60259237807\n",
      "Epoch: 23 Test Loss: 0.05099303 Val RMSE: 37583.229567286304\n",
      "Epoch: 24 Test Loss: 0.04890096 Val RMSE: 37442.43561856537\n",
      "Epoch: 25 Test Loss: 0.04663816 Val RMSE: 37289.33750624702\n",
      "Epoch: 26 Test Loss: 0.04418748 Val RMSE: 37123.4404396241\n",
      "Epoch: 27 Test Loss: 0.04153421 Val RMSE: 36946.32319412658\n",
      "Epoch: 28 Test Loss: 0.03866901 Val RMSE: 36761.671233417226\n",
      "Epoch: 29 Test Loss: 0.03559004 Val RMSE: 36572.249992423356\n",
      "Epoch: 30 Test Loss: 0.03230388 Val RMSE: 36390.550060010304\n",
      "Epoch: 31 Test Loss: 0.02882744 Val RMSE: 36235.664870154935\n",
      "Epoch: 32 Test Loss: 0.02518998 Val RMSE: 36137.31391521064\n",
      "Epoch: 33 Test Loss: 0.02143678 Val RMSE: 36130.41597940588\n",
      "Epoch: 34 Test Loss: 0.01763506 Val RMSE: 36192.574220880575\n",
      "Epoch: 35 Test Loss: 0.01388466 Val RMSE: 35985.368754428586\n",
      "Epoch: 36 Test Loss: 0.01032687 Val RMSE: 35866.34083996194\n",
      "Epoch: 37 Test Loss: 0.00714006 Val RMSE: 33984.05280818847\n",
      "Epoch: 38 Test Loss: 0.00450540 Val RMSE: 30847.169581084167\n",
      "Epoch: 39 Test Loss: 0.00254412 Val RMSE: 27253.560020041026\n",
      "Epoch: 40 Test Loss: 0.00125980 Val RMSE: 23371.894601832584\n",
      "Epoch: 41 Test Loss: 0.00053451 Val RMSE: 20083.118771833713\n",
      "Epoch: 42 Test Loss: 0.00018802 Val RMSE: 22248.406609775957\n",
      "Epoch: 43 Test Loss: 0.00005186 Val RMSE: 33438.63340847212\n",
      "Epoch: 44 Test Loss: 0.00001028 Val RMSE: 51836.380091342995\n",
      "Epoch: 45 Test Loss: 0.00000148 Val RMSE: 71441.41466388147\n",
      "Epoch: 46 Test Loss: 0.00000053 Val RMSE: 86460.51937449138\n",
      "Epoch: 47 Test Loss: 0.00000168 Val RMSE: 94577.98613214429\n",
      "Epoch: 48 Test Loss: 0.00000663 Val RMSE: 97732.3439556179\n",
      "Epoch: 49 Test Loss: 0.00001843 Val RMSE: 97903.05045114408\n",
      "Epoch: 50 Test Loss: 0.00003906 Val RMSE: 96461.92731092048\n",
      "Epoch: 51 Test Loss: 0.00006902 Val RMSE: 94243.51498255647\n",
      "Epoch: 52 Test Loss: 0.00010760 Val RMSE: 91729.14674323951\n",
      "Epoch: 53 Test Loss: 0.00015340 Val RMSE: 89177.65652507676\n",
      "Epoch: 54 Test Loss: 0.00020475 Val RMSE: 86720.59659468006\n",
      "Epoch: 55 Test Loss: 0.00025994 Val RMSE: 84422.2491473656\n",
      "Epoch: 56 Test Loss: 0.00031744 Val RMSE: 82307.20552774316\n",
      "Epoch: 57 Test Loss: 0.00037592 Val RMSE: 80381.7434740094\n",
      "Epoch: 58 Test Loss: 0.00043429 Val RMSE: 78640.04011036629\n",
      "Epoch: 59 Test Loss: 0.00049170 Val RMSE: 77072.0880257936\n",
      "Epoch: 60 Test Loss: 0.00054751 Val RMSE: 75664.31806562962\n",
      "Model trained for window_size of 20 and hidden size of 40\n",
      "Fitting for window_size of 20 and hidden size of 60\n",
      "Epoch:  1 Test Loss: 0.98872995 Val RMSE: 88366.08344414989\n",
      "Epoch:  2 Test Loss: 0.81518406 Val RMSE: 79840.23260857105\n",
      "Epoch:  3 Test Loss: 0.51279730 Val RMSE: 65204.459372303456\n",
      "Epoch:  4 Test Loss: 0.09354125 Val RMSE: 40125.766942456336\n",
      "Epoch:  5 Test Loss: 0.09032506 Val RMSE: 40070.39386362615\n",
      "Epoch:  6 Test Loss: 0.08095853 Val RMSE: 39392.61093876443\n",
      "Epoch:  7 Test Loss: 0.07647380 Val RMSE: 39105.73602090786\n",
      "Epoch:  8 Test Loss: 0.07318689 Val RMSE: 38909.724932213925\n",
      "Epoch:  9 Test Loss: 0.07033978 Val RMSE: 38745.87345719719\n",
      "Epoch: 10 Test Loss: 0.06764414 Val RMSE: 38593.16113802239\n",
      "Epoch: 11 Test Loss: 0.06494489 Val RMSE: 38441.01177641693\n",
      "Epoch: 12 Test Loss: 0.06213447 Val RMSE: 38282.321794306205\n",
      "Epoch: 13 Test Loss: 0.05912998 Val RMSE: 38111.36339368268\n",
      "Epoch: 14 Test Loss: 0.05586651 Val RMSE: 37923.47540174176\n",
      "Epoch: 15 Test Loss: 0.05228910 Val RMSE: 37714.93993348981\n",
      "Epoch: 16 Test Loss: 0.04834238 Val RMSE: 37482.50891215991\n",
      "Epoch: 17 Test Loss: 0.04397176 Val RMSE: 37223.40068054687\n",
      "Epoch: 18 Test Loss: 0.03913712 Val RMSE: 36941.254917513674\n",
      "Epoch: 19 Test Loss: 0.03382903 Val RMSE: 36648.283339194575\n",
      "Epoch: 20 Test Loss: 0.02808106 Val RMSE: 36373.641944105955\n",
      "Epoch: 21 Test Loss: 0.02199246 Val RMSE: 36171.501210933544\n",
      "Epoch: 22 Test Loss: 0.01577866 Val RMSE: 36300.207311199636\n",
      "Epoch: 23 Test Loss: 0.00985118 Val RMSE: 36240.59071156304\n",
      "Epoch: 24 Test Loss: 0.00486283 Val RMSE: 35416.20453604988\n",
      "Epoch: 25 Test Loss: 0.00152791 Val RMSE: 29896.719395916607\n",
      "Epoch: 26 Test Loss: 0.00011873 Val RMSE: 21493.20998038775\n",
      "Epoch: 27 Test Loss: 0.00012748 Val RMSE: 26108.703780492673\n",
      "Epoch: 28 Test Loss: 0.00067145 Val RMSE: 120768.43461085533\n",
      "Epoch: 29 Test Loss: 0.00112775 Val RMSE: 230869.5385609978\n",
      "Epoch: 30 Test Loss: 0.00128437 Val RMSE: 267902.0444134604\n",
      "Epoch: 31 Test Loss: 0.00116498 Val RMSE: 253551.6144994421\n",
      "Epoch: 32 Test Loss: 0.00087159 Val RMSE: 213251.87491241298\n",
      "Epoch: 33 Test Loss: 0.00051749 Val RMSE: 165942.33028859334\n",
      "Epoch: 34 Test Loss: 0.00020676 Val RMSE: 121822.88133194292\n",
      "Epoch: 35 Test Loss: 0.00002443 Val RMSE: 84672.30736902785\n",
      "Epoch: 36 Test Loss: 0.00002521 Val RMSE: 55383.2471854066\n",
      "Epoch: 37 Test Loss: 0.00022440 Val RMSE: 37392.59424269923\n",
      "Epoch: 38 Test Loss: 0.00059829 Val RMSE: 27723.74474454993\n",
      "Epoch: 39 Test Loss: 0.00109505 Val RMSE: 23186.56247237196\n",
      "Epoch: 40 Test Loss: 0.00165074 Val RMSE: 21402.839085457825\n",
      "Epoch: 41 Test Loss: 0.00220385 Val RMSE: 20566.76421139508\n",
      "Epoch: 42 Test Loss: 0.00270472 Val RMSE: 20142.545578036166\n",
      "Epoch: 43 Test Loss: 0.00311968 Val RMSE: 19859.883574564563\n",
      "Epoch: 44 Test Loss: 0.00343134 Val RMSE: 19149.391227175078\n",
      "Epoch: 45 Test Loss: 0.00363645 Val RMSE: 18052.97027124474\n",
      "Epoch: 46 Test Loss: 0.00374264 Val RMSE: 17091.463279220858\n",
      "Epoch: 47 Test Loss: 0.00376467 Val RMSE: 16446.655927227715\n",
      "Epoch: 48 Test Loss: 0.00372076 Val RMSE: 16056.481181886524\n",
      "Epoch: 49 Test Loss: 0.00362950 Val RMSE: 15833.746466982037\n",
      "Epoch: 50 Test Loss: 0.00350764 Val RMSE: 15713.823728341758\n",
      "Epoch: 51 Test Loss: 0.00336878 Val RMSE: 15656.797675703634\n",
      "Epoch: 52 Test Loss: 0.00322303 Val RMSE: 15639.588778409308\n",
      "Epoch: 53 Test Loss: 0.00307741 Val RMSE: 15648.72784723935\n",
      "Epoch: 54 Test Loss: 0.00293620 Val RMSE: 15676.275026268959\n",
      "Epoch: 55 Test Loss: 0.00280180 Val RMSE: 15719.164807156028\n",
      "Epoch: 56 Test Loss: 0.00267534 Val RMSE: 15788.565501010587\n",
      "Epoch: 57 Test Loss: 0.00255713 Val RMSE: 15865.679018621508\n",
      "Epoch: 58 Test Loss: 0.00244691 Val RMSE: 15948.912772532316\n",
      "Epoch: 59 Test Loss: 0.00234428 Val RMSE: 16037.133844627737\n",
      "Epoch: 60 Test Loss: 0.00224866 Val RMSE: 16129.790502948608\n",
      "Epoch: 61 Test Loss: 0.00215953 Val RMSE: 16226.50716341549\n",
      "Epoch: 62 Test Loss: 0.00207627 Val RMSE: 16327.151686205128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 Test Loss: 0.00199844 Val RMSE: 16431.740081438875\n",
      "Epoch: 64 Test Loss: 0.00192551 Val RMSE: 16540.27109727234\n",
      "Epoch: 65 Test Loss: 0.00185711 Val RMSE: 16652.790891558576\n",
      "Epoch: 66 Test Loss: 0.00179283 Val RMSE: 16769.125626397876\n",
      "Epoch: 67 Test Loss: 0.00173233 Val RMSE: 16888.978565718156\n",
      "Epoch: 68 Test Loss: 0.00167530 Val RMSE: 17007.382536103654\n",
      "Epoch: 69 Test Loss: 0.00162150 Val RMSE: 17129.269960745478\n",
      "Epoch: 70 Test Loss: 0.00157064 Val RMSE: 17254.460174160315\n",
      "Epoch: 71 Test Loss: 0.00152251 Val RMSE: 17382.599823409175\n",
      "Model trained for window_size of 20 and hidden size of 60\n",
      "Fitting for window_size of 20 and hidden size of 80\n",
      "Epoch:  1 Test Loss: 1.04213071 Val RMSE: 121133.10713075043\n",
      "Epoch:  2 Test Loss: 0.75439876 Val RMSE: 76823.14662576994\n",
      "Epoch:  3 Test Loss: 0.11304074 Val RMSE: 41410.456688489765\n",
      "Epoch:  4 Test Loss: 0.09157392 Val RMSE: 40154.220262423274\n",
      "Epoch:  5 Test Loss: 0.08342589 Val RMSE: 39683.66584963269\n",
      "Epoch:  6 Test Loss: 0.07897518 Val RMSE: 39445.60986443474\n",
      "Epoch:  7 Test Loss: 0.07584341 Val RMSE: 39289.1095899966\n",
      "Epoch:  8 Test Loss: 0.07317067 Val RMSE: 39156.96725704014\n",
      "Epoch:  9 Test Loss: 0.07067467 Val RMSE: 39031.903423058124\n",
      "Epoch: 10 Test Loss: 0.06822616 Val RMSE: 38906.20623363945\n",
      "Epoch: 11 Test Loss: 0.06573490 Val RMSE: 38774.150328101256\n",
      "Epoch: 12 Test Loss: 0.06312388 Val RMSE: 38630.5245982048\n",
      "Epoch: 13 Test Loss: 0.06032158 Val RMSE: 38470.131383176966\n",
      "Epoch: 14 Test Loss: 0.05725343 Val RMSE: 38287.17703259122\n",
      "Epoch: 15 Test Loss: 0.05383509 Val RMSE: 38074.642536559106\n",
      "Epoch: 16 Test Loss: 0.04997027 Val RMSE: 37824.132942040844\n",
      "Epoch: 17 Test Loss: 0.04555668 Val RMSE: 37527.207960697146\n",
      "Epoch: 18 Test Loss: 0.04050279 Val RMSE: 37177.518883028606\n",
      "Epoch: 19 Test Loss: 0.03475960 Val RMSE: 36796.62540151397\n",
      "Epoch: 20 Test Loss: 0.02836578 Val RMSE: 36413.79654727456\n",
      "Epoch: 21 Test Loss: 0.02150231 Val RMSE: 36139.919443599014\n",
      "Epoch: 22 Test Loss: 0.01457215 Val RMSE: 36197.147321016615\n",
      "Epoch: 23 Test Loss: 0.00827944 Val RMSE: 35478.72962754177\n",
      "Epoch: 24 Test Loss: 0.00352750 Val RMSE: 29501.385550826122\n",
      "Epoch: 25 Test Loss: 0.00089331 Val RMSE: 21420.991008048346\n",
      "Epoch: 26 Test Loss: 0.00004707 Val RMSE: 24785.511371119344\n",
      "Epoch: 27 Test Loss: 0.00006066 Val RMSE: 93308.78189433864\n",
      "Epoch: 28 Test Loss: 0.00023369 Val RMSE: 211830.7703902776\n",
      "Epoch: 29 Test Loss: 0.00032717 Val RMSE: 316913.7577321196\n",
      "Epoch: 30 Test Loss: 0.00033210 Val RMSE: 383234.9588181837\n",
      "Epoch: 31 Test Loss: 0.00028747 Val RMSE: 407977.7641596823\n",
      "Epoch: 32 Test Loss: 0.00022435 Val RMSE: 400447.41721283965\n",
      "Epoch: 33 Test Loss: 0.00016007 Val RMSE: 373001.0775274827\n",
      "Epoch: 34 Test Loss: 0.00010289 Val RMSE: 335981.0985989354\n",
      "Epoch: 35 Test Loss: 0.00005654 Val RMSE: 296406.95521026285\n",
      "Epoch: 36 Test Loss: 0.00002307 Val RMSE: 258439.68084123218\n",
      "Epoch: 37 Test Loss: 0.00000401 Val RMSE: 224217.03844612822\n",
      "Epoch: 38 Test Loss: 0.00000074 Val RMSE: 194555.3582312235\n",
      "Epoch: 39 Test Loss: 0.00001421 Val RMSE: 169484.468681139\n",
      "Epoch: 40 Test Loss: 0.00004467 Val RMSE: 148605.2406552172\n",
      "Epoch: 41 Test Loss: 0.00009145 Val RMSE: 131345.33582411922\n",
      "Epoch: 42 Test Loss: 0.00015295 Val RMSE: 117109.44633699104\n",
      "Epoch: 43 Test Loss: 0.00022685 Val RMSE: 105359.0314733174\n",
      "Epoch: 44 Test Loss: 0.00031034 Val RMSE: 95635.58544349283\n",
      "Model trained for window_size of 20 and hidden size of 80\n",
      "Fitting for window_size of 20 and hidden size of 100\n",
      "Epoch:  1 Test Loss: 0.79798925 Val RMSE: 78903.53161515336\n",
      "Epoch:  2 Test Loss: 0.36194879 Val RMSE: 56892.50065543334\n",
      "Epoch:  3 Test Loss: 0.09428742 Val RMSE: 40546.840859106305\n",
      "Epoch:  4 Test Loss: 0.08783244 Val RMSE: 40170.71628410997\n",
      "Epoch:  5 Test Loss: 0.08241489 Val RMSE: 39830.89350230906\n",
      "Epoch:  6 Test Loss: 0.07871797 Val RMSE: 39610.34445786552\n",
      "Epoch:  7 Test Loss: 0.07567994 Val RMSE: 39431.89354084457\n",
      "Epoch:  8 Test Loss: 0.07293331 Val RMSE: 39270.44812004384\n",
      "Epoch:  9 Test Loss: 0.07029375 Val RMSE: 39113.68431080421\n",
      "Epoch: 10 Test Loss: 0.06764764 Val RMSE: 38953.98521312853\n",
      "Epoch: 11 Test Loss: 0.06491613 Val RMSE: 38785.90764684947\n",
      "Epoch: 12 Test Loss: 0.06204284 Val RMSE: 38605.28024345705\n",
      "Epoch: 13 Test Loss: 0.05898455 Val RMSE: 38408.51657176859\n",
      "Epoch: 14 Test Loss: 0.05570098 Val RMSE: 38191.96057796768\n",
      "Epoch: 15 Test Loss: 0.05214401 Val RMSE: 37951.13994937316\n",
      "Epoch: 16 Test Loss: 0.04825059 Val RMSE: 37680.269330992036\n",
      "Epoch: 17 Test Loss: 0.04393447 Val RMSE: 37372.694624058786\n",
      "Epoch: 18 Test Loss: 0.03907950 Val RMSE: 37026.716870233766\n",
      "Epoch: 19 Test Loss: 0.03355248 Val RMSE: 36651.585452352694\n",
      "Epoch: 20 Test Loss: 0.02724379 Val RMSE: 36279.238545268156\n",
      "Epoch: 21 Test Loss: 0.02015368 Val RMSE: 36050.18306928867\n",
      "Epoch: 22 Test Loss: 0.01261873 Val RMSE: 35610.623333382326\n",
      "Epoch: 23 Test Loss: 0.00577770 Val RMSE: 31433.706064495986\n",
      "Epoch: 24 Test Loss: 0.00145737 Val RMSE: 21685.655423871835\n",
      "Epoch: 25 Test Loss: 0.00008311 Val RMSE: 27912.05342892846\n",
      "Epoch: 26 Test Loss: 0.00003651 Val RMSE: 92453.05051872015\n",
      "Epoch: 27 Test Loss: 0.00012560 Val RMSE: 156480.35748695492\n",
      "Epoch: 28 Test Loss: 0.00014090 Val RMSE: 197499.6006897837\n",
      "Epoch: 29 Test Loss: 0.00011891 Val RMSE: 217571.49386136752\n",
      "Epoch: 30 Test Loss: 0.00008655 Val RMSE: 221268.8479153706\n",
      "Epoch: 31 Test Loss: 0.00005430 Val RMSE: 213778.10507849097\n",
      "Epoch: 32 Test Loss: 0.00002712 Val RMSE: 199878.01534161394\n",
      "Epoch: 33 Test Loss: 0.00000823 Val RMSE: 183127.5751313605\n",
      "Epoch: 34 Test Loss: 0.00000015 Val RMSE: 165803.2091894766\n",
      "Epoch: 35 Test Loss: 0.00000495 Val RMSE: 149204.83131939743\n",
      "Epoch: 36 Test Loss: 0.00002432 Val RMSE: 133989.5147462945\n",
      "Epoch: 37 Test Loss: 0.00005937 Val RMSE: 120417.4423074193\n",
      "Epoch: 38 Test Loss: 0.00011060 Val RMSE: 108522.19222088005\n",
      "Epoch: 39 Test Loss: 0.00017776 Val RMSE: 98213.49989644326\n",
      "Epoch: 40 Test Loss: 0.00025981 Val RMSE: 89346.69303476426\n",
      "Epoch: 41 Test Loss: 0.00035498 Val RMSE: 81756.62296895415\n",
      "Epoch: 42 Test Loss: 0.00046090 Val RMSE: 75280.75258822295\n",
      "Epoch: 43 Test Loss: 0.00057477 Val RMSE: 69768.87623023767\n",
      "Model trained for window_size of 20 and hidden size of 100\n",
      "Fitting for window_size of 20 and hidden size of 150\n",
      "Epoch:  1 Test Loss: 0.63856328 Val RMSE: 71474.3447074654\n",
      "Epoch:  2 Test Loss: 0.00726800 Val RMSE: 19982.01658258324\n",
      "Epoch:  3 Test Loss: 0.08941299 Val RMSE: 40219.45918064669\n",
      "Epoch:  4 Test Loss: 0.08945207 Val RMSE: 40495.50721495022\n",
      "Epoch:  5 Test Loss: 0.08265202 Val RMSE: 40150.810627834246\n",
      "Epoch:  6 Test Loss: 0.07379409 Val RMSE: 39595.982750642\n",
      "Epoch:  7 Test Loss: 0.06500661 Val RMSE: 39011.29616687594\n",
      "Epoch:  8 Test Loss: 0.05596020 Val RMSE: 38372.193712362234\n",
      "Epoch:  9 Test Loss: 0.04617505 Val RMSE: 37637.640077189135\n",
      "Epoch: 10 Test Loss: 0.03526693 Val RMSE: 36811.507790376025\n",
      "Epoch: 11 Test Loss: 0.02315631 Val RMSE: 36012.31048476107\n",
      "Epoch: 12 Test Loss: 0.01095375 Val RMSE: 35285.32883246853\n",
      "Epoch: 13 Test Loss: 0.00234901 Val RMSE: 26293.259956845144\n",
      "Epoch: 14 Test Loss: 0.00000534 Val RMSE: 25472.09061984183\n",
      "Epoch: 15 Test Loss: 0.00033107 Val RMSE: 120805.58574144068\n",
      "Epoch: 16 Test Loss: 0.00047924 Val RMSE: 208060.78689291776\n",
      "Epoch: 17 Test Loss: 0.00043545 Val RMSE: 258383.83122508932\n",
      "Epoch: 18 Test Loss: 0.00031507 Val RMSE: 254517.02996158798\n",
      "Epoch: 19 Test Loss: 0.00016196 Val RMSE: 212118.45945302228\n",
      "Epoch: 20 Test Loss: 0.00004219 Val RMSE: 163214.41786216229\n",
      "Epoch: 21 Test Loss: 0.00000006 Val RMSE: 122951.4039743814\n",
      "Model trained for window_size of 20 and hidden size of 150\n",
      "Fitting for window_size of 40 and hidden size of 10\n",
      "Epoch:  1 Test Loss: 0.85576230 Val RMSE: 124060.03268622683\n",
      "Epoch:  2 Test Loss: 0.79612815 Val RMSE: 118605.42765523738\n",
      "Epoch:  3 Test Loss: 0.73716146 Val RMSE: 113266.19240249823\n",
      "Epoch:  4 Test Loss: 0.67779416 Val RMSE: 108042.29784227726\n",
      "Epoch:  5 Test Loss: 0.61787361 Val RMSE: 102871.98770610659\n",
      "Epoch:  6 Test Loss: 0.55751884 Val RMSE: 97765.50360760656\n",
      "Epoch:  7 Test Loss: 0.49698019 Val RMSE: 92736.0603836377\n",
      "Epoch:  8 Test Loss: 0.43664747 Val RMSE: 87809.3477103495\n",
      "Epoch:  9 Test Loss: 0.37719420 Val RMSE: 82984.82149262082\n",
      "Epoch: 10 Test Loss: 0.31973466 Val RMSE: 78299.2393025889\n",
      "Epoch: 11 Test Loss: 0.26579034 Val RMSE: 73854.1294665739\n",
      "Epoch: 12 Test Loss: 0.21700683 Val RMSE: 69550.17388103259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Test Loss: 0.17473365 Val RMSE: 65530.803844720795\n",
      "Epoch: 14 Test Loss: 0.13966124 Val RMSE: 61955.75219958067\n",
      "Epoch: 15 Test Loss: 0.11169599 Val RMSE: 58718.96374597927\n",
      "Epoch: 16 Test Loss: 0.09010515 Val RMSE: 55800.79154851411\n",
      "Epoch: 17 Test Loss: 0.07380769 Val RMSE: 53276.76937097259\n",
      "Epoch: 18 Test Loss: 0.06165823 Val RMSE: 51163.7472348996\n",
      "Epoch: 19 Test Loss: 0.05262998 Val RMSE: 49432.31599801762\n",
      "Epoch: 20 Test Loss: 0.04589031 Val RMSE: 48028.060751455\n",
      "Epoch: 21 Test Loss: 0.04080480 Val RMSE: 46889.81396031441\n",
      "Epoch: 22 Test Loss: 0.03690699 Val RMSE: 45960.17795135864\n",
      "Epoch: 23 Test Loss: 0.03386142 Val RMSE: 45190.26068502089\n",
      "Epoch: 24 Test Loss: 0.03142899 Val RMSE: 44540.4747574218\n",
      "Epoch: 25 Test Loss: 0.02944040 Val RMSE: 43979.899961510775\n",
      "Epoch: 26 Test Loss: 0.02777534 Val RMSE: 43484.78611175959\n",
      "Epoch: 27 Test Loss: 0.02634864 Val RMSE: 43037.194701680215\n",
      "Epoch: 28 Test Loss: 0.02509953 Val RMSE: 42623.65109259866\n",
      "Epoch: 29 Test Loss: 0.02398524 Val RMSE: 42234.34312232423\n",
      "Epoch: 30 Test Loss: 0.02297488 Val RMSE: 41861.90144483356\n",
      "Epoch: 31 Test Loss: 0.02204682 Val RMSE: 41501.13839423584\n",
      "Epoch: 32 Test Loss: 0.02118562 Val RMSE: 41148.338049347796\n",
      "Epoch: 33 Test Loss: 0.02038004 Val RMSE: 40800.83962600577\n",
      "Epoch: 34 Test Loss: 0.01962183 Val RMSE: 40456.73991378961\n",
      "Epoch: 35 Test Loss: 0.01890535 Val RMSE: 40114.93791672896\n",
      "Epoch: 36 Test Loss: 0.01822636 Val RMSE: 39774.69066810656\n",
      "Epoch: 37 Test Loss: 0.01758132 Val RMSE: 39435.44694321606\n",
      "Epoch: 38 Test Loss: 0.01696785 Val RMSE: 39097.0907973969\n",
      "Epoch: 39 Test Loss: 0.01638367 Val RMSE: 38759.49188645052\n",
      "Epoch: 40 Test Loss: 0.01582702 Val RMSE: 38422.71944732806\n",
      "Epoch: 41 Test Loss: 0.01529630 Val RMSE: 38086.860463930105\n",
      "Epoch: 42 Test Loss: 0.01479000 Val RMSE: 37752.04577053668\n",
      "Epoch: 43 Test Loss: 0.01430683 Val RMSE: 37418.49272558508\n",
      "Epoch: 44 Test Loss: 0.01384551 Val RMSE: 37086.36897173677\n",
      "Epoch: 45 Test Loss: 0.01340486 Val RMSE: 36755.913971265836\n",
      "Epoch: 46 Test Loss: 0.01298384 Val RMSE: 36427.35803103024\n",
      "Epoch: 47 Test Loss: 0.01258122 Val RMSE: 36100.85321227103\n",
      "Epoch: 48 Test Loss: 0.01219597 Val RMSE: 35776.60296792345\n",
      "Epoch: 49 Test Loss: 0.01182723 Val RMSE: 35454.86175221395\n",
      "Epoch: 50 Test Loss: 0.01147408 Val RMSE: 35135.80132801016\n",
      "Epoch: 51 Test Loss: 0.01113564 Val RMSE: 34819.634030401125\n",
      "Epoch: 52 Test Loss: 0.01081122 Val RMSE: 34506.59244496904\n",
      "Epoch: 53 Test Loss: 0.01049991 Val RMSE: 34196.78368627618\n",
      "Epoch: 54 Test Loss: 0.01020107 Val RMSE: 33836.9923316263\n",
      "Epoch: 55 Test Loss: 0.00991400 Val RMSE: 33357.96749614156\n",
      "Epoch: 56 Test Loss: 0.00963825 Val RMSE: 32791.62578754051\n",
      "Epoch: 57 Test Loss: 0.00937319 Val RMSE: 32153.480354150855\n",
      "Epoch: 58 Test Loss: 0.00911823 Val RMSE: 31471.19581480733\n",
      "Epoch: 59 Test Loss: 0.00887287 Val RMSE: 30752.87859756008\n",
      "Epoch: 60 Test Loss: 0.00863675 Val RMSE: 30011.33049819073\n",
      "Epoch: 61 Test Loss: 0.00840932 Val RMSE: 29257.896559951943\n",
      "Epoch: 62 Test Loss: 0.00819024 Val RMSE: 28495.238545606288\n",
      "Epoch: 63 Test Loss: 0.00797909 Val RMSE: 27726.855921247465\n",
      "Epoch: 64 Test Loss: 0.00777556 Val RMSE: 26972.69370800746\n",
      "Epoch: 65 Test Loss: 0.00757933 Val RMSE: 26210.371146889327\n",
      "Epoch: 66 Test Loss: 0.00738991 Val RMSE: 25468.667035421946\n",
      "Epoch: 67 Test Loss: 0.00720705 Val RMSE: 24733.374110418707\n",
      "Epoch: 68 Test Loss: 0.00703054 Val RMSE: 24008.03967732605\n",
      "Epoch: 69 Test Loss: 0.00686007 Val RMSE: 23305.91605277848\n",
      "Epoch: 70 Test Loss: 0.00669529 Val RMSE: 22613.0736315737\n",
      "Epoch: 71 Test Loss: 0.00653603 Val RMSE: 21930.658822023895\n",
      "Epoch: 72 Test Loss: 0.00638207 Val RMSE: 21271.42742164215\n",
      "Epoch: 73 Test Loss: 0.00623306 Val RMSE: 20634.441292471707\n",
      "Epoch: 74 Test Loss: 0.00608889 Val RMSE: 20012.79906682832\n",
      "Epoch: 75 Test Loss: 0.00594922 Val RMSE: 19398.378040768686\n",
      "Epoch: 76 Test Loss: 0.00581393 Val RMSE: 18806.09142764397\n",
      "Epoch: 77 Test Loss: 0.00568283 Val RMSE: 18235.4778582393\n",
      "Epoch: 78 Test Loss: 0.00555563 Val RMSE: 17685.628466699196\n",
      "Epoch: 79 Test Loss: 0.00543229 Val RMSE: 17156.66171287419\n",
      "Epoch: 80 Test Loss: 0.00531256 Val RMSE: 16641.019580956166\n",
      "Epoch: 81 Test Loss: 0.00519633 Val RMSE: 16136.230500440915\n",
      "Epoch: 82 Test Loss: 0.00508335 Val RMSE: 15651.450694153153\n",
      "Epoch: 83 Test Loss: 0.00497353 Val RMSE: 15186.463919337535\n",
      "Epoch: 84 Test Loss: 0.00486674 Val RMSE: 14740.997740881965\n",
      "Epoch: 85 Test Loss: 0.00476282 Val RMSE: 14314.45314253744\n",
      "Epoch: 86 Test Loss: 0.00466163 Val RMSE: 13906.736937164116\n",
      "Epoch: 87 Test Loss: 0.00456312 Val RMSE: 13517.714344881113\n",
      "Epoch: 88 Test Loss: 0.00446707 Val RMSE: 13146.75198163426\n",
      "Epoch: 89 Test Loss: 0.00437345 Val RMSE: 12793.85919813159\n",
      "Epoch: 90 Test Loss: 0.00428211 Val RMSE: 12449.308078192016\n",
      "Epoch: 91 Test Loss: 0.00419298 Val RMSE: 12122.489532704576\n",
      "Epoch: 92 Test Loss: 0.00410593 Val RMSE: 11814.13413916254\n",
      "Epoch: 93 Test Loss: 0.00402096 Val RMSE: 11524.492689040373\n",
      "Epoch: 94 Test Loss: 0.00393795 Val RMSE: 11253.360150698933\n",
      "Epoch: 95 Test Loss: 0.00385676 Val RMSE: 11000.782969854004\n",
      "Epoch: 96 Test Loss: 0.00377747 Val RMSE: 10767.155176449449\n",
      "Epoch: 97 Test Loss: 0.00369990 Val RMSE: 10552.253564493134\n",
      "Epoch: 98 Test Loss: 0.00362402 Val RMSE: 10356.411019957814\n",
      "Epoch: 99 Test Loss: 0.00354984 Val RMSE: 10179.828666303298\n",
      "Epoch: 100 Test Loss: 0.00347722 Val RMSE: 10022.33557379243\n",
      "Epoch: 101 Test Loss: 0.00340619 Val RMSE: 9884.181963990924\n",
      "Epoch: 102 Test Loss: 0.00333671 Val RMSE: 9765.291164145285\n",
      "Epoch: 103 Test Loss: 0.00326869 Val RMSE: 9665.443563670513\n",
      "Epoch: 104 Test Loss: 0.00320203 Val RMSE: 9582.96513562961\n",
      "Epoch: 105 Test Loss: 0.00313673 Val RMSE: 9518.357814967427\n",
      "Epoch: 106 Test Loss: 0.00307269 Val RMSE: 9472.470619727472\n",
      "Epoch: 107 Test Loss: 0.00300978 Val RMSE: 9444.583620319656\n",
      "Epoch: 108 Test Loss: 0.00294798 Val RMSE: 9433.987636631871\n",
      "Epoch: 109 Test Loss: 0.00288707 Val RMSE: 9439.813918189107\n",
      "Epoch: 110 Test Loss: 0.00282706 Val RMSE: 9461.371151553358\n",
      "Epoch: 111 Test Loss: 0.00276777 Val RMSE: 9497.928906942068\n",
      "Epoch: 112 Test Loss: 0.00270911 Val RMSE: 9548.963813119246\n",
      "Epoch: 113 Test Loss: 0.00265098 Val RMSE: 9614.041762918134\n",
      "Epoch: 114 Test Loss: 0.00259325 Val RMSE: 9693.022118530156\n",
      "Epoch: 115 Test Loss: 0.00253591 Val RMSE: 9785.830870364085\n",
      "Epoch: 116 Test Loss: 0.00247884 Val RMSE: 9892.727109052648\n",
      "Epoch: 117 Test Loss: 0.00242212 Val RMSE: 10013.807624337844\n",
      "Epoch: 118 Test Loss: 0.00236573 Val RMSE: 10149.503274350314\n",
      "Epoch: 119 Test Loss: 0.00230965 Val RMSE: 10300.335362183472\n",
      "Epoch: 120 Test Loss: 0.00225390 Val RMSE: 10466.874764363147\n",
      "Epoch: 121 Test Loss: 0.00219851 Val RMSE: 10649.897251191538\n",
      "Epoch: 122 Test Loss: 0.00214347 Val RMSE: 10850.350878217077\n",
      "Epoch: 123 Test Loss: 0.00208883 Val RMSE: 11068.992030169542\n",
      "Epoch: 124 Test Loss: 0.00203458 Val RMSE: 11307.187301583639\n",
      "Epoch: 125 Test Loss: 0.00198072 Val RMSE: 11566.195216107391\n",
      "Epoch: 126 Test Loss: 0.00192725 Val RMSE: 11847.471070666672\n",
      "Epoch: 127 Test Loss: 0.00187426 Val RMSE: 12152.19188566214\n",
      "Model trained for window_size of 40 and hidden size of 10\n",
      "Fitting for window_size of 40 and hidden size of 20\n",
      "Epoch:  1 Test Loss: 0.91848797 Val RMSE: 131546.4915787558\n",
      "Epoch:  2 Test Loss: 0.85086840 Val RMSE: 125264.4268132183\n",
      "Epoch:  3 Test Loss: 0.78250396 Val RMSE: 119115.83766430414\n",
      "Epoch:  4 Test Loss: 0.71142733 Val RMSE: 112911.74458870842\n",
      "Epoch:  5 Test Loss: 0.63511634 Val RMSE: 106415.73139494927\n",
      "Epoch:  6 Test Loss: 0.55063725 Val RMSE: 99269.7456874212\n",
      "Epoch:  7 Test Loss: 0.45519969 Val RMSE: 91199.55429901223\n",
      "Epoch:  8 Test Loss: 0.34833768 Val RMSE: 81944.94962339922\n",
      "Epoch:  9 Test Loss: 0.23772402 Val RMSE: 71802.44817621038\n",
      "Epoch: 10 Test Loss: 0.14466485 Val RMSE: 62101.49499088653\n",
      "Epoch: 11 Test Loss: 0.08809103 Val RMSE: 54459.328121274506\n",
      "Epoch: 12 Test Loss: 0.06143276 Val RMSE: 49812.44500719468\n",
      "Epoch: 13 Test Loss: 0.04942720 Val RMSE: 47372.599262075506\n",
      "Epoch: 14 Test Loss: 0.04346205 Val RMSE: 46046.630749257165\n",
      "Epoch: 15 Test Loss: 0.04001569 Val RMSE: 45233.19090337169\n",
      "Epoch: 16 Test Loss: 0.03768998 Val RMSE: 44655.95757726426\n",
      "Epoch: 17 Test Loss: 0.03590358 Val RMSE: 44190.22483051121\n",
      "Epoch: 18 Test Loss: 0.03440148 Val RMSE: 43778.46190131992\n",
      "Epoch: 19 Test Loss: 0.03306615 Val RMSE: 43393.36816543388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Test Loss: 0.03184095 Val RMSE: 43021.67259226572\n",
      "Epoch: 21 Test Loss: 0.03069704 Val RMSE: 42656.740363780205\n",
      "Epoch: 22 Test Loss: 0.02961858 Val RMSE: 42295.122398245774\n",
      "Epoch: 23 Test Loss: 0.02859640 Val RMSE: 41935.045831130104\n",
      "Epoch: 24 Test Loss: 0.02762436 Val RMSE: 41575.524425015006\n",
      "Epoch: 25 Test Loss: 0.02669827 Val RMSE: 41216.05347682268\n",
      "Epoch: 26 Test Loss: 0.02581475 Val RMSE: 40856.333029881775\n",
      "Epoch: 27 Test Loss: 0.02497110 Val RMSE: 40496.25170478836\n",
      "Epoch: 28 Test Loss: 0.02416520 Val RMSE: 40135.78803301115\n",
      "Epoch: 29 Test Loss: 0.02339487 Val RMSE: 39774.85414316429\n",
      "Epoch: 30 Test Loss: 0.02265816 Val RMSE: 39413.42193240144\n",
      "Epoch: 31 Test Loss: 0.02195352 Val RMSE: 39051.54397064728\n",
      "Epoch: 32 Test Loss: 0.02127928 Val RMSE: 38689.292065729256\n",
      "Epoch: 33 Test Loss: 0.02063411 Val RMSE: 38326.89034400251\n",
      "Epoch: 34 Test Loss: 0.02001624 Val RMSE: 37964.5154229962\n",
      "Epoch: 35 Test Loss: 0.01942392 Val RMSE: 37602.25651616542\n",
      "Epoch: 36 Test Loss: 0.01885471 Val RMSE: 37239.88718097781\n",
      "Epoch: 37 Test Loss: 0.01830612 Val RMSE: 36876.914963072704\n",
      "Epoch: 38 Test Loss: 0.01777581 Val RMSE: 36512.88802259155\n",
      "Epoch: 39 Test Loss: 0.01726185 Val RMSE: 36147.37308768165\n",
      "Epoch: 40 Test Loss: 0.01676262 Val RMSE: 35780.07100924874\n",
      "Epoch: 41 Test Loss: 0.01627677 Val RMSE: 35410.835879232676\n",
      "Epoch: 42 Test Loss: 0.01580338 Val RMSE: 35039.75311703025\n",
      "Epoch: 43 Test Loss: 0.01534146 Val RMSE: 34666.98498667695\n",
      "Epoch: 44 Test Loss: 0.01489009 Val RMSE: 34279.34062358379\n",
      "Epoch: 45 Test Loss: 0.01444845 Val RMSE: 33827.35308139723\n",
      "Epoch: 46 Test Loss: 0.01401551 Val RMSE: 33307.08698382167\n",
      "Epoch: 47 Test Loss: 0.01359034 Val RMSE: 32730.67340844408\n",
      "Epoch: 48 Test Loss: 0.01317208 Val RMSE: 32108.517108882308\n",
      "Epoch: 49 Test Loss: 0.01275966 Val RMSE: 31451.00887861986\n",
      "Epoch: 50 Test Loss: 0.01235190 Val RMSE: 30766.03475973112\n",
      "Epoch: 51 Test Loss: 0.01194759 Val RMSE: 30057.707254996072\n",
      "Epoch: 52 Test Loss: 0.01154536 Val RMSE: 29336.95470089373\n",
      "Epoch: 53 Test Loss: 0.01114374 Val RMSE: 28611.575323512472\n",
      "Epoch: 54 Test Loss: 0.01074157 Val RMSE: 27877.553384426697\n",
      "Epoch: 55 Test Loss: 0.01033841 Val RMSE: 27152.860803455424\n",
      "Epoch: 56 Test Loss: 0.00993509 Val RMSE: 26452.67831758699\n",
      "Epoch: 57 Test Loss: 0.00953311 Val RMSE: 25764.428145220278\n",
      "Epoch: 58 Test Loss: 0.00913430 Val RMSE: 25134.14659941064\n",
      "Epoch: 59 Test Loss: 0.00873955 Val RMSE: 24532.171600917114\n",
      "Epoch: 60 Test Loss: 0.00834903 Val RMSE: 23993.408794549232\n",
      "Epoch: 61 Test Loss: 0.00796247 Val RMSE: 23502.924627466626\n",
      "Epoch: 62 Test Loss: 0.00757973 Val RMSE: 23004.980863588713\n",
      "Epoch: 63 Test Loss: 0.00720172 Val RMSE: 22483.72093437808\n",
      "Epoch: 64 Test Loss: 0.00683073 Val RMSE: 21880.702590467623\n",
      "Epoch: 65 Test Loss: 0.00647092 Val RMSE: 21110.722296809607\n",
      "Epoch: 66 Test Loss: 0.00612777 Val RMSE: 20140.95949279409\n",
      "Epoch: 67 Test Loss: 0.00580759 Val RMSE: 18969.773319062908\n",
      "Epoch: 68 Test Loss: 0.00551642 Val RMSE: 17613.173344323346\n",
      "Epoch: 69 Test Loss: 0.00525888 Val RMSE: 16176.273806807454\n",
      "Epoch: 70 Test Loss: 0.00503749 Val RMSE: 14858.997359255938\n",
      "Epoch: 71 Test Loss: 0.00485239 Val RMSE: 14023.952926371094\n",
      "Epoch: 72 Test Loss: 0.00470143 Val RMSE: 14057.039768743038\n",
      "Epoch: 73 Test Loss: 0.00458096 Val RMSE: 15124.361923170714\n",
      "Epoch: 74 Test Loss: 0.00448618 Val RMSE: 16999.33433923274\n",
      "Epoch: 75 Test Loss: 0.00441219 Val RMSE: 19282.161132787885\n",
      "Epoch: 76 Test Loss: 0.00435436 Val RMSE: 21633.18618124647\n",
      "Epoch: 77 Test Loss: 0.00430864 Val RMSE: 23846.07724559457\n",
      "Epoch: 78 Test Loss: 0.00427156 Val RMSE: 25825.63393908465\n",
      "Epoch: 79 Test Loss: 0.00424054 Val RMSE: 27543.477529773336\n",
      "Epoch: 80 Test Loss: 0.00421339 Val RMSE: 29011.45511447279\n",
      "Epoch: 81 Test Loss: 0.00418857 Val RMSE: 30255.279806646446\n",
      "Epoch: 82 Test Loss: 0.00416485 Val RMSE: 31308.954654620895\n",
      "Epoch: 83 Test Loss: 0.00414135 Val RMSE: 32204.38313734348\n",
      "Epoch: 84 Test Loss: 0.00411740 Val RMSE: 32971.98772917429\n",
      "Epoch: 85 Test Loss: 0.00409251 Val RMSE: 33639.74340820229\n",
      "Epoch: 86 Test Loss: 0.00406630 Val RMSE: 34230.19860043156\n",
      "Epoch: 87 Test Loss: 0.00403852 Val RMSE: 34762.11868962131\n",
      "Epoch: 88 Test Loss: 0.00400888 Val RMSE: 35252.79320873321\n",
      "Epoch: 89 Test Loss: 0.00397740 Val RMSE: 35713.880273523166\n",
      "Epoch: 90 Test Loss: 0.00394388 Val RMSE: 36157.42476303342\n",
      "Model trained for window_size of 40 and hidden size of 20\n",
      "Fitting for window_size of 40 and hidden size of 40\n",
      "Epoch:  1 Test Loss: 1.17787707 Val RMSE: 637057.8143902218\n",
      "Epoch:  2 Test Loss: 1.04566526 Val RMSE: 275272.2370550236\n",
      "Epoch:  3 Test Loss: 0.88795888 Val RMSE: 135968.1486318473\n",
      "Epoch:  4 Test Loss: 0.67053181 Val RMSE: 114711.95249138724\n",
      "Epoch:  5 Test Loss: 0.32817855 Val RMSE: 84459.72994611155\n",
      "Epoch:  6 Test Loss: 0.06082680 Val RMSE: 48734.02424874462\n",
      "Epoch:  7 Test Loss: 0.04245998 Val RMSE: 44218.31209367767\n",
      "Epoch:  8 Test Loss: 0.03882712 Val RMSE: 43327.32065560654\n",
      "Epoch:  9 Test Loss: 0.03689966 Val RMSE: 42865.23428895205\n",
      "Epoch: 10 Test Loss: 0.03542965 Val RMSE: 42504.87903918462\n",
      "Epoch: 11 Test Loss: 0.03414590 Val RMSE: 42176.91494497742\n",
      "Epoch: 12 Test Loss: 0.03295955 Val RMSE: 41859.525615444625\n",
      "Epoch: 13 Test Loss: 0.03183266 Val RMSE: 41543.73363405961\n",
      "Epoch: 14 Test Loss: 0.03074595 Val RMSE: 41225.002292551675\n",
      "Epoch: 15 Test Loss: 0.02968833 Val RMSE: 40900.58497492413\n",
      "Epoch: 16 Test Loss: 0.02865321 Val RMSE: 40568.72086812414\n",
      "Epoch: 17 Test Loss: 0.02763654 Val RMSE: 40228.187917273506\n",
      "Epoch: 18 Test Loss: 0.02663646 Val RMSE: 39878.24174858971\n",
      "Epoch: 19 Test Loss: 0.02565251 Val RMSE: 39518.562771408\n",
      "Epoch: 20 Test Loss: 0.02468562 Val RMSE: 39149.31720258565\n",
      "Epoch: 21 Test Loss: 0.02373741 Val RMSE: 38770.89896996809\n",
      "Epoch: 22 Test Loss: 0.02280999 Val RMSE: 38384.092287489024\n",
      "Epoch: 23 Test Loss: 0.02190547 Val RMSE: 37989.76719295651\n",
      "Epoch: 24 Test Loss: 0.02102579 Val RMSE: 37588.931330115425\n",
      "Epoch: 25 Test Loss: 0.02017244 Val RMSE: 37182.5131600972\n",
      "Epoch: 26 Test Loss: 0.01934636 Val RMSE: 36771.33686746069\n",
      "Epoch: 27 Test Loss: 0.01854807 Val RMSE: 36356.200820282895\n",
      "Epoch: 28 Test Loss: 0.01777743 Val RMSE: 35937.6186965938\n",
      "Epoch: 29 Test Loss: 0.01703394 Val RMSE: 35516.04622826804\n",
      "Epoch: 30 Test Loss: 0.01631684 Val RMSE: 35091.91677218098\n",
      "Epoch: 31 Test Loss: 0.01562513 Val RMSE: 34665.545399002855\n",
      "Epoch: 32 Test Loss: 0.01495775 Val RMSE: 34231.1943051292\n",
      "Epoch: 33 Test Loss: 0.01431334 Val RMSE: 33727.49150932788\n",
      "Epoch: 34 Test Loss: 0.01369081 Val RMSE: 33127.509275595476\n",
      "Epoch: 35 Test Loss: 0.01308899 Val RMSE: 32441.276321388043\n",
      "Epoch: 36 Test Loss: 0.01250681 Val RMSE: 31677.876261341597\n",
      "Epoch: 37 Test Loss: 0.01194334 Val RMSE: 30849.221906695126\n",
      "Epoch: 38 Test Loss: 0.01139783 Val RMSE: 29963.00268062849\n",
      "Epoch: 39 Test Loss: 0.01086945 Val RMSE: 29031.44874187142\n",
      "Epoch: 40 Test Loss: 0.01035779 Val RMSE: 28065.260671074706\n",
      "Epoch: 41 Test Loss: 0.00986222 Val RMSE: 27065.54121318748\n",
      "Epoch: 42 Test Loss: 0.00938245 Val RMSE: 26035.25937647832\n",
      "Epoch: 43 Test Loss: 0.00891809 Val RMSE: 24999.90780718153\n",
      "Epoch: 44 Test Loss: 0.00846897 Val RMSE: 23926.525499315132\n",
      "Epoch: 45 Test Loss: 0.00803495 Val RMSE: 22859.49529570883\n",
      "Epoch: 46 Test Loss: 0.00761604 Val RMSE: 21777.595936243448\n",
      "Epoch: 47 Test Loss: 0.00721220 Val RMSE: 20687.245435526576\n",
      "Epoch: 48 Test Loss: 0.00682368 Val RMSE: 19611.244560933254\n",
      "Epoch: 49 Test Loss: 0.00645083 Val RMSE: 18554.558227192305\n",
      "Epoch: 50 Test Loss: 0.00609423 Val RMSE: 17483.22844098786\n",
      "Epoch: 51 Test Loss: 0.00575465 Val RMSE: 16450.423588190177\n",
      "Epoch: 52 Test Loss: 0.00543312 Val RMSE: 15475.641909463066\n",
      "Epoch: 53 Test Loss: 0.00513061 Val RMSE: 14587.531196784204\n",
      "Epoch: 54 Test Loss: 0.00484822 Val RMSE: 13828.434913006\n",
      "Epoch: 55 Test Loss: 0.00458685 Val RMSE: 13252.461515466595\n",
      "Epoch: 56 Test Loss: 0.00434699 Val RMSE: 12935.183779869241\n",
      "Epoch: 57 Test Loss: 0.00412879 Val RMSE: 12990.077526731115\n",
      "Epoch: 58 Test Loss: 0.00393162 Val RMSE: 13498.382373250382\n",
      "Epoch: 59 Test Loss: 0.00375409 Val RMSE: 14503.77311698285\n",
      "Epoch: 60 Test Loss: 0.00359400 Val RMSE: 15998.917782182793\n",
      "Epoch: 61 Test Loss: 0.00344834 Val RMSE: 17931.89735113466\n",
      "Epoch: 62 Test Loss: 0.00331340 Val RMSE: 20225.006065826554\n",
      "Epoch: 63 Test Loss: 0.00318517 Val RMSE: 22795.262485741267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 Test Loss: 0.00305980 Val RMSE: 25567.168404755772\n",
      "Epoch: 65 Test Loss: 0.00293385 Val RMSE: 28482.8725662181\n",
      "Epoch: 66 Test Loss: 0.00280474 Val RMSE: 31506.228667198702\n",
      "Epoch: 67 Test Loss: 0.00267092 Val RMSE: 34619.11815610967\n",
      "Epoch: 68 Test Loss: 0.00253188 Val RMSE: 37820.22328667733\n",
      "Epoch: 69 Test Loss: 0.00238818 Val RMSE: 41146.67727043762\n",
      "Epoch: 70 Test Loss: 0.00224112 Val RMSE: 44656.446392284204\n",
      "Epoch: 71 Test Loss: 0.00209263 Val RMSE: 48275.53440400652\n",
      "Epoch: 72 Test Loss: 0.00194492 Val RMSE: 51993.92402872607\n",
      "Epoch: 73 Test Loss: 0.00180029 Val RMSE: 55786.32853580105\n",
      "Epoch: 74 Test Loss: 0.00166091 Val RMSE: 59614.12338909267\n",
      "Epoch: 75 Test Loss: 0.00152867 Val RMSE: 63423.52843022643\n",
      "Model trained for window_size of 40 and hidden size of 40\n",
      "Fitting for window_size of 40 and hidden size of 60\n",
      "Epoch:  1 Test Loss: 0.97992855 Val RMSE: 244813.55166496555\n",
      "Epoch:  2 Test Loss: 0.79246360 Val RMSE: 126554.11190548625\n",
      "Epoch:  3 Test Loss: 0.43485010 Val RMSE: 94758.18574761834\n",
      "Epoch:  4 Test Loss: 0.03282628 Val RMSE: 40267.87758496854\n",
      "Epoch:  5 Test Loss: 0.04816895 Val RMSE: 45768.31113688651\n",
      "Epoch:  6 Test Loss: 0.04248416 Val RMSE: 44555.894433244495\n",
      "Epoch:  7 Test Loss: 0.03924445 Val RMSE: 43881.06296226356\n",
      "Epoch:  8 Test Loss: 0.03685360 Val RMSE: 43374.74484418522\n",
      "Epoch:  9 Test Loss: 0.03479549 Val RMSE: 42914.25320643086\n",
      "Epoch: 10 Test Loss: 0.03288332 Val RMSE: 42455.995889651196\n",
      "Epoch: 11 Test Loss: 0.03103805 Val RMSE: 41981.71046487474\n",
      "Epoch: 12 Test Loss: 0.02922661 Val RMSE: 41483.90277777716\n",
      "Epoch: 13 Test Loss: 0.02743951 Val RMSE: 40960.41442440071\n",
      "Epoch: 14 Test Loss: 0.02568001 Val RMSE: 40411.722845768454\n",
      "Epoch: 15 Test Loss: 0.02395669 Val RMSE: 39839.33356493444\n",
      "Epoch: 16 Test Loss: 0.02227877 Val RMSE: 39245.2483360354\n",
      "Epoch: 17 Test Loss: 0.02065402 Val RMSE: 38632.18527860088\n",
      "Epoch: 18 Test Loss: 0.01908767 Val RMSE: 38003.82841115475\n",
      "Epoch: 19 Test Loss: 0.01758215 Val RMSE: 37365.13471495766\n",
      "Epoch: 20 Test Loss: 0.01613755 Val RMSE: 36722.80719312688\n",
      "Epoch: 21 Test Loss: 0.01475239 Val RMSE: 36086.132365173056\n",
      "Epoch: 22 Test Loss: 0.01342537 Val RMSE: 35468.33113423414\n",
      "Epoch: 23 Test Loss: 0.01215630 Val RMSE: 34887.40723518368\n",
      "Epoch: 24 Test Loss: 0.01094638 Val RMSE: 34366.18790775461\n",
      "Epoch: 25 Test Loss: 0.00979878 Val RMSE: 33690.523471712775\n",
      "Epoch: 26 Test Loss: 0.00871861 Val RMSE: 32270.00673218748\n",
      "Epoch: 27 Test Loss: 0.00771267 Val RMSE: 30602.491552977233\n",
      "Epoch: 28 Test Loss: 0.00678908 Val RMSE: 28725.895774852273\n",
      "Epoch: 29 Test Loss: 0.00595725 Val RMSE: 26599.17957360632\n",
      "Epoch: 30 Test Loss: 0.00522808 Val RMSE: 24133.92420510081\n",
      "Epoch: 31 Test Loss: 0.00461365 Val RMSE: 21181.32605211486\n",
      "Epoch: 32 Test Loss: 0.00412400 Val RMSE: 17868.430257863954\n",
      "Epoch: 33 Test Loss: 0.00376037 Val RMSE: 14778.755437449227\n",
      "Epoch: 34 Test Loss: 0.00351022 Val RMSE: 13743.365795378031\n",
      "Epoch: 35 Test Loss: 0.00335084 Val RMSE: 17231.750833793278\n",
      "Epoch: 36 Test Loss: 0.00325758 Val RMSE: 23226.398331645178\n",
      "Epoch: 37 Test Loss: 0.00320959 Val RMSE: 29009.090229986174\n",
      "Epoch: 38 Test Loss: 0.00319136 Val RMSE: 33688.153059890654\n",
      "Epoch: 39 Test Loss: 0.00319208 Val RMSE: 37265.78461157814\n",
      "Epoch: 40 Test Loss: 0.00320423 Val RMSE: 39972.192019162445\n",
      "Epoch: 41 Test Loss: 0.00322264 Val RMSE: 42043.628933268796\n",
      "Epoch: 42 Test Loss: 0.00324356 Val RMSE: 43672.81375916085\n",
      "Epoch: 43 Test Loss: 0.00326415 Val RMSE: 45008.82591157197\n",
      "Epoch: 44 Test Loss: 0.00328207 Val RMSE: 46168.85263581165\n",
      "Epoch: 45 Test Loss: 0.00329526 Val RMSE: 47247.53114578031\n",
      "Epoch: 46 Test Loss: 0.00330179 Val RMSE: 48321.78321085032\n",
      "Epoch: 47 Test Loss: 0.00329982 Val RMSE: 49458.519071796225\n",
      "Epoch: 48 Test Loss: 0.00328757 Val RMSE: 50713.74345745\n",
      "Epoch: 49 Test Loss: 0.00326349 Val RMSE: 52134.43625019201\n",
      "Epoch: 50 Test Loss: 0.00322606 Val RMSE: 53762.6003192215\n",
      "Epoch: 51 Test Loss: 0.00317413 Val RMSE: 55629.96408114545\n",
      "Epoch: 52 Test Loss: 0.00310673 Val RMSE: 57762.29772049429\n",
      "Epoch: 53 Test Loss: 0.00302340 Val RMSE: 60177.71129848919\n",
      "Model trained for window_size of 40 and hidden size of 60\n",
      "Fitting for window_size of 40 and hidden size of 80\n",
      "Epoch:  1 Test Loss: 0.92682296 Val RMSE: 132063.9739070736\n",
      "Epoch:  2 Test Loss: 0.72818065 Val RMSE: 113742.19001417949\n",
      "Epoch:  3 Test Loss: 0.25217900 Val RMSE: 70963.50936332064\n",
      "Epoch:  4 Test Loss: 0.08986766 Val RMSE: 52261.358334199365\n",
      "Epoch:  5 Test Loss: 0.07888884 Val RMSE: 50907.72487157718\n",
      "Epoch:  6 Test Loss: 0.06854629 Val RMSE: 49377.43518419967\n",
      "Epoch:  7 Test Loss: 0.06258538 Val RMSE: 48502.791327937884\n",
      "Epoch:  8 Test Loss: 0.05831204 Val RMSE: 47878.603114192956\n",
      "Epoch:  9 Test Loss: 0.05479033 Val RMSE: 47356.53898726657\n",
      "Epoch: 10 Test Loss: 0.05163394 Val RMSE: 46873.226656232924\n",
      "Epoch: 11 Test Loss: 0.04865561 Val RMSE: 46396.06551431966\n",
      "Epoch: 12 Test Loss: 0.04575485 Val RMSE: 45905.451583414484\n",
      "Epoch: 13 Test Loss: 0.04287779 Val RMSE: 45388.479084779494\n",
      "Epoch: 14 Test Loss: 0.04000119 Val RMSE: 44836.69555616095\n",
      "Epoch: 15 Test Loss: 0.03712423 Val RMSE: 44245.085297056736\n",
      "Epoch: 16 Test Loss: 0.03426045 Val RMSE: 43610.858031869524\n",
      "Epoch: 17 Test Loss: 0.03142989 Val RMSE: 42932.284202653034\n",
      "Epoch: 18 Test Loss: 0.02865380 Val RMSE: 42208.11378620129\n",
      "Epoch: 19 Test Loss: 0.02595508 Val RMSE: 41439.086828023304\n",
      "Epoch: 20 Test Loss: 0.02336054 Val RMSE: 40630.458856121\n",
      "Epoch: 21 Test Loss: 0.02089866 Val RMSE: 39793.71256310863\n",
      "Epoch: 22 Test Loss: 0.01859174 Val RMSE: 38945.83081908678\n",
      "Epoch: 23 Test Loss: 0.01644962 Val RMSE: 38107.50194688462\n",
      "Epoch: 24 Test Loss: 0.01446840 Val RMSE: 37302.31796772281\n",
      "Epoch: 25 Test Loss: 0.01263447 Val RMSE: 36558.65368602985\n",
      "Epoch: 26 Test Loss: 0.01092953 Val RMSE: 35913.562473021026\n",
      "Epoch: 27 Test Loss: 0.00933355 Val RMSE: 34293.03387137197\n",
      "Epoch: 28 Test Loss: 0.00783006 Val RMSE: 31070.389722215546\n",
      "Epoch: 29 Test Loss: 0.00641741 Val RMSE: 26623.968646116435\n",
      "Epoch: 30 Test Loss: 0.00513296 Val RMSE: 19655.102219617536\n",
      "Epoch: 31 Test Loss: 0.00407455 Val RMSE: 12805.311948310436\n",
      "Epoch: 32 Test Loss: 0.00336312 Val RMSE: 26954.62273448444\n",
      "Epoch: 33 Test Loss: 0.00304414 Val RMSE: 39456.02811301508\n",
      "Epoch: 34 Test Loss: 0.00305196 Val RMSE: 43371.40515652046\n",
      "Epoch: 35 Test Loss: 0.00326771 Val RMSE: 42345.90763108086\n",
      "Epoch: 36 Test Loss: 0.00357984 Val RMSE: 39416.187448302655\n",
      "Epoch: 37 Test Loss: 0.00390720 Val RMSE: 36152.70677511052\n",
      "Epoch: 38 Test Loss: 0.00419697 Val RMSE: 33220.82721629353\n",
      "Epoch: 39 Test Loss: 0.00441621 Val RMSE: 30868.048333784798\n"
     ]
    }
   ],
   "source": [
    "def hyperparameterSearch( window_sizes = [10, 20, 40, 80, 100], hidden_sizes = [10, 20, 40, 60, 80, 100, 150], zipcode = 91331, df = cal_df):\n",
    "    lowest_rmse = math.inf\n",
    "    val_rmse = math.inf\n",
    "    \n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        WINDOW_SIZE = window_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            HIDDEN_SIZE = hidden_size\n",
    "            \n",
    "            print(f\"Fitting for window_size of {WINDOW_SIZE} and hidden size of {HIDDEN_SIZE}\")\n",
    "            y = df.loc[zipcode]\n",
    "\n",
    "            y_train, y_valid, y_test = split_dataset(y, 0.1, 0.1)\n",
    "\n",
    "            model = LSTM(window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE)\n",
    "            model, val_rmse = model.fit(y_train, y_valid)\n",
    "            print(f\"Model trained for window_size of {model.window_size} and hidden size of {model.hidden_size}\")\n",
    "\n",
    "\n",
    "            if (val_rmse < lowest_rmse):\n",
    "                best_model = copy.deepcopy(model)\n",
    "                lowest_rmse = val_rmse\n",
    "                \n",
    "    save_regressor(best_model,zipcode)\n",
    "    return best_model\n",
    "\n",
    "def evaluate(zipcode):\n",
    "    model = load_regressor(zipcode)\n",
    "    print(\"Window size:\", model.window_size, \"Hidden size:\", model.hidden_size)\n",
    "    y = cal_df.loc[zipcode]\n",
    "    y_train, y_valid, y_test = split_dataset(y, 0.1, 0.1)\n",
    "    test_rmse, y_preds = model.score(y_test)\n",
    "    print(\"RMSE:\", test_rmse)\n",
    "\n",
    "\n",
    "    plt.plot(np.append(model.prices, y_preds))\n",
    "    plt.plot(np.append(y_train, np.append(y_valid, y_test)))\n",
    "                \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cal_df = PriceData(datapath).df\n",
    "    zip_codes = cal_df.index[:10]\n",
    "    for zip_code in zip_codes:\n",
    "        print(f\"Training Model for ZipCode {zip_code}\")\n",
    "        hyperparameterSearch(zipcode = zip_code, df = cal_df)\n",
    "\n",
    "        print(f\"Evaluating Model for ZipCode {zip_code}\")\n",
    "        evaluate(zip_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
