{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#Path to datafile\n",
    "datapath = \"All_zip.csv\"\n",
    "WINDOW_SIZE = 50\n",
    "LEARNING_RATE = 0.000025\n",
    "N_EPOCHS = 200\n",
    "HIDDEN_SIZE = 100\n",
    "EPOCHS_EARLY = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "class PriceData():\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.df = self.generateDF(filename)\n",
    "\n",
    "    def generateDF(self, filename):\n",
    "        \n",
    "        def lat(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][0]\n",
    "\n",
    "        def long(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][1]\n",
    "\n",
    "        \n",
    "        orig_df = pd.read_csv(filename)\n",
    "        filtered_df = orig_df.loc[(orig_df['State'] == \"CA\")]\n",
    "        \n",
    "        \n",
    "\n",
    "        columns = filtered_df.columns\n",
    "        \n",
    "\n",
    "        cal_df = filtered_df \\\n",
    "            .dropna() \\\n",
    "            .drop(columns=columns[3:9]) \\\n",
    "            .drop(columns=columns[0:2]) \\\n",
    "            .rename(columns={'RegionName': 'ZipCode'}) \\\n",
    "            .reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        cal_df.set_index(\"ZipCode\", inplace = True)\n",
    "\n",
    "#         for zip_code in cal_df.index:\n",
    "#             print(zip_code)\n",
    "#             cal_df[\"windows\"] = cal_df.apply(lambda row: createBatches(row[\"prices\"]), axis = 1)\n",
    "        \n",
    "\n",
    "        return cal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size = 1, window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE, out_size = 1, learning_rate = LEARNING_RATE, epochs = N_EPOCHS):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        #Model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,out_size)\n",
    "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
    "        self.window_size = None\n",
    "        self.prices = None\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        #Data processing\n",
    "        self.scaler = None\n",
    "        \n",
    "        #Training parameters\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        \n",
    "        #Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def _preprocessor(self, ySeries):\n",
    "        y = ySeries.values\n",
    "\n",
    "        \n",
    "        \n",
    "        window_size = self.window_size\n",
    "\n",
    "        out = []\n",
    "        self.prices = y[:window_size].reshape(window_size)\n",
    "        for i in range(len(y) - window_size):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            y_scaled = scaler.fit_transform(y[i:i+window_size+1].reshape(-1, 1))\n",
    "            self.scaler = scaler\n",
    "            window = torch.tensor(y_scaled[:window_size]).to(torch.float32)\n",
    "            label = torch.tensor(y_scaled[window_size:window_size+1]).to(torch.float32)\n",
    "            self.prices = np.append(self.prices, y[i+window_size:i+window_size+1][0])\n",
    "            out.append((window, label))\n",
    "        return out\n",
    "    \n",
    "    def fit(self, y, y_val):\n",
    "        y_train = self._preprocessor(y)\n",
    "        \n",
    "        epochs_wo_imp = 0\n",
    "        lowest_rmse = math.inf\n",
    "        val_rmse = math.inf\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for seq, y_hat in y_train:\n",
    "                self.optimiser.zero_grad()\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size), torch.zeros(1,1,self.hidden_size))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "                loss = self.criterion(y_hat[0], y_pred)\n",
    "                loss.backward() \n",
    "                self.optimiser.step()\n",
    "            \n",
    "            val_rmse = self.score(y_val)[0]\n",
    "            \n",
    "            if (val_rmse < lowest_rmse):\n",
    "                best_model = copy.deepcopy(self)\n",
    "                best_model.prices = np.append(best_model.prices, y_val)\n",
    "                lowest_rmse = val_rmse\n",
    "                epochs_wo_imp = 0\n",
    "            else:\n",
    "                epochs_wo_imp += 1\n",
    "                \n",
    "            if (epochs_wo_imp == EPOCHS_EARLY):\n",
    "                return best_model, lowest_rmse\n",
    "            \n",
    "            print(f'Epoch: {epoch+1:2} Test Loss: {loss.item():10.8f} Val RMSE: {val_rmse}')\n",
    "            \n",
    "        return (best_model, lowest_rmse)\n",
    "                \n",
    "            \n",
    "    def predict(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            seq = torch.FloatTensor(scaler.fit_transform(self.prices[-self.window_size:].reshape(-1, 1)))\n",
    "            self.scaler = scaler\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self.scaler.inverse_transform(np.array(self(seq).item()).reshape(-1, 1)))\n",
    "        \n",
    "        predictions = self.prices[-future_instances:]\n",
    "        self.prices = self.prices[:-future_instances]\n",
    "        return predictions\n",
    "    \n",
    "    def predict_inplace(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            seq = torch.FloatTensor(scaler.fit_transform(self.prices[-self.window_size:].reshape(-1, 1)))\n",
    "            self.scaler = scaler\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self.scaler.inverse_transform(np.array(self(seq).item()).reshape(-1, 1)))\n",
    "        \n",
    "        predictions = self.prices[-future_instances:]\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, y):\n",
    "        y_pred = self.predict(len(y))\n",
    "        rmse = np.sqrt(np.mean(((np.array(y_pred)-np.array(y)))**2))\n",
    "        return rmse, y_pred\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
    "        pred = self.linear(lstm_out.view(len(seq),-1))\n",
    "        return pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(y, valid_proportion, test_proportion):\n",
    "\n",
    "   \n",
    "    \n",
    "    n_test = round(len(y) * test_proportion)\n",
    "    n_valid = round(len(y) * valid_proportion)\n",
    "    n_train = (len(y) - n_test) - n_valid\n",
    "    \n",
    "    y_train = y[:n_train]\n",
    "    y_valid = y[n_train:n_train + n_valid]\n",
    "    y_test = y[n_train + n_valid:]\n",
    "    \n",
    "    return (y_train, y_valid, y_test)\n",
    "\n",
    "\n",
    "def save_regressor(trained_model, zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to save the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with load_regressor\n",
    "    with open(str(zipcode) + '_model.pickle', 'wb') as target:\n",
    "        pickle.dump(trained_model, target)\n",
    "    print(f\"\\nSaved model in {zipcode}_model.pickle\\n\")\n",
    "\n",
    "\n",
    "def load_regressor(zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to load the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with save_regressor\n",
    "    with open(str(zipcode) + '_model.pickle', 'rb') as target:\n",
    "        trained_model = pickle.load(target)\n",
    "    print(f\"\\nLoaded model in {zipcode}_model.pickle\\n\")\n",
    "    return trained_model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameterSearch(df, window_sizes = [10, 20, 40, 80, 100], hidden_sizes = [10, 20, 40, 60, 80, 100, 150], zipcode = 91331):\n",
    "    lowest_rmse = math.inf\n",
    "    val_rmse = math.inf\n",
    "    \n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        WINDOW_SIZE = window_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            HIDDEN_SIZE = hidden_size\n",
    "            \n",
    "            print(f\"Fitting for window_size of {WINDOW_SIZE} and hidden size of {HIDDEN_SIZE}\")\n",
    "            y = df.loc[zipcode]\n",
    "\n",
    "            y_train, y_valid, y_test = split_dataset(y, 0.1, 0.1)\n",
    "\n",
    "            model = LSTM(window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE)\n",
    "            model, val_rmse = model.fit(y_train, y_valid)\n",
    "            print(f\"Model trained for window_size of {model.window_size} and hidden size of {model.hidden_size}\")\n",
    "\n",
    "\n",
    "            if (val_rmse < lowest_rmse):\n",
    "                best_model = copy.deepcopy(model)\n",
    "                lowest_rmse = val_rmse\n",
    "                \n",
    "    save_regressor(best_model,zipcode)\n",
    "    return best_model\n",
    "\n",
    "def evaluate(zipcode, df):\n",
    "    model = load_regressor(zipcode)\n",
    "    print(\"Window size:\", model.window_size, \"Hidden size:\", model.hidden_size)\n",
    "    y = cal_df.loc[zipcode]\n",
    "    y_train, y_valid, y_test = split_dataset(y, 0.1, 0.1)\n",
    "    test_rmse, y_preds = model.score(y_test)\n",
    "    print(\"RMSE:\", test_rmse)\n",
    "\n",
    "    \n",
    "    dates = pd.to_datetime(cal_df.columns)\n",
    "    golden_prices = np.append(model.prices, y_preds)\n",
    "    predicted_prices = np.append(y_train, np.append(y_valid, y_test))\n",
    "    # Create a figure and axis object\n",
    "    fig, ax = plt.subplots(figsize = (16, 9))\n",
    "    ax.plot(dates, golden_prices)\n",
    "    ax.plot(dates, predicted_prices)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price')\n",
    "    ax.set_title(f'Price Prediction vs Golden for Zipocde {zipcode}')\n",
    "\n",
    "    # format x-axis tick labels to show only the year\n",
    "    years = mdates.YearLocator()\n",
    "    year_format = mdates.DateFormatter('%Y')\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(year_format)\n",
    "    \n",
    "#     plt.savefig(f'{zipcode}_plot_model.png')\n",
    "    plt.show()\n",
    "                \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     cal_df = PriceData(datapath).df\n",
    "#     zip_codes = [91331, 90201, 90044, 90280, 93307]\n",
    "    \n",
    "#     for zip_code in zip_codes:\n",
    "# #         print(f\"Training Model for ZipCode {zip_code}\")\n",
    "# #         hyperparameterSearch(zipcode = zip_code, df = cal_df)\n",
    "\n",
    "#         print(f\"Evaluating Model for ZipCode {zip_code}\")\n",
    "#         evaluate(zip_code, cal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_regressor_deploy(trained_model, zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to save the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with load_regressor\n",
    "    with open(str(zipcode) + '_deploy_model.pickle', 'wb') as target:\n",
    "        pickle.dump(trained_model, target)\n",
    "    print(f\"\\nSaved model in {zipcode}_model.pickle\\n\")\n",
    "\n",
    "\n",
    "def load_regressor_deploy(zipcode): \n",
    "    \"\"\" \n",
    "    Utility function to load the trained regressor model in part2_model.pickle.\n",
    "    \"\"\"\n",
    "    # If you alter this, make sure it works in tandem with save_regressor\n",
    "    with open(str(zipcode) + '_deploy_model.pickle', 'rb') as target:\n",
    "        trained_model = pickle.load(target)\n",
    "    print(f\"\\nLoaded model in {zipcode}_model.pickle\\n\")\n",
    "    return trained_model\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     cal_df = PriceData(datapath).df\n",
    "#     zip_codes = [91331, 90201, 90044, 90280, 93307]\n",
    "    \n",
    "#     for zip_code in zip_codes:\n",
    "#         model = load_regressor(zip_code)\n",
    "#         WINDOW_SIZE = model.window_size\n",
    "#         HIDDEN_SIZE = model.hidden_size\n",
    "#         print(f\"Fitting for window_size of {WINDOW_SIZE} and hidden size of {HIDDEN_SIZE}\")\n",
    "#         y = cal_df.loc[zip_code]\n",
    "\n",
    "#         y_train, y_valid, y_test = split_dataset(y, 0.1, 0)\n",
    "\n",
    "#         model = LSTM(window_size = WINDOW_SIZE, hidden_size = HIDDEN_SIZE)\n",
    "#         model, val_rmse = model.fit(y_train, y_valid)\n",
    "#         print(f\"Model trained for window_size of {model.window_size} and hidden size of {model.hidden_size}\")\n",
    "#         save_regressor_deploy(model, zip_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the date you are planning to buy the house (YYYY-MM-DD):2030-08-15\n",
      "Please enter the current price of the house in USD($):6381256.82\n",
      "Please enter the zipcode of the house:91331\n",
      "\n",
      "Loaded model in 91331_model.pickle\n",
      "\n",
      "The predicted price of the house is: 6824238.099621132\n"
     ]
    }
   ],
   "source": [
    "def count_months(date1, date2):\n",
    "    \n",
    "    # calculate number of months between the two dates\n",
    "    num_days = relativedelta(date2, date1).days\n",
    "    num_months = relativedelta(date2, date1).months\n",
    "    num_years = relativedelta(date2, date1).years\n",
    "    \n",
    "    months = num_years*12 + num_months + int(num_days > 15)\n",
    "    \n",
    "    return months\n",
    "\n",
    "int()\n",
    "if __name__ == \"__main__\":\n",
    "    #Get user input\n",
    "    date_user = input(\"Please enter the date you are planning to buy the house (YYYY-MM-DD):\")\n",
    "    cur_price = float(input(\"Please enter the current price of the house in USD($):\"))\n",
    "    zip_code = int(input(\"Please enter the zipcode of the house:\"))\n",
    "    \n",
    "    #Get 3 dates\n",
    "    last_date = datetime.strptime('2022-12-31', '%Y-%m-%d').date()\n",
    "    date_today = date.today()\n",
    "    date_user = datetime.strptime(date_user, '%Y-%m-%d').date()\n",
    "    \n",
    "    #Count number of predictions to be made\n",
    "    num_preds = count_months(last_date, date_user)\n",
    "    num_preds_till_today = count_months(last_date, date_today)\n",
    "    \n",
    "    #Load model and make predictions\n",
    "    model = load_regressor_deploy(zip_code)\n",
    "    price_predictions = model.predict(num_preds)\n",
    "    \n",
    "    today_median = price_predictions[num_preds_till_today - 1]\n",
    "    final_median = price_predictions[-1]\n",
    "    \n",
    "    scaling_factor = final_median/today_median\n",
    "    predicted_price = cur_price*scaling_factor\n",
    "    \n",
    "    print(\"The predicted price of the house is:\", predicted_price)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
