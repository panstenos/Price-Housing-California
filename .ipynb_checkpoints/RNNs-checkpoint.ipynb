{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Path to datafile\n",
    "datapath = \"All_zip.csv\"\n",
    "WINDOW_SIZE = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "class PriceData():\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.df = self.generateDF(filename)\n",
    "\n",
    "    def generateDF(self, filename):\n",
    "        \n",
    "        def lat(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][0]\n",
    "\n",
    "        def long(row):\n",
    "            return geolocator.geocode({\"postalcode\":row[\"RegionName\"]})[1][1]\n",
    "\n",
    "        \n",
    "        orig_df = pd.read_csv(filename)\n",
    "        filtered_df = orig_df.loc[(orig_df['State'] == \"CA\")]\n",
    "        \n",
    "        \n",
    "\n",
    "        columns = filtered_df.columns\n",
    "        \n",
    "\n",
    "        cal_df = filtered_df \\\n",
    "            .dropna() \\\n",
    "            .drop(columns=columns[3:9]) \\\n",
    "            .drop(columns=columns[0:2]) \\\n",
    "            .rename(columns={'RegionName': 'ZipCode'}) \\\n",
    "            .reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        cal_df.set_index(\"ZipCode\", inplace = True)\n",
    "\n",
    "#         for zip_code in cal_df.index:\n",
    "#             print(zip_code)\n",
    "#             cal_df[\"windows\"] = cal_df.apply(lambda row: createBatches(row[\"prices\"]), axis = 1)\n",
    "        \n",
    "\n",
    "        return cal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size = 1, hidden_size = 100, out_size = 1, learning_rate = LEARNING_RATE, epochs = N_EPOCHS):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        #Model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,out_size)\n",
    "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
    "        self.window_size = None\n",
    "        self.prices = None\n",
    "        \n",
    "        #Data processing\n",
    "        self.scaler = None\n",
    "        \n",
    "        #Training parameters\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        \n",
    "        #Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def _preprocessor(self, ySeries, window_size = WINDOW_SIZE):\n",
    "        y = ySeries.values\n",
    "\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        y_scaled = scaler.fit_transform(y.reshape(-1, 1))\n",
    "        self.scaler = scaler\n",
    "        self.window_size = window_size\n",
    "\n",
    "        out = []\n",
    "        self.prices = y_scaled[:window_size].reshape(window_size)\n",
    "        for i in range(len(y_scaled) - window_size):\n",
    "            window = torch.tensor(y_scaled[i:i+window_size]).to(torch.float32)\n",
    "            label = torch.tensor(y_scaled[i+window_size:i+window_size+1]).to(torch.float32)\n",
    "            self.prices = np.append(self.prices, y_scaled[i+window_size:i+window_size+1][0][0])\n",
    "            out.append((window, label))\n",
    "        return out\n",
    "    \n",
    "    def fit(self, y):\n",
    "        y_train = self._preprocessor(y)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for seq, y_hat in y_train:\n",
    "                self.optimiser.zero_grad()\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size), torch.zeros(1,1,self.hidden_size))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "#                 print(\"y_pred:\", y_pred, \"y_hat:\", y_hat)\n",
    "                loss = self.criterion(y_hat[0], y_pred)\n",
    "                loss.backward() \n",
    "                self.optimiser.step()\n",
    "            print(f'Epoch: {epoch+1:2} Loss: {loss.item():10.8f}')\n",
    "        \n",
    "    def predict(self, future_instances):\n",
    "        \n",
    "        self.eval()\n",
    "        for i in range(future_instances):\n",
    "            seq = torch.FloatTensor(self.prices[-self.window_size:])\n",
    "            print(\"Predict window\", i, \":\", seq)\n",
    "            with torch.no_grad():\n",
    "                self.hidden = (torch.zeros(1,1,self.hidden_size),\n",
    "                                torch.zeros(1,1,self.hidden_size))\n",
    "                self.prices = np.append(self.prices, self(seq).item())\n",
    "        \n",
    "        predictions = self.scaler.inverse_transform(np.array(self.prices[self.window_size:]).reshape(-1, 1))\n",
    "        print(self.prices[self.window_size])\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, y):\n",
    "        y_pred = self.predict(len(y))\n",
    "        rmse = np.sqrt(np.mean(((np.array(y_pred)-np.array(y)))**2))\n",
    "        return rmse\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
    "        pred = self.linear(lstm_out.view(len(seq),-1))\n",
    "        return pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(ySeries, test_proportion):\n",
    "\n",
    "    \n",
    "    n_test = round(len(ySeries) * test_proportion)\n",
    "    n_train = (len(ySeries) - n_test)\n",
    "\n",
    "    y_train = y.iloc[:n_train]\n",
    "    \n",
    "\n",
    "    y_test = y.iloc[n_train :]\n",
    "    \n",
    "    #print (x_train, x_valid, x_test, y_train, y_valid, y_test)\n",
    "    return (y_train, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cal_df = PriceData(datapath).df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (12,4))\n",
    "# plt.title('House Prices')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Price')\n",
    "# plt.grid(True)\n",
    "# plt.autoscale(axis='x',tight=True)\n",
    "# plt.plot(cal_df.loc[91331],color='#8000ff')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss: 0.00067032\n",
      "Epoch:  2 Loss: 0.00600693\n",
      "Epoch:  3 Loss: 0.00010316\n",
      "Epoch:  4 Loss: 0.00051821\n",
      "Epoch:  5 Loss: 0.00113403\n",
      "Epoch:  6 Loss: 0.00104663\n",
      "Epoch:  7 Loss: 0.00067235\n",
      "Epoch:  8 Loss: 0.00036965\n",
      "Epoch:  9 Loss: 0.00021266\n",
      "Epoch: 10 Loss: 0.00015679\n",
      "Predict window 0 : tensor([0.6729, 0.6774, 0.6850, 0.6948, 0.7017, 0.7054, 0.7106, 0.7149, 0.7197,\n",
      "        0.7210, 0.7260, 0.7328, 0.7406, 0.7481, 0.7546, 0.7615, 0.7718, 0.7811,\n",
      "        0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700,\n",
      "        0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725,\n",
      "        0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616,\n",
      "        0.9772, 0.9785, 0.9777, 0.9819, 1.0000])\n",
      "Predict window 1 : tensor([0.6774, 0.6850, 0.6948, 0.7017, 0.7054, 0.7106, 0.7149, 0.7197, 0.7210,\n",
      "        0.7260, 0.7328, 0.7406, 0.7481, 0.7546, 0.7615, 0.7718, 0.7811, 0.7920,\n",
      "        0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758,\n",
      "        0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687,\n",
      "        0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772,\n",
      "        0.9785, 0.9777, 0.9819, 1.0000, 0.9978])\n",
      "Predict window 2 : tensor([0.6850, 0.6948, 0.7017, 0.7054, 0.7106, 0.7149, 0.7197, 0.7210, 0.7260,\n",
      "        0.7328, 0.7406, 0.7481, 0.7546, 0.7615, 0.7718, 0.7811, 0.7920, 0.8056,\n",
      "        0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802,\n",
      "        0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703,\n",
      "        0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785,\n",
      "        0.9777, 0.9819, 1.0000, 0.9978, 1.0025])\n",
      "Predict window 3 : tensor([0.6948, 0.7017, 0.7054, 0.7106, 0.7149, 0.7197, 0.7210, 0.7260, 0.7328,\n",
      "        0.7406, 0.7481, 0.7546, 0.7615, 0.7718, 0.7811, 0.7920, 0.8056, 0.8197,\n",
      "        0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789,\n",
      "        0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738,\n",
      "        0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777,\n",
      "        0.9819, 1.0000, 0.9978, 1.0025, 1.0066])\n",
      "Predict window 4 : tensor([0.7017, 0.7054, 0.7106, 0.7149, 0.7197, 0.7210, 0.7260, 0.7328, 0.7406,\n",
      "        0.7481, 0.7546, 0.7615, 0.7718, 0.7811, 0.7920, 0.8056, 0.8197, 0.8318,\n",
      "        0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769,\n",
      "        0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855,\n",
      "        0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819,\n",
      "        1.0000, 0.9978, 1.0025, 1.0066, 1.0101])\n",
      "Predict window 5 : tensor([0.7054, 0.7106, 0.7149, 0.7197, 0.7210, 0.7260, 0.7328, 0.7406, 0.7481,\n",
      "        0.7546, 0.7615, 0.7718, 0.7811, 0.7920, 0.8056, 0.8197, 0.8318, 0.8396,\n",
      "        0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724,\n",
      "        0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954,\n",
      "        0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000,\n",
      "        0.9978, 1.0025, 1.0066, 1.0101, 1.0132])\n",
      "Predict window 6 : tensor([0.7106, 0.7149, 0.7197, 0.7210, 0.7260, 0.7328, 0.7406, 0.7481, 0.7546,\n",
      "        0.7615, 0.7718, 0.7811, 0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482,\n",
      "        0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681,\n",
      "        0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097,\n",
      "        0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978,\n",
      "        1.0025, 1.0066, 1.0101, 1.0132, 1.0158])\n",
      "Predict window 7 : tensor([0.7149, 0.7197, 0.7210, 0.7260, 0.7328, 0.7406, 0.7481, 0.7546, 0.7615,\n",
      "        0.7718, 0.7811, 0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565,\n",
      "        0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681,\n",
      "        0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242,\n",
      "        0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025,\n",
      "        1.0066, 1.0101, 1.0132, 1.0158, 1.0180])\n",
      "Predict window 8 : tensor([0.7197, 0.7210, 0.7260, 0.7328, 0.7406, 0.7481, 0.7546, 0.7615, 0.7718,\n",
      "        0.7811, 0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634,\n",
      "        0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690,\n",
      "        0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430,\n",
      "        0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066,\n",
      "        1.0101, 1.0132, 1.0158, 1.0180, 1.0199])\n",
      "Predict window 9 : tensor([0.7210, 0.7260, 0.7328, 0.7406, 0.7481, 0.7546, 0.7615, 0.7718, 0.7811,\n",
      "        0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700,\n",
      "        0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725,\n",
      "        0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616,\n",
      "        0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101,\n",
      "        1.0132, 1.0158, 1.0180, 1.0199, 1.0216])\n",
      "Predict window 10 : tensor([0.7260, 0.7328, 0.7406, 0.7481, 0.7546, 0.7615, 0.7718, 0.7811, 0.7920,\n",
      "        0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758,\n",
      "        0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687,\n",
      "        0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772,\n",
      "        0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101, 1.0132,\n",
      "        1.0158, 1.0180, 1.0199, 1.0216, 1.0229])\n",
      "Predict window 11 : tensor([0.7328, 0.7406, 0.7481, 0.7546, 0.7615, 0.7718, 0.7811, 0.7920, 0.8056,\n",
      "        0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802,\n",
      "        0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703,\n",
      "        0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785,\n",
      "        0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101, 1.0132, 1.0158,\n",
      "        1.0180, 1.0199, 1.0216, 1.0229, 1.0241])\n",
      "Predict window 12 : tensor([0.7406, 0.7481, 0.7546, 0.7615, 0.7718, 0.7811, 0.7920, 0.8056, 0.8197,\n",
      "        0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789,\n",
      "        0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738,\n",
      "        0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777,\n",
      "        0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101, 1.0132, 1.0158, 1.0180,\n",
      "        1.0199, 1.0216, 1.0229, 1.0241, 1.0251])\n",
      "Predict window 13 : tensor([0.7481, 0.7546, 0.7615, 0.7718, 0.7811, 0.7920, 0.8056, 0.8197, 0.8318,\n",
      "        0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769,\n",
      "        0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855,\n",
      "        0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819,\n",
      "        1.0000, 0.9978, 1.0025, 1.0066, 1.0101, 1.0132, 1.0158, 1.0180, 1.0199,\n",
      "        1.0216, 1.0229, 1.0241, 1.0251, 1.0259])\n",
      "Predict window 14 : tensor([0.7546, 0.7615, 0.7718, 0.7811, 0.7920, 0.8056, 0.8197, 0.8318, 0.8396,\n",
      "        0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724,\n",
      "        0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954,\n",
      "        0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000,\n",
      "        0.9978, 1.0025, 1.0066, 1.0101, 1.0132, 1.0158, 1.0180, 1.0199, 1.0216,\n",
      "        1.0229, 1.0241, 1.0251, 1.0259, 1.0266])\n",
      "Predict window 15 : tensor([0.7615, 0.7718, 0.7811, 0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482,\n",
      "        0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681,\n",
      "        0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097,\n",
      "        0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978,\n",
      "        1.0025, 1.0066, 1.0101, 1.0132, 1.0158, 1.0180, 1.0199, 1.0216, 1.0229,\n",
      "        1.0241, 1.0251, 1.0259, 1.0266, 1.0271])\n",
      "Predict window 16 : tensor([0.7718, 0.7811, 0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565,\n",
      "        0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681,\n",
      "        0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242,\n",
      "        0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025,\n",
      "        1.0066, 1.0101, 1.0132, 1.0158, 1.0180, 1.0199, 1.0216, 1.0229, 1.0241,\n",
      "        1.0251, 1.0259, 1.0266, 1.0271, 1.0276])\n",
      "Predict window 17 : tensor([0.7811, 0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634,\n",
      "        0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690,\n",
      "        0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430,\n",
      "        0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066,\n",
      "        1.0101, 1.0132, 1.0158, 1.0180, 1.0199, 1.0216, 1.0229, 1.0241, 1.0251,\n",
      "        1.0259, 1.0266, 1.0271, 1.0276, 1.0280])\n",
      "Predict window 18 : tensor([0.7920, 0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700,\n",
      "        0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725,\n",
      "        0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616,\n",
      "        0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101,\n",
      "        1.0132, 1.0158, 1.0180, 1.0199, 1.0216, 1.0229, 1.0241, 1.0251, 1.0259,\n",
      "        1.0266, 1.0271, 1.0276, 1.0280, 1.0283])\n",
      "Predict window 19 : tensor([0.8056, 0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758,\n",
      "        0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687,\n",
      "        0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772,\n",
      "        0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101, 1.0132,\n",
      "        1.0158, 1.0180, 1.0199, 1.0216, 1.0229, 1.0241, 1.0251, 1.0259, 1.0266,\n",
      "        1.0271, 1.0276, 1.0280, 1.0283, 1.0286])\n",
      "Predict window 20 : tensor([0.8197, 0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802,\n",
      "        0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703,\n",
      "        0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785,\n",
      "        0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101, 1.0132, 1.0158,\n",
      "        1.0180, 1.0199, 1.0216, 1.0229, 1.0241, 1.0251, 1.0259, 1.0266, 1.0271,\n",
      "        1.0276, 1.0280, 1.0283, 1.0286, 1.0288])\n",
      "Predict window 21 : tensor([0.8318, 0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789,\n",
      "        0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738,\n",
      "        0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777,\n",
      "        0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101, 1.0132, 1.0158, 1.0180,\n",
      "        1.0199, 1.0216, 1.0229, 1.0241, 1.0251, 1.0259, 1.0266, 1.0271, 1.0276,\n",
      "        1.0280, 1.0283, 1.0286, 1.0288, 1.0289])\n",
      "Predict window 22 : tensor([0.8396, 0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769,\n",
      "        0.8724, 0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855,\n",
      "        0.8954, 0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819,\n",
      "        1.0000, 0.9978, 1.0025, 1.0066, 1.0101, 1.0132, 1.0158, 1.0180, 1.0199,\n",
      "        1.0216, 1.0229, 1.0241, 1.0251, 1.0259, 1.0266, 1.0271, 1.0276, 1.0280,\n",
      "        1.0283, 1.0286, 1.0288, 1.0289, 1.0291])\n",
      "Predict window 23 : tensor([0.8482, 0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724,\n",
      "        0.8681, 0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954,\n",
      "        0.9097, 0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000,\n",
      "        0.9978, 1.0025, 1.0066, 1.0101, 1.0132, 1.0158, 1.0180, 1.0199, 1.0216,\n",
      "        1.0229, 1.0241, 1.0251, 1.0259, 1.0266, 1.0271, 1.0276, 1.0280, 1.0283,\n",
      "        1.0286, 1.0288, 1.0289, 1.0291, 1.0292])\n",
      "Predict window 24 : tensor([0.8565, 0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681,\n",
      "        0.8681, 0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097,\n",
      "        0.9242, 0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978,\n",
      "        1.0025, 1.0066, 1.0101, 1.0132, 1.0158, 1.0180, 1.0199, 1.0216, 1.0229,\n",
      "        1.0241, 1.0251, 1.0259, 1.0266, 1.0271, 1.0276, 1.0280, 1.0283, 1.0286,\n",
      "        1.0288, 1.0289, 1.0291, 1.0292, 1.0293])\n",
      "Predict window 25 : tensor([0.8634, 0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681,\n",
      "        0.8690, 0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242,\n",
      "        0.9430, 0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025,\n",
      "        1.0066, 1.0101, 1.0132, 1.0158, 1.0180, 1.0199, 1.0216, 1.0229, 1.0241,\n",
      "        1.0251, 1.0259, 1.0266, 1.0271, 1.0276, 1.0280, 1.0283, 1.0286, 1.0288,\n",
      "        1.0289, 1.0291, 1.0292, 1.0293, 1.0293])\n",
      "Predict window 26 : tensor([0.8700, 0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690,\n",
      "        0.8725, 0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430,\n",
      "        0.9616, 0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066,\n",
      "        1.0101, 1.0132, 1.0158, 1.0180, 1.0199, 1.0216, 1.0229, 1.0241, 1.0251,\n",
      "        1.0259, 1.0266, 1.0271, 1.0276, 1.0280, 1.0283, 1.0286, 1.0288, 1.0289,\n",
      "        1.0291, 1.0292, 1.0293, 1.0293, 1.0294])\n",
      "Predict window 27 : tensor([0.8758, 0.8802, 0.8789, 0.8769, 0.8724, 0.8681, 0.8681, 0.8690, 0.8725,\n",
      "        0.8687, 0.8703, 0.8738, 0.8855, 0.8954, 0.9097, 0.9242, 0.9430, 0.9616,\n",
      "        0.9772, 0.9785, 0.9777, 0.9819, 1.0000, 0.9978, 1.0025, 1.0066, 1.0101,\n",
      "        1.0132, 1.0158, 1.0180, 1.0199, 1.0216, 1.0229, 1.0241, 1.0251, 1.0259,\n",
      "        1.0266, 1.0271, 1.0276, 1.0280, 1.0283, 1.0286, 1.0288, 1.0289, 1.0291,\n",
      "        1.0292, 1.0293, 1.0293, 1.0294, 1.0294])\n",
      "0.34846949219393586\n",
      "Predictions: [[284244.        ]\n",
      " [291748.        ]\n",
      " [301410.        ]\n",
      " [311190.        ]\n",
      " [320422.        ]\n",
      " [328641.        ]\n",
      " [338012.        ]\n",
      " [346941.        ]\n",
      " [353763.        ]\n",
      " [359830.        ]\n",
      " [364771.        ]\n",
      " [371651.        ]\n",
      " [377952.        ]\n",
      " [384791.        ]\n",
      " [390417.        ]\n",
      " [397096.        ]\n",
      " [404870.        ]\n",
      " [413404.        ]\n",
      " [421977.        ]\n",
      " [431350.        ]\n",
      " [438314.        ]\n",
      " [444504.        ]\n",
      " [450278.        ]\n",
      " [455791.        ]\n",
      " [461989.        ]\n",
      " [467113.        ]\n",
      " [473868.        ]\n",
      " [479373.        ]\n",
      " [483257.        ]\n",
      " [486568.        ]\n",
      " [487085.        ]\n",
      " [488725.        ]\n",
      " [490096.        ]\n",
      " [492953.        ]\n",
      " [494615.        ]\n",
      " [495595.        ]\n",
      " [495366.        ]\n",
      " [495953.        ]\n",
      " [494438.        ]\n",
      " [492747.        ]\n",
      " [488572.        ]\n",
      " [484589.        ]\n",
      " [480022.        ]\n",
      " [474812.        ]\n",
      " [469769.        ]\n",
      " [464462.        ]\n",
      " [460615.        ]\n",
      " [454548.        ]\n",
      " [443698.        ]\n",
      " [428009.        ]\n",
      " [410356.        ]\n",
      " [393146.        ]\n",
      " [373796.        ]\n",
      " [354727.        ]\n",
      " [338761.        ]\n",
      " [325867.        ]\n",
      " [314616.        ]\n",
      " [302623.        ]\n",
      " [293358.        ]\n",
      " [286399.        ]\n",
      " [280300.        ]\n",
      " [274557.        ]\n",
      " [268672.        ]\n",
      " [263429.        ]\n",
      " [258841.        ]\n",
      " [256195.        ]\n",
      " [253997.        ]\n",
      " [252874.        ]\n",
      " [253387.        ]\n",
      " [255736.        ]\n",
      " [257036.        ]\n",
      " [256679.        ]\n",
      " [258048.        ]\n",
      " [259889.        ]\n",
      " [263357.        ]\n",
      " [263150.        ]\n",
      " [263274.        ]\n",
      " [261059.        ]\n",
      " [260784.        ]\n",
      " [260728.        ]\n",
      " [260936.        ]\n",
      " [261583.        ]\n",
      " [261868.        ]\n",
      " [262881.        ]\n",
      " [262160.        ]\n",
      " [261967.        ]\n",
      " [259662.        ]\n",
      " [260109.        ]\n",
      " [259992.        ]\n",
      " [260487.        ]\n",
      " [258964.        ]\n",
      " [257526.        ]\n",
      " [256966.        ]\n",
      " [256750.        ]\n",
      " [256350.        ]\n",
      " [256321.        ]\n",
      " [256267.        ]\n",
      " [256976.        ]\n",
      " [257790.        ]\n",
      " [259182.        ]\n",
      " [260408.        ]\n",
      " [261790.        ]\n",
      " [263063.        ]\n",
      " [265850.        ]\n",
      " [268340.        ]\n",
      " [273122.        ]\n",
      " [276689.        ]\n",
      " [282904.        ]\n",
      " [289179.        ]\n",
      " [296844.        ]\n",
      " [302725.        ]\n",
      " [308845.        ]\n",
      " [314568.        ]\n",
      " [321351.        ]\n",
      " [326669.        ]\n",
      " [330870.        ]\n",
      " [334711.        ]\n",
      " [337587.        ]\n",
      " [342084.        ]\n",
      " [343770.        ]\n",
      " [345650.        ]\n",
      " [345526.        ]\n",
      " [347495.        ]\n",
      " [349143.        ]\n",
      " [351444.        ]\n",
      " [352924.        ]\n",
      " [354743.        ]\n",
      " [356690.        ]\n",
      " [359116.        ]\n",
      " [361540.        ]\n",
      " [365330.        ]\n",
      " [368759.        ]\n",
      " [372124.        ]\n",
      " [372571.        ]\n",
      " [374886.        ]\n",
      " [376793.        ]\n",
      " [379191.        ]\n",
      " [380960.        ]\n",
      " [383383.        ]\n",
      " [386768.        ]\n",
      " [390042.        ]\n",
      " [394349.        ]\n",
      " [397081.        ]\n",
      " [400233.        ]\n",
      " [402232.        ]\n",
      " [406636.        ]\n",
      " [409829.        ]\n",
      " [412895.        ]\n",
      " [414204.        ]\n",
      " [416006.        ]\n",
      " [419035.        ]\n",
      " [422989.        ]\n",
      " [425753.        ]\n",
      " [427236.        ]\n",
      " [429306.        ]\n",
      " [431026.        ]\n",
      " [432935.        ]\n",
      " [433467.        ]\n",
      " [435474.        ]\n",
      " [438220.        ]\n",
      " [441309.        ]\n",
      " [444330.        ]\n",
      " [446927.        ]\n",
      " [449695.        ]\n",
      " [453814.        ]\n",
      " [457546.        ]\n",
      " [461923.        ]\n",
      " [467367.        ]\n",
      " [473015.        ]\n",
      " [477879.        ]\n",
      " [480970.        ]\n",
      " [484426.        ]\n",
      " [487752.        ]\n",
      " [490512.        ]\n",
      " [493178.        ]\n",
      " [495486.        ]\n",
      " [497235.        ]\n",
      " [496734.        ]\n",
      " [495936.        ]\n",
      " [494106.        ]\n",
      " [492403.        ]\n",
      " [492386.        ]\n",
      " [492745.        ]\n",
      " [494176.        ]\n",
      " [492638.        ]\n",
      " [493264.        ]\n",
      " [494693.        ]\n",
      " [499388.        ]\n",
      " [503324.        ]\n",
      " [509054.        ]\n",
      " [514887.        ]\n",
      " [522392.        ]\n",
      " [529853.        ]\n",
      " [536095.        ]\n",
      " [536637.        ]\n",
      " [536321.        ]\n",
      " [537992.        ]\n",
      " [545238.        ]\n",
      " [544343.90986276]\n",
      " [546230.89227867]\n",
      " [547869.93814635]\n",
      " [549287.83721995]\n",
      " [550509.99440002]\n",
      " [551559.7611835 ]\n",
      " [552458.14914227]\n",
      " [553224.21195173]\n",
      " [553874.85437655]\n",
      " [554425.50082064]\n",
      " [554889.76105213]\n",
      " [555279.76447845]\n",
      " [555606.11239266]\n",
      " [555878.16449499]\n",
      " [556104.18215346]\n",
      " [556291.13738966]\n",
      " [556445.238168  ]\n",
      " [556571.73738146]\n",
      " [556675.07611227]\n",
      " [556759.21790695]\n",
      " [556827.31450129]\n",
      " [556882.23110962]\n",
      " [556926.21214986]\n",
      " [556961.31102562]\n",
      " [556989.05585122]\n",
      " [557010.87923384]\n",
      " [557027.92725921]\n",
      " [557041.01173806]]\n",
      "Golden: 2020-09-30    555033.0\n",
      "2020-10-31    565379.0\n",
      "2020-11-30    572143.0\n",
      "2020-12-31    575935.0\n",
      "2021-01-31    578138.0\n",
      "2021-02-28    584915.0\n",
      "2021-03-31    591649.0\n",
      "2021-04-30    603113.0\n",
      "2021-05-31    617866.0\n",
      "2021-06-30    635506.0\n",
      "2021-07-31    652443.0\n",
      "2021-08-31    658546.0\n",
      "2021-09-30    662930.0\n",
      "2021-10-31    664377.0\n",
      "2021-11-30    670361.0\n",
      "2021-12-31    676348.0\n",
      "2022-01-31    681207.0\n",
      "2022-02-28    689101.0\n",
      "2022-03-31    700377.0\n",
      "2022-04-30    714435.0\n",
      "2022-05-31    726009.0\n",
      "2022-06-30    727168.0\n",
      "2022-07-31    724400.0\n",
      "2022-08-31    712326.0\n",
      "2022-09-30    703432.0\n",
      "2022-10-31    695984.0\n",
      "2022-11-30    697234.0\n",
      "2022-12-31    699036.0\n",
      "Name: 91331, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = cal_df.loc[91331]\n",
    "\n",
    "y_train, y_test = split_dataset(y, 0.1)\n",
    "\n",
    "model = LSTM()\n",
    "model.fit(y_train)\n",
    "\n",
    "preds = model.predict(len(y_test))\n",
    "print(\"Predictions:\", preds)\n",
    "print(\"Golden:\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
